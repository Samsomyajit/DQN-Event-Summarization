{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rougeScores(genSummary, refSummary):\n",
    "    genTotal, refTotal, intersection = 0., 0., 0.\n",
    "    for token in list(set(list(refSummary.keys()) + list(genSummary.keys()) )):\n",
    "        intersection += min(refSummary[token], genSummary[token])\n",
    "        refTotal += refSummary[token]\n",
    "        genTotal += genSummary[token]\n",
    "\n",
    "    recall = intersection / refTotal if refTotal > 0. else 0.\n",
    "    prec   = intersection / genTotal if genTotal > 0. else 0.\n",
    "    f1 = (2. * recall * prec) / (recall + prec) if (recall + prec) > 0. else 0.\n",
    "    \n",
    "    return recall, prec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstmRegressor(nn.Module):  # inheriting from nn.Module!\n",
    "    # calls the init function of nn.Module.  Dont get confused by syntax, always do it in an nn.Module\n",
    "    def __init__(self, input_size, outputsize, nunits, nlayers, sent_size, batch_size):        \n",
    "        super(lstmRegressor, self).__init__()\n",
    "        self.nunits = nunits\n",
    "        self.nlayers = nlayers\n",
    "        self.sent_size = sent_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        self.lstmlayer = nn.LSTM(nunits, nunits, num_layers=self.nlayers)        \n",
    "        self.linearlayer= nn.Linear(nunits, nunits)\n",
    "        \n",
    "        self.dense1_bn = nn.BatchNorm1d(nunits * 2)\n",
    "        \n",
    "        self.outputlayer = nn.Linear(nunits * 2, outputsize)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (autograd.Variable(torch.zeros(self.sent_size, self.batch_size, self.nunits)),\n",
    "                autograd.Variable(torch.zeros(self.sent_size, self.batch_size, self.nunits)))\n",
    "    \n",
    "    def forward(self, sent_embed, summ_embed):\n",
    "        hiddenlayer0 = self.linearlayer(sent_embed)\n",
    "        \n",
    "        out, hiddenlayer = self.lstmlayer(summ_embed, self.hidden)\n",
    "        hiddenlayer1 = self.linearlayer(out[-1])\n",
    "        # Concatenates the layers into (600, 2)\n",
    "        catlayer = torch.cat((hiddenlayer0, hiddenlayer1), 1)\n",
    "        \n",
    "        return self.outputlayer(self.dense1_bn(catlayer))\n",
    "\n",
    "def buildPredSummary(df, summary, sentence_emb, curr_pred_emb, action, select_index, sent_index):\n",
    "    if action.select(1, select_index).tolist()[0] == 1:\n",
    "        sum_len =  curr_pred_emb.size()[0]\n",
    "        summary = summary + ' ' + df['sentence'][sent_index]\n",
    "        curr_pred_emb = torch.cat([curr_pred_emb[1:sum_len, :], sentence_emb], 0)\n",
    "        return curr_pred_emb, summary\n",
    "    \n",
    "    else:\n",
    "        return curr_pred_emb, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.read_csv('/home/francisco/GitHub/DQN-Event-Summarization/data/sif/train_000_0.csv')\n",
    "\n",
    "# Initializing stuff\n",
    "\n",
    "SKIP = 0\n",
    "SELECT = 1\n",
    "\n",
    "true_summary = sdf['summary'][0]\n",
    "ts_tokenized = Counter(true_summary.split(\" \"))\n",
    "\n",
    "nepochs = 500\n",
    "lrate = 0.01\n",
    "momentum_rate = 0.8\n",
    "\n",
    "outputdim = 2\n",
    "batchsize = 1\n",
    "sent_size = 1\n",
    "sif_emb_d = 300\n",
    "nhiddenlayers = 1\n",
    "predsummary_size = 45\n",
    "\n",
    "rand_rate = 1.0\n",
    "decay_rate = 0.05\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "nsentences = sdf.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; f1 = 0.173\n"
     ]
    }
   ],
   "source": [
    "t0 = time.clock()\n",
    "model = lstmRegressor(sent_size, outputdim, sif_emb_d, nhiddenlayers, predsummary_size, batchsize)\n",
    "\n",
    "# swap to ADAM\n",
    "optimizer = optim.Adam(model.parameters(), lr=lrate)\n",
    "\n",
    "lossf = {'loss': [], 'sent_idx': [], 'epoch': [], 'action': [], 'f1': [], 'optpred': [], 'rouge_delta':[]}\n",
    "for epoch in range(nepochs):\n",
    "    # reset embeddings and summary at the start of training\n",
    "    f1_t0 = 0.\n",
    "    curr_summary = ''\n",
    "    predsummary_emb = torch.from_numpy(np.zeros((predsummary_size, sif_emb_d))).float()\n",
    "    \n",
    "    for sent_index in range(nsentences):        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # The embeddings start on the 5th column (index 4)\n",
    "        sent_emb = torch.FloatTensor(\n",
    "            sdf[sdf.columns[4:]].values[sent_index, :].reshape(1, sif_emb_d)\n",
    "        )\n",
    "\n",
    "        train_ys = torch.from_numpy(np.asarray([0]).reshape(1, 1)).float()\n",
    "        action = torch.from_numpy(np.asarray([0, 0]).reshape(1,2)).int()\n",
    "\n",
    "        rouge_preds = model(\n",
    "                autograd.Variable(sent_emb), \n",
    "                autograd.Variable(predsummary_emb.view(predsummary_size, batchsize, -1)) \n",
    "        )\n",
    "\n",
    "        qMax, qIndx = rouge_preds.max(dim=1)\n",
    "\n",
    "        if np.random.uniform() < rand_rate and rand_rate > 0:\n",
    "            # Randomly choosing either 0 or 1 some percent of the time\n",
    "            qIndx = np.random.randint(0, 2, 1)[0]\n",
    "\n",
    "        action[:, qIndx.data[0]] = 1\n",
    "        action[:, abs(qIndx.data[0] - 1)] = 0\n",
    "        \n",
    "        predQonActions = torch.masked_select(rouge_preds, autograd.Variable(action.byte()))\n",
    "        # building the summary and capturing the embedding\n",
    "        # without a history model doesn't make a lot of sense\n",
    "        # not clear what's happening...\n",
    "        # concatenate summary embedding to input or try separate joining layer like before\n",
    "        # Worth looking at rougue of each sentence...calculate f1 for each sentence to find out\n",
    "        # might help figure out what's going on...\n",
    "        predsummary_emb, curr_summary = buildPredSummary(\n",
    "                                             sdf, \n",
    "                                             curr_summary, \n",
    "                                             sent_emb, \n",
    "                                             predsummary_emb, \n",
    "                                             action, \n",
    "                                             SELECT, \n",
    "                                             sent_index\n",
    "                                        )\n",
    "        recall, prec, f1 = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))\n",
    "        \n",
    "        # Backward part\n",
    "        rouge_delta = f1 - f1_t0\n",
    "        train_ys[0] = rouge_delta\n",
    "        loss = criterion(predQonActions, autograd.Variable(train_ys))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lossf['loss'].append(loss.data[0])\n",
    "        lossf['sent_idx'].append(sent_index)\n",
    "        lossf['epoch'].append(epoch)\n",
    "        lossf['action'].append(qIndx.data[0])\n",
    "        lossf['f1'].append(f1)\n",
    "        lossf['optpred'].append(predQonActions.data[0])\n",
    "        lossf['rouge_delta'].append(rouge_delta)\n",
    "\n",
    "        # Storing last round\n",
    "        f1_t0 = f1\n",
    "        \n",
    "#         if epoch == 1:\n",
    "#             print(predsummary_emb[40:45, 0:5])\n",
    "    \n",
    "    if rand_rate > 0:\n",
    "        rand_rate -= decay_rate\n",
    "        \n",
    "    if (epoch % 100) == 0:\n",
    "        print('epoch %i; f1 = %.3f' % (epoch, f1))\n",
    "\n",
    "print(\"training complete...runtime = %.2f minutes\" %  ((time.clock() - t0)/60.) ) \n",
    "\n",
    "# Making the performance data a dataframe\n",
    "perf = pd.DataFrame(lossf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf[perf['sent_idx'] == perf['sent_idx'].max()].plot(\n",
    "    x='epoch', y='loss', c='red',\n",
    "    grid=True,\n",
    "    figsize=(12, 6),\n",
    "    title='Loss value across training'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "perf[perf['sent_idx'] == perf['sent_idx'].max()].plot(\n",
    "    x='epoch', y='f1',\n",
    "    grid=True,\n",
    "    figsize=(12, 6),\n",
    "    ylim=[0, 1],\n",
    "    title='f1-score across training'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead3 = ' '.join(sdf['sentence'][0:3])\n",
    "\n",
    "finalsummary = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))\n",
    "baseline = rougeScores(ts_tokenized, Counter(lead3.split(\" \")))\n",
    "\n",
    "print(\"lead-3  recall = %.3f; precision = %.3f; f1-score = %.3f \" % (baseline[0], baseline[1], baseline[2]))\n",
    "\n",
    "print(\"learned recall = %.3f; precision = %.3f; f1-score = %.3f \" % (finalsummary[0], finalsummary[1], finalsummary[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
