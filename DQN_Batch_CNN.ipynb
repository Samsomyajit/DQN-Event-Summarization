{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : ..\n",
       "  2 : Code\n",
       "  3 : .\n",
       "  4 : DQN_Batch_CNN.ipynb\n",
       "  5 : data\n",
       "  6 : .gitignore\n",
       "  7 : .git\n",
       "  8 : Presentation\n",
       "  9 : README.md\n",
       "  10 : .ipynb_checkpoints\n",
       "  11 : Paper\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths.dir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'os'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'optim'\n",
    "-- require 'cunn'\n",
    "-- require 'cunnx'\n",
    "-- require 'cutorch'\n",
    "require 'parallel'\n",
    "\n",
    "dl = require 'dataload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...Utils file loaded\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "...Utils file loaded\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dofile(\"Code/utils.lua\")\n",
    "dofile(\"Code/utilsNNbatch.lua\")\n",
    "dofile(\"Code/Utils/load_cnn.lua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputpath = '/home/francisco/GitHub/DQN-Event-Summarization/data/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.setnumthreads(torch.getnumthreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries, sentences, trueSummaries = loadCNN(outputpath, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20001\n",
    "learning_rate=1e-5\n",
    "embDim = 50\n",
    "gamma=0\n",
    "batch_size = 25\n",
    "mem_multiplier = 1\n",
    "cuts = 4\n",
    "endexplorerate=0.8\n",
    "base_explore_rate=0.1\n",
    "nepochs = 100\n",
    "epsilon = 1\n",
    "print_perf=false\n",
    "adapt=false\n",
    "adapt_lambda = 0.25\n",
    "usecuda= false\n",
    "seedval= 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...running on CPU\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if usecuda then\n",
    "    Tensor = torch.CudaTensor\n",
    "    LongTensor = torch.CudaLongTensor   \n",
    "    ByteTensor = torch.CudaByteTensor\n",
    "    maskLayer = nn.MaskedSelect():cuda()\n",
    "    print(\"...running on GPU\")\n",
    "else\n",
    "    Tensor = torch.Tensor\n",
    "    LongTensor = torch.LongTensor\n",
    "    ByteTensor = torch.ByteTensor\n",
    "    maskLayer = nn.MaskedSelect()\n",
    "    print(\"...running on CPU\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running bag-of-words model to learn f1\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "k = #trueSummaries\n",
    "n = queries[1]:size(1)\n",
    "q = queries[1]:size(2)\n",
    "n_s = #queries\n",
    "\n",
    "optimParams = { learningRate = learning_rate }\n",
    "delta = cuts / nepochs\n",
    "end_baserate = torch.round(nepochs * endexplorerate )\n",
    "\n",
    "\n",
    "qTokens = {}\n",
    "for i=1, n do\n",
    "    qTokens[i] = Tokenize({trueSummaries[1][i]:totable()}, false)[1]\n",
    "end\n",
    "\n",
    "-- Building the model\n",
    "model = buildModel('bow', vocab_size, embDim, 'f1', adapt, usecuda)\n",
    "params, gradParams = model:getParameters()\n",
    "\n",
    "if adapt then \n",
    "    criterion = nn.ParallelCriterion():add(nn.MSECriterion()):add(nn.BCECriterion())\n",
    "    criterion[\"weights\"] = {1, adapt_lambda}\n",
    "else \n",
    "    criterion = nn.MSECriterion()\n",
    "end \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabsize = 0\n",
    "for i=1, 124 do\n",
    "    vocabsize = math.max(queries[i]:max(), sentences[i]:max(), trueSummaries[i]:max(), vocabsize)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running model with 500 queries and 125 sentences\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(string.format(\"Running model with %i queries and %i sentences\", n, n_s))\n",
    "qValues = {}\n",
    "qActions = {}\n",
    "qPreds = {}\n",
    "rewards = {}\n",
    "lossfull = {}\n",
    "rouguef1 = {}\n",
    "rougue_scores = {}\n",
    "\n",
    "totalPredsummary = LongTensor(n, n_s * k):fill(0)\n",
    "\n",
    "memfull = false\n",
    "curr_memsize = 0\n",
    "memsize = n * n_s * mem_multiplier\n",
    "queryMemory = Tensor(memsize, q):fill(0)\n",
    "qActionMemory = Tensor(memsize, 2):fill(0)\n",
    "predSummaryMemory = Tensor(memsize, n_s * k):fill(0)\n",
    "sentenceMemory = Tensor(memsize, k):fill(0)\n",
    "sentencetp1Memory  = Tensor(memsize, k):fill(0)\n",
    "predSummarytp1Memory = Tensor(memsize, n_s * k):fill(0)\n",
    "qPredsMemory = Tensor(memsize, 2):fill(0)\n",
    "qValuesMemory = Tensor(memsize, 1):fill(0)\n",
    "rewardMemory = Tensor(memsize, 1):fill(0)\n",
    "totalPreds = Tensor(n, 1):fill(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i = 1, n_s do\n",
    "    qPreds[i] = Tensor(n, 2):fill(0) \n",
    "    qValues[i] = Tensor(n, 1):fill(0)\n",
    "    qActions[i] = Tensor(n, 2):fill(0)\n",
    "    rewards[i] = Tensor(n, 1):fill(0)\n",
    "    rougue_scores[i] = Tensor(n, 1):fill(0)\n",
    "    if adapt then\n",
    "        regPreds[i] = Tensor(n, 1):fill(0)\n",
    "    end        \n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i=1, n_s do\n",
    "    qPreds[i]:fill(0)\n",
    "    qValues[i]:fill(0)\n",
    "    qActions[i]:fill(0)\n",
    "    rewards[i]:fill(0)\n",
    "    rougue_scores[i]:fill(0)\n",
    "    totalPredsummary:fill(0)\n",
    "    if adapt then\n",
    "        regMemory[i]:fill(0)\n",
    "    end        \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalPreds:fill(0)\n",
    "start_row = 1\n",
    "end_row = batch_size\n",
    "c = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "[string \"for start_row=1, n, batch_size do            ...\"]:7: inconsistent tensor size at /tmp/luarocks_torch-scm-1-9784/torch7/lib/TH/generic/THTensorCopy.c:17\nstack traceback:\n\t[C]: in function 'copy'\n\t[string \"for start_row=1, n, batch_size do            ...\"]:7: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/francisco/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/francisco/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/francisco/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...francisco/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...francisco/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...francisco/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/francisco/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405d50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"for start_row=1, n, batch_size do            ...\"]:7: inconsistent tensor size at /tmp/luarocks_torch-scm-1-9784/torch7/lib/TH/generic/THTensorCopy.c:17\nstack traceback:\n\t[C]: in function 'copy'\n\t[string \"for start_row=1, n, batch_size do            ...\"]:7: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/francisco/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/francisco/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/francisco/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...francisco/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...francisco/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...francisco/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/francisco/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405d50"
     ]
    }
   ],
   "source": [
    "for start_row=1, n, batch_size do                 \n",
    "    end_row = c * batch_size\n",
    "\n",
    "    if end_row > n then \n",
    "        end_row = n\n",
    "    end\n",
    "    totalPreds[{{start_row, end_row}}]:copy(\n",
    "        model:forward({\n",
    "            queries[i][{{start_row, end_row}}], \n",
    "            sentences[i][{{start_row, end_row}}], \n",
    "            totalPredsummary[{{start_row, end_row}}]\n",
    "        })\n",
    "    )\n",
    "    c = c + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 25\n",
       " 19\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "  25\n",
       " 662\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       "    25\n",
       " 15625\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[i][{{start_row, end_row}}]:size(), sentences[i][{{start_row, end_row}}]:size(),  totalPredsummary[{{start_row, end_row}}]:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
