{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rougeScores(genSummary, refSummary):\n",
    "    genTotal, refTotal, intersection = 0, 0, 0\n",
    "    for token in list(set(list(refSummary.keys()) + list(genSummary.keys()) )):\n",
    "        intersection += min(refSummary[token], genSummary[token])\n",
    "        refTotal += refSummary[token]\n",
    "        genTotal += genSummary[token]\n",
    "\n",
    "    recall = intersection / float(refTotal) if float(refTotal) > 0 else 0\n",
    "    prec   = intersection / float(genTotal) if float(genTotal) > 0 else 0\n",
    "    f1 = (2 * recall * prec) / (recall + prec) if (recall + prec) > 0 else 0\n",
    "    \n",
    "    return recall, prec, f1\n",
    "\n",
    "class BoWRegressor(nn.Module):  # inheriting from nn.Module!\n",
    "    # calls the init function of nn.Module.  Dont get confused by syntax, always do it in an nn.Module\n",
    "    def __init__(self, input_size, outputsize):        \n",
    "        super(BoWRegressor, self).__init__()        \n",
    "        self.linear = nn.Linear(input_size, outputsize)\n",
    "        \n",
    "    def forward(self, bow_vec):\n",
    "        return F.sigmoid(self.linear(bow_vec))\n",
    "\n",
    "\n",
    "def buildPredSummary(df, curr_summary, sentence_emb, curr_pred_emb, action, select_index, sent_index):\n",
    "    if sent_index==0 and action.select(1, select_index).tolist()[0] == 1:\n",
    "        return sentence_emb, curr_summary + df['sentence'][select_index]\n",
    "\n",
    "    if action.select(1, select_index).tolist()[0] == 1:\n",
    "        return (curr_pred_emb + sentence_emb)/2., curr_summary + ' ' + df['sentence'][select_index]\n",
    "    \n",
    "    else:\n",
    "        return sentence_emb, curr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.read_csv('/home/francisco/GitHub/DQN-Event-Summarization/data/sif/train_000_0.csv')\n",
    "\n",
    "# Initializing stuff\n",
    "\n",
    "SKIP = 0\n",
    "SELECT = 1\n",
    "\n",
    "true_summary = sdf['summary'][0]\n",
    "ts_tokenized = Counter(true_summary.split(\" \"))\n",
    "\n",
    "nepochs = 1000\n",
    "emb_d = 300\n",
    "outputdim = 2\n",
    "rand_rate = 0.75\n",
    "\n",
    "lrate = 0.1\n",
    "decay_rate = 0.025\n",
    "\n",
    "model = BoWRegressor(emb_d, outputdim)\n",
    "model.zero_grad()\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lrate)\n",
    "nsentences = sdf.index.max()\n",
    "\n",
    "lossf = {'loss': [], 'sent_idx': [], 'epoch': [], 'action': [], 'f1': []}\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # reset embeddings and summary at the start of training\n",
    "    predsummary_emb = torch.from_numpy(np.zeros((1, emb_d))).float()\n",
    "    curr_summary = ''\n",
    "    f1_t0 = 0.\n",
    "    \n",
    "    for sent_index in range(nsentences):\n",
    "        # The embeddings start on the 5th column (index 4)\n",
    "        train_xs = torch.FloatTensor(sdf[sdf.columns[4:]].values[sent_index,:].reshape(1, emb_d))\n",
    "        train_ys = torch.from_numpy(np.asarray([0, 0]).reshape(1,2)).float()\n",
    "        action_ys = torch.from_numpy(np.asarray([0]).reshape(1,1)).float()\n",
    "        action = torch.from_numpy(np.asarray([0, 0]).reshape(1,2)).int()\n",
    "\n",
    "        rouge_preds = model(autograd.Variable(train_xs))\n",
    "        \n",
    "        qMax, qIndx = rouge_preds.max(dim=1)\n",
    "\n",
    "        if np.random.uniform() > rand_rate and rand_rate > 0:\n",
    "            # Randomly choosing either 0 or 1 some percent of hte time\n",
    "            qIndx = np.random.randint(0, 2, 1)[0]\n",
    "\n",
    "        action[:, qIndx.data[0]] = 1\n",
    "        action[:, abs(qIndx.data[0] - 1)] = 0\n",
    "        \n",
    "        # building the summary and capturing the embedding\n",
    "        predsummary_emb, curr_summary = buildPredSummary(\n",
    "                                             sdf, \n",
    "                                             curr_summary, \n",
    "                                             train_xs, \n",
    "                                             predsummary_emb, \n",
    "                                             action, \n",
    "                                             SELECT, \n",
    "                                             sent_index\n",
    "                                        )\n",
    "        recall, prec, f1 = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))\n",
    "        \n",
    "        # Backward part\n",
    "        predQonActions = torch.masked_select(rouge_preds, autograd.Variable(action.byte()))\n",
    "        action_ys[0] = f1 - f1_t0\n",
    "        \n",
    "#        # Change in rouge-f1\n",
    "        train_ys[:, qIndx.data[0]] = f1 - f1_t0\n",
    "        train_ys[:, abs(qIndx.data[0]-1)] = 0.\n",
    "\n",
    "        loss = criterion(rouge_preds, autograd.Variable(train_ys))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lossf['loss'].append(loss.data[0])\n",
    "        lossf['sent_idx'].append(sent_index)\n",
    "        lossf['epoch'].append(epoch)\n",
    "        lossf['action'].append(qIndx.data[0])\n",
    "        lossf['f1'].append(f1)\n",
    "\n",
    "        # Storing last round\n",
    "        f1_t0 = f1 - f1_t0\n",
    "        \n",
    "    rand_rate -= decay_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perf = pd.DataFrame(lossf)\n",
    "\n",
    "perf.plot(y='loss', figsize=(12, 6))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.DataFrame(lossf)\n",
    "\n",
    "perf.plot(y='action', figsize=(12, 6))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead3 = ' '.join(sdf['sentence'][0:3])\n",
    "\n",
    "finalsummary = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))\n",
    "baseline = rougeScores(ts_tokenized, Counter(lead3.split(\" \")))\n",
    "\n",
    "print(\"lead-3  recall = %.3f; precision = %.3f; f1-score = %.3f \" % (baseline[0], baseline[1], baseline[2]))\n",
    "\n",
    "print(\"learned recall = %.3f; precision = %.3f; f1-score = %.3f \" % (finalsummary[0], finalsummary[1], finalsummary[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lrate)\n",
    "nsentences = sdf.index.max()\n",
    "\n",
    "lossf = {'loss': [], 'sent_idx': [], 'epoch': [], 'action': [], 'f1': []}\n",
    "epoch = 0\n",
    "sent_index = 0\n",
    "model.zero_grad()\n",
    "    \n",
    "# reset embeddings and summary at the start of training\n",
    "predsummary_emb = torch.from_numpy(np.zeros((1, emb_d))).float()\n",
    "curr_summary = ''\n",
    "f1_t0 = 0.\n",
    "    \n",
    "# The embeddings start on the 5th column (index 4)\n",
    "train_xs = torch.FloatTensor(sdf[sdf.columns[4:]].values[sent_index,:].reshape(1, emb_d))\n",
    "train_ys = torch.from_numpy(np.asarray([0, 0]).reshape(1,2)).float()\n",
    "action_ys = torch.from_numpy(np.asarray([0]).reshape(1,1)).float()\n",
    "action = torch.from_numpy(np.asarray([0, 0]).reshape(1,2)).int()\n",
    "\n",
    "rouge_preds = model(autograd.Variable(train_xs))\n",
    "\n",
    "qMax, qIndx = rouge_preds.max(dim=1)\n",
    "\n",
    "action[:, qIndx.data[0]] = 1\n",
    "action[:, abs(qIndx.data[0] - 1)] = 0\n",
    "\n",
    "# building the summary and capturing the embedding\n",
    "predsummary_emb, curr_summary = buildPredSummary(\n",
    "                                     sdf, \n",
    "                                     curr_summary, \n",
    "                                     train_xs, \n",
    "                                     predsummary_emb, \n",
    "                                     action, \n",
    "                                     SELECT,\n",
    "                                     sent_index\n",
    "                                )\n",
    "\n",
    "recall, prec, f1 = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward part\n",
    "\n",
    "predQonActions = torch.masked_select(rouge_preds, autograd.Variable(action.byte()))\n",
    "action_ys[0] = f1 - f1_t0\n",
    "\n",
    "# Storing last round\n",
    "f1_t0 = f1 - f1_t0\n",
    "\n",
    "#        # Change in rouge-f1\n",
    "train_ys[:, qIndx.data[0]] = f1 - f1_t0\n",
    "train_ys[:, abs(qIndx.data[0]-1)] = 0.\n",
    "\n",
    "loss = criterion(rouge_preds, autograd.Variable(train_ys))\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "lossf['loss'].append(loss.data[0])\n",
    "lossf['sent_idx'].append(sent_index)\n",
    "lossf['epoch'].append(epoch)\n",
    "lossf['action'].append(qIndx.data[0])\n",
    "lossf['f1'].append(f1)\n",
    "\n",
    "rand_rate -= decay_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mse(rouge_preds, autograd.Variable(train_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = action.byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optQ = torch.masked_select(rouge_preds, autograd.Variable(action.byte()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dl.TensorLoader({\n",
    "                    queryMemory[{{1, memrows}}], \n",
    "                    sentenceMemory[{{1, memrows}}], \n",
    "                    predSummaryMemory[{{1, memrows}}], \n",
    "                    qPredsMemory[{{1, memrows}}], \n",
    "                    ByteTensor(memrows, 2):copy(qActionMemory[{{1, memrows}}]), \n",
    "                    qValuesMemory[{{1, memrows}}],\n",
    "                    sentencetp1Memory[{{1, memrows}}],\n",
    "                    predSummarytp1Memory[{{1, memrows}}]                    \n",
    "                    }, \n",
    "                rewardMemory[{{1, memrows}}]\n",
    " )\n",
    "     \n",
    "for k, xin, reward in dataloader:sampleiter(batch_size, memsize) do\n",
    "        local function feval(params)\n",
    "            gradParams:zero()\n",
    "                model:forget()\n",
    "                    # Predicting previous state\n",
    "                predtp1 = model:forward({xin[1], xin[7], xin[8]})\n",
    "                predtp1max, _ = torch.max(predtp1, 2)\n",
    "                model:forget()\n",
    "                    # Predicting current state f(query, sentence, current summary)\n",
    "                predt = model:forward({xin[1], xin[2], xin[3]})\n",
    "                    # reward value plus the expected future state gainn\n",
    "                y_j = reward + (gamma * predtp1max) \n",
    "                    # prediction and binary selection mask\n",
    "                predQOnActions = maskLayer:forward({predt, xin[5]}) \n",
    "                    #  calculate loss\n",
    "                lossf = criterion:forward(predQOnActions, y_j )\n",
    "                    # backprop\n",
    "                gradOutput = criterion:backward(predQOnActions, y_j)\n",
    "                gradMaskLayer = maskLayer:backward({predt, xin[5]}, gradOutput)\n",
    "                model:backward({xin[1], xin[2], xin[3]}, gradMaskLayer[1])\n",
    "            return lossf, gradParams\n",
    "        end\n",
    "        --- optim.rmsprop returns \\theta, f(\\theta):= loss function\n",
    "         _, lossv  = optim.rmsprop(feval, params, optimParams)\n",
    "        loss[c] = lossv[1]\n",
    "        c = c + 1\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead3 = ' '.join(sdf['sentence'][0:3])\n",
    "\n",
    "finalsummary = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))\n",
    "baseline = rougeScores(ts_tokenized, Counter(lead3.split(\" \")))\n",
    "\n",
    "print(\"lead-3  recall = %.3f; precision = %.3f; f1-score = %.3f \" % (baseline[0], baseline[1], baseline[2]))\n",
    "\n",
    "print(\"learned recall = %.3f; precision = %.3f; f1-score = %.3f \" % (finalsummary[0], finalsummary[1], finalsummary[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(sdf['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
