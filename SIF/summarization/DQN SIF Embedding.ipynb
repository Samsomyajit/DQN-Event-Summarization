{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rougeScores(genSummary, refSummary):\n",
    "    genTotal, refTotal, intersection = 0., 0., 0.\n",
    "    for token in list(set(list(refSummary.keys()) + list(genSummary.keys()) )):\n",
    "        intersection += min(refSummary[token], genSummary[token])\n",
    "        refTotal += refSummary[token]\n",
    "        genTotal += genSummary[token]\n",
    "\n",
    "    recall = intersection / refTotal if refTotal > 0. else 0.\n",
    "    prec   = intersection / genTotal if genTotal > 0. else 0.\n",
    "    f1 = (2. * recall * prec) / (recall + prec) if (recall + prec) > 0. else 0.\n",
    "    \n",
    "    return recall, prec, f1\n",
    "\n",
    "class BoWRegressor(nn.Module):  # inheriting from nn.Module!\n",
    "    # calls the init function of nn.Module.  Dont get confused by syntax, always do it in an nn.Module\n",
    "    def __init__(self, input_size, outputsize):        \n",
    "        super(BoWRegressor, self).__init__()        \n",
    "        self.linear = nn.Linear(input_size, outputsize)\n",
    "        \n",
    "    def forward(self, bow_vec):\n",
    "        return self.linear(bow_vec)\n",
    "#         return F.sigmoid(self.linear(bow_vec))\n",
    "\n",
    "\n",
    "def buildPredSummary(df, summary, sentence_emb, curr_pred_emb, action, select_index, sent_index):\n",
    "    if sent_index==0 and action.select(1, select_index).tolist()[0] == 1:\n",
    "        return sentence_emb, summary + df['sentence'][sent_index]\n",
    "\n",
    "    if action.select(1, select_index).tolist()[0] == 1:\n",
    "        # This uses the avergae of the embeddings from the previous \n",
    "        # steps...but maybe we should try something different\n",
    "        return curr_pred_emb * sentence_emb, curr_summary + ' ' + df['sentence'][sent_index]\n",
    "    \n",
    "    else:\n",
    "        return sentence_emb, curr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.read_csv('/home/francisco/GitHub/DQN-Event-Summarization/data/sif/train_000_0.csv')\n",
    "\n",
    "# Initializing stuff\n",
    "\n",
    "SKIP = 0\n",
    "SELECT = 1\n",
    "\n",
    "true_summary = sdf['summary'][0]\n",
    "ts_tokenized = Counter(true_summary.split(\" \"))\n",
    "\n",
    "nepochs = 1000\n",
    "sif_emb_d = 300\n",
    "input_dim = 600\n",
    "\n",
    "outputdim = 2\n",
    "rand_rate = 0.50\n",
    "decay_rate = 0.025\n",
    "\n",
    "lrate = 0.01\n",
    "momentum_rate = 0.8\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "nsentences = sdf.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWRegressor(input_dim, outputdim)\n",
    "model.zero_grad()\n",
    "\n",
    "# swap to ADAM\n",
    "optimizer = optim.Adam(model.parameters(), lr=lrate)\n",
    "\n",
    "lossf = {'loss': [], 'sent_idx': [], 'epoch': [], 'action': [], 'f1': [], 'optpred': [], 'rouge_delta':[]}\n",
    "for epoch in range(nepochs):\n",
    "    # reset embeddings and summary at the start of training\n",
    "    f1_t0 = 0.\n",
    "    curr_summary = ''\n",
    "    predsummary_emb = torch.from_numpy(np.zeros((1, sif_emb_d))).float()\n",
    "    \n",
    "    for sent_index in range(nsentences):        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # The embeddings start on the 5th column (index 4)\n",
    "        sent_emb = torch.FloatTensor(sdf[sdf.columns[4:]].values[sent_index, :].reshape(1, sif_emb_d))\n",
    "        train_xs = torch.cat([sent_emb, predsummary_emb], dim=1)\n",
    "        train_ys = torch.from_numpy(np.asarray([0]).reshape(1, 1)).float()\n",
    "        action = torch.from_numpy(np.asarray([0, 0]).reshape(1,2)).int()\n",
    "\n",
    "        rouge_preds = model(autograd.Variable(train_xs))\n",
    "        qMax, qIndx = rouge_preds.max(dim=1)\n",
    "\n",
    "        if np.random.uniform() > rand_rate and rand_rate > 0:\n",
    "            # Randomly choosing either 0 or 1 some percent of hte time\n",
    "            qIndx = np.random.randint(0, 2, 1)[0]\n",
    "\n",
    "        action[:, qIndx.data[0]] = 1\n",
    "        action[:, abs(qIndx.data[0] - 1)] = 0\n",
    "        \n",
    "        # building the summary and capturing the embedding\n",
    "        # without a history model doesn't make a lot of sense\n",
    "        # not clear what's happening...\n",
    "        # concatenate summary embedding to input or try separate joining layer like before\n",
    "        # Worth looking at rougue of each sentence...calculate f1 for each sentence to find out\n",
    "            # might help figure out what's going on...\n",
    "        predsummary_emb, curr_summary = buildPredSummary(\n",
    "                                             sdf, \n",
    "                                             curr_summary, \n",
    "                                             sent_emb, \n",
    "                                             predsummary_emb, \n",
    "                                             action, \n",
    "                                             SELECT, \n",
    "                                             sent_index\n",
    "                                        )\n",
    "\n",
    "        recall, prec, f1 = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))\n",
    "        \n",
    "        # Backward part\n",
    "        predQonActions = torch.masked_select(rouge_preds, autograd.Variable(action.byte()))\n",
    "        rouge_delta = f1 - f1_t0\n",
    "        \n",
    "        # Change in rouge-f1\n",
    "        train_ys[0] = rouge_delta\n",
    "\n",
    "        loss = criterion(predQonActions, autograd.Variable(train_ys))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lossf['loss'].append(loss.data[0])\n",
    "        lossf['sent_idx'].append(sent_index)\n",
    "        lossf['epoch'].append(epoch)\n",
    "        lossf['action'].append(qIndx.data[0])\n",
    "        lossf['f1'].append(f1)\n",
    "        lossf['optpred'].append(predQonActions.data[0])\n",
    "        lossf['rouge_delta'].append(rouge_delta)\n",
    "\n",
    "        # Storing last round\n",
    "        f1_t0 = f1 - f1_t0\n",
    "        \n",
    "    rand_rate -= decay_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.DataFrame(lossf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf[(perf['sent_idx'] == perf['sent_idx'].max() & (perf['action']==0))].plot(x='epoch', y='optpred', figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf[(perf['sent_idx'] == perf['sent_idx'].max() & (perf['action']==1))].plot(x='epoch', y='optpred', figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf[(perf['sent_idx'] == perf['sent_idx'].max() & (perf['action']==0))].plot(x='epoch', y='loss', figsize=(12, 6))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf[(perf['sent_idx'] == perf['sent_idx'].max() & (perf['action']==1))].plot(x='epoch', y='loss', figsize=(12, 6))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perf = pd.DataFrame(lossf)\n",
    "\n",
    "perf[perf['sent_idx'] == perf['sent_idx'].max()].plot(y='loss', figsize=(12, 6))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perf[perf['sent_idx'] == perf['sent_idx'].max()].plot(y='f1', figsize=(12, 6))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf[perf['epoch'] == perf['epoch'].max()].plot(y='action', figsize=(12, 6))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead3 = ' '.join(sdf['sentence'][0:3])\n",
    "\n",
    "finalsummary = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))\n",
    "baseline = rougeScores(ts_tokenized, Counter(lead3.split(\" \")))\n",
    "\n",
    "print(\"lead-3  recall = %.3f; precision = %.3f; f1-score = %.3f \" % (baseline[0], baseline[1], baseline[2]))\n",
    "\n",
    "print(\"learned recall = %.3f; precision = %.3f; f1-score = %.3f \" % (finalsummary[0], finalsummary[1], finalsummary[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "curr_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
