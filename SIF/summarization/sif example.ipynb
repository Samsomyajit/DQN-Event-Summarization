{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import struct\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from tensorflow.core.example import example_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file0 = '/home/francisco/GitHub/cnn-dailymail/finished_files/chunked/train_000.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = sorted(os.listdir('/home/francisco/GitHub/cnn-dailymail/finished_files/chunked/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load word vecs\n",
    "\n",
    "Iterate through chunks of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returnBytes(reader_obj):\n",
    "    len_bytes = reader_obj.read(8)\n",
    "    str_len = struct.unpack('q', len_bytes)[0]\n",
    "    e_s = struct.unpack(\"%ds\" % str_len, reader.read(str_len))\n",
    "    es = e_s[0]\n",
    "    c = example_pb2.Example.FromString(es)\n",
    "    article  = str(c.features.feature['article'].bytes_list.value[0])\n",
    "    abstract = str(c.features.feature['abstract'].bytes_list.value[0])\n",
    "    ab = sent_tokenize(abstract)\n",
    "    clean_article = sent_tokenize(article)\n",
    "    clean_abstract = '. '.join([' '.join(s for s in x.split() if s.isalnum()) for x in ''.join(ab).replace(\"<s>\",\"\").split(\"</s>\")]).strip()    \n",
    "    return clean_abstract, clean_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = open(file0, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab0, ar0 =  returnBytes(reader)\n",
    "ab1, ar1 =  returnBytes(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harry potter star daniel radcliffe gets 20m fortune as he turns 18 monday. young actor says he has no plans to fritter his cash away. radcliffe earnings from first five potter films have been held in trust fund.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append('../src')\n",
    "import data_io, params, SIF_embedding\n",
    "import show_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "wordfile = '/home/francisco/GitHub/SIF/data/glove.840B.300d.txt'   # word vector file, can be downloaded from GloVe website\n",
    "weightfile = '/home/francisco/GitHub/SIF/auxiliary_data/enwiki_vocab_min200.txt' # each line is a word and its frequency\n",
    "weightpara = 1e-3 # the parameter in the SIF weighting scheme, usually in the range [3e-5, 3e-3]\n",
    "rmpc = 0\n",
    "# rmpc = 1 # they usually set 1 ; number of principal components to remove in SIF weighting scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load word vectors\n",
    "(words, We) = data_io.getWordmap(wordfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load word weights\n",
    "word2weight = data_io.getWordWeight(weightfile, weightpara) # word2weight['str'] is the weight for the word 'str'\n",
    "weight4ind = data_io.getWeight(words, word2weight) # weight4ind[i] is the weight for the i-th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "params = params.params()\n",
    "params.rmpc = rmpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = ar0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load sentences\n",
    "x, m = data_io.sentences2idx(sentences, words) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "w = data_io.seq2weight(x, m, weight4ind) # get word weights\n",
    "\n",
    "# get SIF embedding\n",
    "embeddings = SIF_embedding.SIF_embedding(We, x, w, params) # embedding[i,:] is the embedding for sentence i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sentence embeddings\n",
    "sdf = pd.DataFrame(sentences, columns=['sentence'])\n",
    "sdf['summary'] = ab0\n",
    "sdf.ix[1:, 'summary']  = ''\n",
    "emb = pd.DataFrame(embeddings, columns=['emb_%i' % x for x in range(embeddings.shape[1])])\n",
    "sdf = pd.concat([sdf, emb], axis=1)\n",
    "sdf = sdf[[sdf.columns[1], sdf.columns[0]] + sdf.columns[2:].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
