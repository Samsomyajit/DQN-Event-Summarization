{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'optim'\n",
    "require 'io'\n",
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'csvigo'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'\n",
    "\n",
    "dl = require 'dataload'\n",
    "cmd = torch.CmdLine()\n",
    "dofile(\"Code/utils.lua\")\n",
    "dofile(\"Code/utilsNN.lua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datapath ='data/0-output/'\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "LongTensor = torch.LongTensor\n",
    "ByteTensor = torch.ByteTensor\n",
    "\n",
    "use_cuda = false\n",
    "thresh = 0\n",
    "edim = 10\n",
    "metric = 'f1'\n",
    "inputs = loadMetadata(datapath .. \"dqn_metadata.csv\")                                               \n",
    "stoplist = loadStopdata(datapath .. 'stopwordids.csv')\n",
    "adapt = true\n",
    "\n",
    "vocabSize, query_data = initialize_variables(inputs, 20, datapath, 5, 30, stoplist, thresh, use_cuda)\n",
    "\n",
    "model = buildModel('bow', vocabSize, edim, metric, true, use_cuda)\n",
    "\n",
    "criterion = nn.ParallelCriterion():add(nn.MSECriterion()):add(nn.BCECriterion())\n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "query_randomF1 = {}\n",
    "params, gradParams = model:getParameters()\n",
    "\n",
    "query_id = 1\n",
    "\n",
    "\n",
    "sentenceStream = query_data[query_id][1]\n",
    "streamSize = query_data[query_id][2]\n",
    "query = query_data[query_id][3]\n",
    "actions = query_data[query_id][4]\n",
    "exploreDraws = query_data[query_id][5]\n",
    "summaryBuffer = query_data[query_id][6]\n",
    "qValues = query_data[query_id][7]\n",
    "rouge = query_data[query_id][8]\n",
    "actionsOpt = query_data[query_id][9]\n",
    "rougeOpt = query_data[query_id][10]\n",
    "refSummary = query_data[query_id][11]\n",
    "refCounts = query_data[query_id][12]\n",
    "buffer = query_data[query_id][13]\n",
    "\n",
    "maskLayer = nn.MaskedSelect()\n",
    "-- Have to set clear the inputs at the beginning of each scoring round\n",
    "actions:fill(0)\n",
    "actionsOpt:fill(0)\n",
    "rouge:fill(0)\n",
    "rougeOpt:fill(0)\n",
    "qValues:fill(0)\n",
    "summaryBuffer:fill(0)\n",
    "buffer:fill(0)\n",
    "exploreDraws:fill(0)\n",
    "exploreDraws:uniform(0, 1)\n",
    "summary = summaryBuffer:zero():narrow(1, 1, 1) -- summary starts empty\n",
    "\n",
    "i = 1\n",
    "\n",
    "sentence = sentenceStream:narrow(1, i, 1)\n",
    "\n",
    "predTotal = model:forward({sentence, query, summary})\n",
    "predQ = predTotal[1]\n",
    "predReg = predTotal[2]\n",
    "actions = ByteTensor(1, 2):fill(0)\n",
    "\n",
    "if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "    actions[i][SKIP] = 1\n",
    "else\n",
    "    actions[i][SELECT] = 1\n",
    "end\n",
    "\n",
    "predQOnActions = maskLayer:forward({predQ[i], actions[i]}) \n",
    "\n",
    "print('predQ', predQ)\n",
    "print('predReg', predReg)\n",
    "print('actions', actions)\n",
    "print('predQonActions', predQOnActions)\n",
    "\n",
    "reward = torch.zeros(1):fill(0.23):resize(1,1)\n",
    "class = torch.ones(1):resize(1,1)\n",
    "\n",
    "nll = nn.BCECriterion()\n",
    "mse = nn.MSECriterion()\n",
    "pc = nn.ParallelCriterion():add(mse):add(nll)\n",
    "\n",
    "lossf = mse:forward(predQOnActions, reward)\n",
    "print('rmse', lossf)\n",
    "\n",
    "lossf = criterion:forward({predQOnActions, predReg}, {reward, class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predQ[i], actions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predQOnActions, predReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local predQ = model:forward(xinput)\n",
    "local predQOnActions = maskLayer:forward({predQ, actions_in})\n",
    "local lossf = criterion:forward(predQOnActions, reward)\n",
    "local gradOutput = criterion:backward(predQOnActions, reward)\n",
    "local gradMaskLayer = maskLayer:backward({predQ, actions_in}, gradOutput)\n",
    "model:backward(xinput, gradMaskLayer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predTotal = model:forward({sentence, query, summary})\n",
    "predQ = predTotal[1]\n",
    "predReg = predTotal[2]\n",
    "\n",
    "predQOnActions = maskLayer:forward({predQ[i], actions[i]}) \n",
    "lossf = criterion:forward({predQOnActions, predReg}, {reward, class})\n",
    "gradOutput = criterion:backward({predQOnActions, predReg}, {reward, class})\n",
    "gradMaskLayer = maskLayer:backward({predQ, actions}, gradOutput[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradOutput, gradMaskLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model:backward({sentence, query, summary}, gradMaskLayer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model:backward({sentence, query, summary}, gradMaskLayer[1])\n",
    "print('success')\n",
    "\n",
    "-- memory, rougeRecall, rougePrecision, rougeF1, qValues = forwardpass(\n",
    "--                 query_data, query_id, model, 1, 0., \n",
    "--                 metric, thresh, stoplist, use_cuda\n",
    "-- )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "math.randomseed(3)\n",
    "torch.manualSeed(3)\n",
    "\n",
    "-- Building data\n",
    "x = torch.randn(20):resize(10, 2)\n",
    "xhat = x + 0.01 * torch.rand(20):resize(10, 2)\n",
    "b = torch.rand(2, 1)\n",
    "yhat = torch.mm(x, b)  + torch.randn(10)  -- np.dot()\n",
    "n = yhat:size(1)\n",
    "onex = torch.ones(n):resize(n, 1)\n",
    "target = torch.round(nn.Sigmoid():forward(yhat))\n",
    "\n",
    "print(target)\n",
    "\n",
    "-- This is the Logistic\n",
    "LogisticModel = nn.Sequential():add(nn.Linear(2, 1)):add(nn.LogSoftMax())\n",
    "\n",
    "-- This is the linear regression\n",
    "LinearModel = nn.Sequential():add(nn.Linear(2, 2))\n",
    "\n",
    "--- Stacking the models together\n",
    "FullModel = nn.ConcatTable():add(LinearModel):add(LogisticModel)\n",
    "\n",
    "print(\"Logistic Pred:\")\n",
    "pred_log = LogisticModel:forward(x)\n",
    "print(pred_log)\n",
    "\n",
    "print(\"Linear Pred:\")\n",
    "pred_reg = LinearModel:forward(x)\n",
    "print(pred_reg)\n",
    "\n",
    "print(\"Logistic and Linear Pred:\")\n",
    "pred_final = FullModel:forward(x)\n",
    "print(pred_final)\n",
    "\n",
    "nll = nn.BCECriterion()\n",
    "mse = nn.MSECriterion()\n",
    "pc = nn.ParallelCriterion():add(mse):add(nll)\n",
    "\n",
    "print(\"NLL loss:\")\n",
    "nll_loss = nll:forward(pred_log, target)\n",
    "print(nll_loss)\n",
    "\n",
    "print(\"MSE loss:\")\n",
    "mse_loss = mse:forward(pred_reg, xhat)\n",
    "print(nll_loss)\n",
    "\n",
    "print(\"Parallel NLL-MSE loss:\")\n",
    "prl_loss = pc:forward( {pred_reg, pred_log}, {xhat, target} )\n",
    "print(prl_loss)\n",
    "\n",
    "print(\"Parallel Full NLL-MSE loss:\")\n",
    "prl_final = pc:forward(pred_final, {xhat, target})\n",
    "print(prl_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions = torch.ByteTensor(10, 2):fill(0)\n",
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "qTotal  = FullModel:forward(x)\n",
    "qValues = qTotal[1]\n",
    "regValues = qTotal[2]\n",
    "\n",
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "for i=1, qValues:size(1) do\n",
    "    if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "        actions[i][SKIP] = 1\n",
    "    else\n",
    "        actions[i][SELECT] = 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The full backprop without selection is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward = torch.rand(20):resize(10, 2)\n",
    "class = torch.ones(10):resize(10, 1)\n",
    "\n",
    "qTotal  = FullModel:forward(x)\n",
    "qValues = qTotal[1]\n",
    "regValues = qTotal[2]\n",
    "\n",
    "gradOutput = pc:backward(qTotal, {reward, class})\n",
    "print(gradOutput)\n",
    "print(FullModel:backward(x, gradOutput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "math.randomseed(3)\n",
    "torch.manualSeed(3)\n",
    "\n",
    "-- Simulating data\n",
    "x = torch.randn(20):resize(10, 2)\n",
    "xhat = x + 0.01 * torch.rand(20):resize(10, 2)\n",
    "b = torch.rand(2, 1)\n",
    "yhat = torch.mm(x, b)  + torch.randn(10)  -- np.dot()\n",
    "n = yhat:size(1)\n",
    "onex = torch.ones(n):resize(n, 1)\n",
    "target = torch.round(nn.Sigmoid():forward(yhat))\n",
    "\n",
    "-- This is the Logistic\n",
    "LogisticModel = nn.Sequential():add(nn.Linear(2, 1)):add(nn.LogSoftMax())\n",
    "\n",
    "-- This is the linear regression\n",
    "LinearModel = nn.Sequential():add(nn.Linear(2, 2))\n",
    "\n",
    "--- Stacking the models together\n",
    "FullModel = nn.ConcatTable():add(LinearModel):add(LogisticModel)\n",
    "\n",
    "actions = torch.ByteTensor(10, 2):fill(0)\n",
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "for i=1, qValues:size(1) do\n",
    "    if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "        actions[i][SKIP] = 1\n",
    "    else\n",
    "        actions[i][SELECT] = 1\n",
    "    end\n",
    "end\n",
    "\n",
    "nll = nn.BCECriterion()\n",
    "mse = nn.MSECriterion()\n",
    "pc = nn.ParallelCriterion():add(mse):add(nll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop on just the linear model with selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss\t0.40705395688884\t\n",
       " 0.0212  0.0425\n",
       "-0.0799 -0.1597\n",
       " 0.0378  0.0755\n",
       "-0.0423 -0.0844\n",
       "-0.0179 -0.0357\n",
       "-0.0122 -0.0244\n",
       " 0.0286  0.0571\n",
       " 0.0498  0.0995\n",
       " 0.0287  0.0574\n",
       " 0.0298  0.0596\n",
       "[torch.DoubleTensor of size 10x2]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "reward = torch.rand(20):resize(10, 1)\n",
    "class = torch.ones(10):resize(10, 1)\n",
    "\n",
    "qValues  = LinearModel:forward(x)\n",
    "\n",
    "-- Selection\n",
    "predQOnActions = maskLayer:forward({qValues, actions})\n",
    "\n",
    "-- Calculate loss\n",
    "print('loss', mse:forward(predQOnActions, reward))\n",
    "\n",
    "-- Calculate gradients\n",
    "gradOutput = mse:backward(predQOnActions, reward)\n",
    "gradMaskLayer = maskLayer:backward({qValues, actions}, gradOutput)\n",
    "\n",
    "print(LinearModel:backward(x, gradMaskLayer[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop joint model with selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss\t27.917112936544\t\n",
       " 0.0077  0.0153\n",
       "-0.0821 -0.1640\n",
       " 0.0260  0.0519\n",
       "-0.0326 -0.0652\n",
       " 0.0039  0.0077\n",
       "-0.0027 -0.0053\n",
       " 0.0033  0.0066\n",
       " 0.0306  0.0611\n",
       " 0.0354  0.0708\n",
       " 0.0125  0.0249\n",
       "[torch.DoubleTensor of size 10x2]\n",
       "\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = torch.rand(10):resize(10)\n",
    "class = torch.ones(10):resize(10, 1)\n",
    "\n",
    "qTotal  = FullModel:forward(x)\n",
    "qValues = qTotal[1]\n",
    "regValues = qTotal[2]\n",
    "\n",
    "-- Selection part\n",
    "predQOnActions = maskLayer:forward({qValues, actions})\n",
    "\n",
    "-- Calculate loss\n",
    "print('loss', pc:forward({predQOnActions, regValues}, {reward, class}))\n",
    "\n",
    "-- Calculate gradients\n",
    "gradOutput = pc:backward({predQOnActions, regValues}, {reward, class})\n",
    "gradMaskLayer = maskLayer:backward({qValues, actions}, gradOutput[1])\n",
    "\n",
    "-- Backprop on joint model\n",
    "print(FullModel:backward(x, {gradMaskLayer[1], gradOutput[2]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
