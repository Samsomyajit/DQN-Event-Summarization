{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...Utils file loaded\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'optim'\n",
    "require 'io'\n",
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'csvigo'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'\n",
    "\n",
    "dl = require 'dataload'\n",
    "cmd = torch.CmdLine()\n",
    "dofile(\"Code/utils.lua\")\n",
    "dofile(\"Code/utilsNN.lua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running on a subset of 20 observations\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "...query loaded\t\n",
       "Running LSTM model to learn f1\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Using adaptive regularization\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = 'data/0-output/'\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "LongTensor = torch.LongTensor\n",
    "ByteTensor = torch.ByteTensor\n",
    "\n",
    "use_cuda = false\n",
    "\n",
    "thresh = 0\n",
    "edim = 10\n",
    "metric = 'f1'\n",
    "inputs = loadMetadata(datapath .. \"dqn_metadata.csv\")                                               \n",
    "stoplist = loadStopdata(datapath .. 'stopwordids.csv')\n",
    "adapt = true\n",
    "metric ='f1'\n",
    "use_cuda = false\n",
    "embeddingSize = 20\n",
    "\n",
    "nepochs = 2\n",
    "gamma= 0.\n",
    "learning_rate = 0.1\n",
    "epsilon = 1\n",
    "stopwordlist = stopwords \n",
    "mem_size = 100\n",
    "optimParams = { learningRate = learning_rate }\n",
    "\n",
    "vocabSize, query_data = initialize_variables(inputs, 20, datapath, 5, 30, stoplist, thresh, use_cuda)\n",
    "\n",
    "print(\"...query loaded\")\n",
    "model = buildModel(model, vocabSize, embeddingSize, metric, adapt, usecuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "math.randomseed(420)\n",
    "torch.manualSeed(420)\n",
    "criterion = nn.MSECriterion()\n",
    "\n",
    "if adapt then \n",
    "    criterion = nn.ParallelCriterion():add(nn.MSECriterion()):add(nn.BCECriterion())\n",
    "end\n",
    "\n",
    "\n",
    "if use_cuda then\n",
    "    criterion = criterion:cuda()\n",
    "    model = model:cuda()\n",
    "end\n",
    "params, gradParams = model:getParameters()\n",
    "\n",
    "query_id = 1 \n",
    "memory, rougeRecall, rougePrecision, rougeF1, qValues = forwardpass(\n",
    "                query_data, query_id, model, epsilon, gamma, \n",
    "                metric, thresh, stopwordlist, adapt, use_cuda\n",
    ")\n",
    "fullmemory = memory\n",
    "-- Stacking data\n",
    "fullmemory = stackMemory(memory, fullmemory, mem_size, adapt, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- xinput = fullmemory[1]\n",
    "-- reward = fullmemory[2]\n",
    "-- actions_in = fullmemory[3]\n",
    "\n",
    "xinput = memory[1]\n",
    "actions_in = memory[3]\n",
    "reward = memory[2]:resize(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predTotal = model:forward(xinput)\n",
    "predQ = predTotal[1]\n",
    "predReg = predTotal[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 20\n",
       "  2\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 20\n",
       "  2\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 20\n",
       "  1\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 20\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predQ:size(), actions_in:size(), reward:size(), ones:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predQOnActions = maskLayer:forward({predQ, actions_in})\n",
    "\n",
    "ones = torch.ones(predQ:size(1))\n",
    "\n",
    "-- ones = torch.ones(predQ:size(1)):resize(predQ:size(1), 1)\n",
    "lossf = criterion:forward({predQOnActions, predReg}, {reward, ones})\n",
    "\n",
    "gradOutput = criterion:backward({predQOnActions, predReg}, {reward, ones})\n",
    "gradMaskLayer = maskLayer:backward({predQ, actions_in}, gradOutput[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : \n",
       "    {\n",
       "      1 : LongTensor - size: 20x5\n",
       "      2 : LongTensor - size: 20x3\n",
       "      3 : LongTensor - size: 20x30\n",
       "    }\n",
       "  2 : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 20x2\n",
       "      2 : ByteTensor - size: 20x2\n",
       "    }\n",
       "  3 : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 20\n",
       "      2 : DoubleTensor - size: 20x1\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{xinput, gradMaskLayer, gradOutput}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model:backward(xinput, {gradMaskLayer[1], gradOutput[1]} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 32x5\n",
       "  2 : DoubleTensor - size: 32x3\n",
       "  3 : DoubleTensor - size: 32x30\n",
       "}\n",
       "{\n",
       "  1 : DoubleTensor - size: 32x2\n",
       "  2 : DoubleTensor - size: 32x1\n",
       "}\n",
       "32\t\n"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 8x5\n",
       "  2 : DoubleTensor - size: 8x3\n",
       " "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 3 : DoubleTensor - size: 8x30\n",
       "}\n",
       "{\n",
       "  1 : DoubleTensor - size: 8x2\n",
       "  2 : DoubleTensor - size: 8x1\n",
       "}\n",
       "8\t\n"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k, xin, reward in dataloader:sampleiter(batch_size, memsize) do\n",
    "    xinput = xin[1]\n",
    "    actions_in = xin[2]\n",
    "    predTotal = model:forward(xinput)                \n",
    "    \n",
    "    predQ = predTotal[1]\n",
    "    predReg = predTotal[2]\n",
    "    print(xinput, predTotal, predQ:size(1))\n",
    "    \n",
    "    predQOnActions = maskLayer:forward({predQ, actions_in}) \n",
    "\n",
    "    ones = torch.ones(predQ:size(1)):resize(predQ:size(1), 1)\n",
    "    lossf = criterion:forward({predQOnActions, predReg}, {reward, ones})\n",
    "    \n",
    "    gradOutput = criterion:backward({predQOnActions, predReg}, {reward, ones})\n",
    "    gradMaskLayer = maskLayer:backward({predQ, actions_in}, gradOutput[1])\n",
    "    \n",
    "--     model:backward(xinput, {gradMaskLayer[1], gradOutput[1]} )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, xin, reward in dataloader:sampleiter(batch_size, memsize) do\n",
    "    xinput = xin[1]\n",
    "    actions_in = xin[2]\n",
    "\n",
    "    if use_cuda then\n",
    "        maskLayer = nn.MaskedSelect():cuda()\n",
    "        actions_in = torch.CudaByteTensor(#actions_in):copy(actions_in)\n",
    "    end\n",
    "\n",
    "    local function feval(params)\n",
    "        gradParams:zero()\n",
    "        if adapt then\n",
    "            local predTotal = model:forward(xinput)                \n",
    "            local predQ = predTotal[1]\n",
    "            local predReg = predTotal[2]\n",
    "            local predQOnActions = maskLayer:forward({predQ, actions_in}) \n",
    "            local ones = torch.ones(predQ:size(1)):resize(predQ:size(1))\n",
    "            lossf = criterion:forward({predQOnActions, predReg}, {reward, ones})\n",
    "            local gradOutput = criterion:backward({predQOnActions, predReg}, {reward, ones})\n",
    "            local gradMaskLayer = maskLayer:backward({predQ, actions_in}, gradOutput[1])\n",
    "            print(#gradMaskLayer[2], #gradOutput[1])\n",
    "            model:backward(xinput, {gradMaskLayer[1], gradOutput[2]})\n",
    "        else \n",
    "            local predQ = model:forward(xinput)\n",
    "            local predQOnActions = maskLayer:forward({predQ, actions_in}) \n",
    "            lossf = criterion:forward(predQOnActions, reward)\n",
    "            local gradOutput = criterion:backward(predQOnActions, reward)\n",
    "            local gradMaskLayer = maskLayer:backward({predQ, actions_in}, gradOutput)\n",
    "            print(#gradOutput)\n",
    "            model:backward(xinput, gradMaskLayer[1])\n",
    "        end \n",
    "        return lossf, gradParams\n",
    "    end\n",
    " --- optim.rmsprop returns \\theta, f(\\theta):= loss function\n",
    " _, lossv  = optim.rmsprop(feval, params, optimParams)\n",
    "end\n",
    "print(lossv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = backProp(fullmemory, params, gradParams, optimParams, model, \n",
    "    criterion, batch_size, mem_size, adapt, use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
