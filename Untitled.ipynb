{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...Utils file loaded\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'optim'\n",
    "require 'io'\n",
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'csvigo'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'\n",
    "\n",
    "dl = require 'dataload'\n",
    "cmd = torch.CmdLine()\n",
    "dofile(\"Code/utils.lua\")\n",
    "dofile(\"Code/utilsNN.lua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running on a subset of 20 observations\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Running bag-of-words model to learn f1\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Using adaptive regularization\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "predQ\t 0.3397 -0.4828\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       "predReg\t"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 1\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n",
       "actions\t 0  1\n",
       "[torch.ByteTensor of size 1x2]\n",
       "\n",
       "predQonActions\t-0.4828\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n",
       "rmse\t0.50806856257832\t\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath ='data/0-output/'\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "LongTensor = torch.LongTensor\n",
    "ByteTensor = torch.ByteTensor\n",
    "\n",
    "use_cuda = false\n",
    "thresh = 0\n",
    "edim = 10\n",
    "metric = 'f1'\n",
    "inputs = loadMetadata(datapath .. \"dqn_metadata.csv\")                                               \n",
    "stoplist = loadStopdata(datapath .. 'stopwordids.csv')\n",
    "adapt = true\n",
    "\n",
    "vocabSize, query_data = initialize_variables(inputs, 20, datapath, 5, 30, stoplist, thresh, use_cuda)\n",
    "\n",
    "model = buildModel('bow', vocabSize, edim, metric, true, use_cuda)\n",
    "\n",
    "criterion = nn.ParallelCriterion():add(nn.MSECriterion()):add(nn.BCECriterion())\n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "query_randomF1 = {}\n",
    "params, gradParams = model:getParameters()\n",
    "\n",
    "query_id = 1\n",
    "\n",
    "\n",
    "sentenceStream = query_data[query_id][1]\n",
    "streamSize = query_data[query_id][2]\n",
    "query = query_data[query_id][3]\n",
    "actions = query_data[query_id][4]\n",
    "exploreDraws = query_data[query_id][5]\n",
    "summaryBuffer = query_data[query_id][6]\n",
    "qValues = query_data[query_id][7]\n",
    "rouge = query_data[query_id][8]\n",
    "actionsOpt = query_data[query_id][9]\n",
    "rougeOpt = query_data[query_id][10]\n",
    "refSummary = query_data[query_id][11]\n",
    "refCounts = query_data[query_id][12]\n",
    "buffer = query_data[query_id][13]\n",
    "\n",
    "maskLayer = nn.MaskedSelect()\n",
    "-- Have to set clear the inputs at the beginning of each scoring round\n",
    "actions:fill(0)\n",
    "actionsOpt:fill(0)\n",
    "rouge:fill(0)\n",
    "rougeOpt:fill(0)\n",
    "qValues:fill(0)\n",
    "summaryBuffer:fill(0)\n",
    "buffer:fill(0)\n",
    "exploreDraws:fill(0)\n",
    "exploreDraws:uniform(0, 1)\n",
    "summary = summaryBuffer:zero():narrow(1, 1, 1) -- summary starts empty\n",
    "\n",
    "i = 1\n",
    "\n",
    "sentence = sentenceStream:narrow(1, i, 1)\n",
    "\n",
    "predTotal = model:forward({sentence, query, summary})\n",
    "predQ = predTotal[1]\n",
    "predReg = predTotal[2]\n",
    "actions = ByteTensor(1, 2):fill(0)\n",
    "\n",
    "if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "    actions[i][SKIP] = 1\n",
    "else\n",
    "    actions[i][SELECT] = 1\n",
    "end\n",
    "\n",
    "predQOnActions = maskLayer:forward({predQ[i], actions[i]}) \n",
    "\n",
    "print('predQ', predQ)\n",
    "print('predReg', predReg)\n",
    "print('actions', actions)\n",
    "print('predQonActions', predQOnActions)\n",
    "\n",
    "reward = torch.zeros(1):fill(0.23):resize(1,1)\n",
    "class = torch.ones(1):resize(1,1)\n",
    "\n",
    "nll = nn.BCECriterion()\n",
    "mse = nn.MSECriterion()\n",
    "pc = nn.ParallelCriterion():add(mse):add(nll)\n",
    "\n",
    "lossf = mse:forward(predQOnActions, reward)\n",
    "print('rmse', lossf)\n",
    "\n",
    "lossf = criterion:forward({predQOnActions, predReg}, {reward, class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.2300\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.3397\n",
       "-0.4828\n",
       "[torch.DoubleTensor of size 2]\n",
       "\n",
       " 0\n",
       " 1\n",
       "[torch.ByteTensor of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predQ[i], actions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4828\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n",
       " 1\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predQOnActions, predReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local predQ = model:forward(xinput)\n",
    "local predQOnActions = maskLayer:forward({predQ, actions_in})\n",
    "local lossf = criterion:forward(predQOnActions, reward)\n",
    "local gradOutput = criterion:backward(predQOnActions, reward)\n",
    "local gradMaskLayer = maskLayer:backward({predQ, actions_in}, gradOutput)\n",
    "model:backward(xinput, gradMaskLayer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predTotal = model:forward({sentence, query, summary})\n",
    "predQ = predTotal[1]\n",
    "predReg = predTotal[2]\n",
    "\n",
    "predQOnActions = maskLayer:forward({predQ[i], actions[i]}) \n",
    "lossf = criterion:forward({predQOnActions, predReg}, {reward, class})\n",
    "gradOutput = criterion:backward({predQOnActions, predReg}, {reward, class})\n",
    "gradMaskLayer = maskLayer:backward({predQ, actions}, gradOutput[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 1\n",
       "  2 : DoubleTensor - size: 1x1\n",
       "}\n",
       "{\n",
       "  1 : DoubleTensor - size: 1x2\n",
       "  2 : ByteTensor - size: 1x2\n",
       "}\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradOutput, gradMaskLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model:backward({sentence, query, summary}, gradMaskLayer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model:backward({sentence, query, summary}, gradMaskLayer[1])\n",
    "print('success')\n",
    "\n",
    "-- memory, rougeRecall, rougePrecision, rougeF1, qValues = forwardpass(\n",
    "--                 query_data, query_id, model, 1, 0., \n",
    "--                 metric, thresh, stoplist, use_cuda\n",
    "-- )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       "[torch.DoubleTensor of size 10x1]\n",
       "\n",
       "Logistic Pred:\t\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 10x1]\n",
       "\n",
       "Linear Pred:\t\n",
       "-0.8611  0.4867\n",
       "-0.6617 -0.6213\n",
       "-0.8278  0.9368\n",
       "-1.3838  0.2187\n",
       "-0.1060  0.5200\n",
       "-0.5733  0.6481\n",
       "-0.5975  0.8620\n",
       "-0.6819  1.1842\n",
       "-0.4667  0.8899\n",
       "-1.5645  0.5753\n",
       "[torch.DoubleTensor of size 10x2]\n",
       "\n",
       "Logistic and Linear Pred:\t\n",
       "{\n",
       "  1 : DoubleTensor - size: 10x2\n",
       "  2 : DoubleTensor - size: 10x1\n",
       "}\n",
       "NLL loss:\t\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8.2893063347779\t\n",
       "MSE loss:\t\n",
       "8.2893063347779\t\n",
       "Parallel NLL-MSE loss:\t\n",
       "8.7774178529368\t\n",
       "Parallel Full NLL-MSE loss:\t\n",
       "8.7774178529368\t\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'nn'\n",
    "math.randomseed(3)\n",
    "torch.manualSeed(3)\n",
    "\n",
    "-- Building data\n",
    "x = torch.randn(20):resize(10, 2)\n",
    "xhat = x + 0.01 * torch.rand(20):resize(10, 2)\n",
    "b = torch.rand(2, 1)\n",
    "yhat = torch.mm(x, b)  + torch.randn(10)  -- np.dot()\n",
    "n = yhat:size(1)\n",
    "onex = torch.ones(n):resize(n, 1)\n",
    "target = torch.round(nn.Sigmoid():forward(yhat))\n",
    "\n",
    "print(target)\n",
    "\n",
    "-- This is the Logistic\n",
    "LogisticModel = nn.Sequential():add(nn.Linear(2, 1)):add(nn.LogSoftMax())\n",
    "\n",
    "-- This is the linear regression\n",
    "LinearModel = nn.Sequential():add(nn.Linear(2, 2))\n",
    "\n",
    "--- Stacking the models together\n",
    "FullModel = nn.ConcatTable():add(LinearModel):add(LogisticModel)\n",
    "\n",
    "print(\"Logistic Pred:\")\n",
    "pred_log = LogisticModel:forward(x)\n",
    "print(pred_log)\n",
    "\n",
    "print(\"Linear Pred:\")\n",
    "pred_reg = LinearModel:forward(x)\n",
    "print(pred_reg)\n",
    "\n",
    "print(\"Logistic and Linear Pred:\")\n",
    "pred_final = FullModel:forward(x)\n",
    "print(pred_final)\n",
    "\n",
    "nll = nn.BCECriterion()\n",
    "mse = nn.MSECriterion()\n",
    "pc = nn.ParallelCriterion():add(mse):add(nll)\n",
    "\n",
    "print(\"NLL loss:\")\n",
    "nll_loss = nll:forward(pred_log, target)\n",
    "print(nll_loss)\n",
    "\n",
    "print(\"MSE loss:\")\n",
    "mse_loss = mse:forward(pred_reg, xhat)\n",
    "print(nll_loss)\n",
    "\n",
    "print(\"Parallel NLL-MSE loss:\")\n",
    "prl_loss = pc:forward( {pred_reg, pred_log}, {xhat, target} )\n",
    "print(prl_loss)\n",
    "\n",
    "print(\"Parallel Full NLL-MSE loss:\")\n",
    "prl_final = pc:forward(pred_final, {xhat, target})\n",
    "print(prl_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions = torch.ByteTensor(10, 2):fill(0)\n",
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "qTotal  = FullModel:forward(x)\n",
    "qValues = qTotal[1]\n",
    "regValues = qTotal[2]\n",
    "\n",
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "for i=1, qValues:size(1) do\n",
    "    if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "        actions[i][SKIP] = 1\n",
    "    else\n",
    "        actions[i][SELECT] = 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The full backprop without selection is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0878  0.0180\n",
       "-0.1132 -0.0316\n",
       "-0.0708  0.0666\n",
       "-0.1050  0.0133\n",
       "-0.0004  0.0223\n",
       "-0.0603  0.0487\n",
       "-0.0260  0.0320\n",
       "-0.0508  0.0918\n",
       "-0.0519  0.0434\n",
       "-0.1052  0.0450\n",
       "[torch.DoubleTensor of size 10x2]\n",
       "\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = torch.rand(20):resize(10, 2)\n",
    "class = torch.ones(10):resize(10, 1)\n",
    "\n",
    "qTotal  = FullModel:forward(x)\n",
    "qValues = qTotal[1]\n",
    "regValues = qTotal[2]\n",
    "\n",
    "gradOutput = pc:backward(qTotal, {reward, class})\n",
    "print(FullModel:backward(x, gradOutput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop on just the linear model with selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0195 -0.0390\n",
       "-0.0680 -0.1358\n",
       " 0.0022  0.0044\n",
       " 0.0097  0.0193\n",
       " 0.0098  0.0196\n",
       "-0.0146 -0.0291\n",
       "-0.0014 -0.0027\n",
       " 0.0456  0.0911\n",
       " 0.0361  0.0721\n",
       " 0.0313  0.0625\n",
       "[torch.DoubleTensor of size 10x2]\n",
       "\n"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskLayer = nn.MaskedSelect()\n",
    "\n",
    "reward = torch.rand(20):resize(10, 1)\n",
    "class = torch.ones(10):resize(10, 1)\n",
    "\n",
    "qValues  = LinearModel:forward(x)\n",
    "\n",
    "predQOnActions = maskLayer:forward({qValues, actions})\n",
    "gradOutput = mse:backward(predQOnActions, reward)\n",
    "gradMaskLayer = maskLayer:backward({qValues, actions}, gradOutput)\n",
    "print(LinearModel:backward(x, gradMaskLayer[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop joint model with selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reward = torch.rand(10):resize(10)\n",
    "class = torch.ones(10):resize(10, 1)\n",
    "\n",
    "qTotal  = FullModel:forward(x)\n",
    "qValues = qTotal[1]\n",
    "regValues = qTotal[2]\n",
    "\n",
    "-- Selection part\n",
    "predQOnActions = maskLayer:forward({qValues, actions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 10\n",
       "  2 : DoubleTensor - size: 10x1\n",
       "}\n"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc:backward({predQOnActions, regValues}, {reward, class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 10x2\n",
       "  2 : ByteTensor - size: 10x2\n",
       "}\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskLayer:backward({qValues, actions}, gradOutput[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradOutput = pc:backward({predQOnActions, regValues}, {reward, class})\n",
    "gradMaskLayer = maskLayer:backward({qValues, actions}, gradOutput[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 10\n",
       "  2 : DoubleTensor - size: 10x1\n",
       "}\n"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(FullModel:backward(x, gradMaskLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reward = torch.rand(10):resize(10, 1)\n",
    "class = torch.ones(10):resize(10, 1)\n",
    "\n",
    "qTotal  = FullModel:forward(x)\n",
    "qValues = qTotal[1]\n",
    "regValues = qTotal[2]\n",
    "\n",
    "predQOnActions = maskLayer:forward({qValues, actions})\n",
    "\n",
    "gradOutput = pc:backward({predQOnActions, regValues}, {reward, class})\n",
    "gradMaskLayer = maskLayer:backward({qValues, actions}, gradOutput[1])\n",
    "print(FullModel:backward(x, gradMaskLayer[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
