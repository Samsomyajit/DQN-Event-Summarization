{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputfile = \"/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/cnn_data_corpus.csv\"\n",
    "inputdict = \"/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/cnn_total_corpus_smry.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f66e58e38d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francisco/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "qdf = pd.read_csv(inputfile)\n",
    "qdict = pd.read_csv(inputdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = qdf['query_id']\n",
    "true_summaries = qdf['tstokens']\n",
    "sentences = qdf[[x for x in qdf.columns if 'stokens_' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 2, 'b': 1, 'c': 1, 'd': 1})\n"
     ]
    }
   ],
   "source": [
    "corpus = Counter()\n",
    "for word in ['a' ,'b', 'c', 'a', 'd']:\n",
    "    corpus[word] += 1\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rougueScores(genSummary, refSummary):\n",
    "    genTotal, refTotal, intersection = 0, 0, 0\n",
    "    for token in list(set(list(refSummary.keys()) + list(genSummary.keys()) )):\n",
    "        intersection += min(refSummary[token], genSummary[token])\n",
    "        refTotal += refSummary[token]\n",
    "        genTotal += genSummary[token]\n",
    "\n",
    "    recall = intersection / float(refTotal) if float(refTotal) > 0 else 0\n",
    "    prec   = intersection / float(genTotal) if float(genTotal) > 0 else 0\n",
    "    f1 = (2 * recall * prec) / (recall + prec) if (recall + prec) > 0 else 0\n",
    "    \n",
    "    return recall, prec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueSummary = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3])\n",
    "\n",
    "predSummary0 = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3])\n",
    "\n",
    "predSummary1 = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3, 4])\n",
    "\n",
    "predSummary2 = Counter([1, 1, 1, 2, 2, 2, 2, 3])\n",
    "\n",
    "predSummary3 = Counter([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 1.0)\n",
      "(1.0, 0.9, 0.9473684210526316)\n",
      "(0.8888888888888888, 1.0, 0.9411764705882353)\n",
      "(0.0, 0.0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(rougueScores(predSummary0, trueSummary))\n",
    "print(rougueScores(predSummary1, trueSummary))\n",
    "print(rougueScores(predSummary2, trueSummary))\n",
    "print(rougueScores(predSummary3, trueSummary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "      <th>cumfreq</th>\n",
       "      <th>percent</th>\n",
       "      <th>cumpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>by</td>\n",
       "      <td>4528679</td>\n",
       "      <td>4528679</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>0.007296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>try</td>\n",
       "      <td>4088095</td>\n",
       "      <td>8616774</td>\n",
       "      <td>0.006586</td>\n",
       "      <td>0.013882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>once</td>\n",
       "      <td>3899082</td>\n",
       "      <td>12515856</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.020163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>case</td>\n",
       "      <td>3867709</td>\n",
       "      <td>16383565</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.026394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3694710</td>\n",
       "      <td>20078275</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.032347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id token  frequency   cumfreq   percent  cumpercent\n",
       "0   40    by    4528679   4528679  0.007296    0.007296\n",
       "1   17   try    4088095   8616774  0.006586    0.013882\n",
       "2    9  once    3899082  12515856  0.006282    0.020163\n",
       "3  114  case    3867709  16383565  0.006231    0.026394\n",
       "4    3    45    3694710  20078275  0.005952    0.032347"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dict = dict(zip(qdict['id'].values, qdict['token'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for token in sentence:\n",
    "        vec[token] += 1\n",
    "    return vec.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        \n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        return F.log_softmax(self.linear(bow_vec))\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    (make_bow_vector([int(s) for s in sentences['stokens_0'][0].split(\" \")], corpus_dict),\n",
    "    torch.LongTensor([0]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlabels = 2 \n",
    "vocab_size = len(corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "-2.8658e-03 -1.6441e-03  2.5561e-03  ...   4.4683e-04 -9.2455e-04  8.7829e-04\n",
      "-2.1095e-03  2.1107e-03  2.8656e-03  ...   2.2872e-03  8.5265e-04  8.3847e-04\n",
      "[torch.FloatTensor of size 2x111212]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-03 *\n",
      "  1.2245\n",
      " -0.9217\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "Variable containing:\n",
      "-0.6966 -0.6897\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BoWClassifier(nlabels, vocab_size)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "log_probs = model(autograd.Variable(train_data[0]))\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data =  [\n",
    "    (make_bow_vector([int(s) for s in sentences['stokens_0'][1].split(\" \")], corpus_dict),\n",
    "    torch.LongTensor([1]) )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.6905 -0.6958\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for instance, label in test_data:\n",
    "    log_probs = model(autograd.Variable(instance))\n",
    "    print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually you want to pass over the training data several times.\n",
    "# 100 is much bigger than on a real data set, but real datasets have more than\n",
    "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
    "for epoch in range(100):\n",
    "    for instance, label in train_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
    "        # Variable as an integer. For example, if the target is SPANISH, then\n",
    "        # we wrap the integer 0. The loss function then knows that the 0th\n",
    "        # element of the log probabilities is the log probability\n",
    "        # corresponding to SPANISH\n",
    "        bow_vec = autograd.Variable(instance)\n",
    "        target = autograd.Variable(label)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = model(bow_vec)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.4435 -1.0266\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for instance, label in test_data:\n",
    "    bow_vec = autograd.Variable(instance)\n",
    "    log_probs = model(bow_vec)\n",
    "    print(log_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
