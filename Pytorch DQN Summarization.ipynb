{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputfile = \"/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/cnn_data_corpus.csv\"\n",
    "inputdict = \"/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/cnn_total_corpus_smry.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francisco/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "qdf = pd.read_csv(inputfile)\n",
    "qdict = pd.read_csv(inputdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queries = qdf['query_id']\n",
    "sentences = qdf[[x for x in qdf.columns if 'stokens_' in x]]\n",
    "\n",
    "true_summaries = {}\n",
    "for queryid, true_summary in zip(queries, qdf['tstokens']):\n",
    "    true_summaries[queryid] = Counter([int(x) for x in true_summary.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_dict = dict(zip(qdict['id'].values, qdict['token'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for token in sentence:\n",
    "        vec[token] += 1\n",
    "    return vec.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a global variable\n",
    "xs  = torch.zeros(sentences.shape[0], len(corpus_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensorSentences(index):\n",
    "    tokens = sentences['stokens_0'][index].split(\" \")\n",
    "    if len(tokens) > 0:\n",
    "        xs[index, :] = make_bow_vector([int(s) for s in tokens], corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst = [xs[0:5,0:5], xs[0:5,0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(tst, 'tst.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       " [torch.FloatTensor of size 5x5], \n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       "  0  0  0  0  0\n",
       " [torch.FloatTensor of size 5x5]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('tst.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(tensorSentences)(i) for i in range(sentences.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_xs = torch.zeros(sentences.shape[0], len(corpus_dict))\n",
    "# train_ys = torch.from_numpy(np.random.random((n, 2))).float()  # Simulating the output\n",
    "\n",
    "for i, row in enumerate(sentences['stokens_0']):\n",
    "    tokens = row.split(\" \")\n",
    "    if len(tokens) > 0:\n",
    "        train_xs[i, :] = make_bow_vector([int(s) for s in tokens], corpus_dict)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stokens_0</th>\n",
       "      <th>stokens_1</th>\n",
       "      <th>stokens_2</th>\n",
       "      <th>stokens_3</th>\n",
       "      <th>stokens_4</th>\n",
       "      <th>stokens_5</th>\n",
       "      <th>stokens_6</th>\n",
       "      <th>stokens_7</th>\n",
       "      <th>stokens_8</th>\n",
       "      <th>stokens_9</th>\n",
       "      <th>...</th>\n",
       "      <th>stokens_115</th>\n",
       "      <th>stokens_116</th>\n",
       "      <th>stokens_117</th>\n",
       "      <th>stokens_118</th>\n",
       "      <th>stokens_119</th>\n",
       "      <th>stokens_120</th>\n",
       "      <th>stokens_121</th>\n",
       "      <th>stokens_122</th>\n",
       "      <th>stokens_123</th>\n",
       "      <th>stokens_124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 1 2 3 4 5 6 7</td>\n",
       "      <td>20001 8 9 10 0 11 12 13 14 0 20001 15 16 17 18...</td>\n",
       "      <td>0 23 51 14 52 53 54 55 56 23 57 58 59 9 60 61 ...</td>\n",
       "      <td>68 69 70 71 72 0 73 74 75 76 77 15 78 79 80 81...</td>\n",
       "      <td>0 94 90 37 69 14 0 95 9 26 78 79 96 20001 97 9...</td>\n",
       "      <td>37 96 107 108 15 109 4 20001 110 101 48 111 99...</td>\n",
       "      <td>123 0 124 125 126 127 128 129 4 130 131 37 132...</td>\n",
       "      <td>62 0 136 146 147 90 9 148 110 141 3 149 150 15...</td>\n",
       "      <td>164 165 166 167 118 168 169 170</td>\n",
       "      <td>171 172 173 174 140 175 176 177 178 179 180 18...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78 79 549 411 550 44 551 552 549 84 553 20001 ...</td>\n",
       "      <td>37 561 102 562 3 563 564 565 8 37 20001 23 566...</td>\n",
       "      <td>37 558 102 551 84 570 571 572 23 573 74 337 26...</td>\n",
       "      <td>394 84 570 574 56 105 558 20001 74 575 271 15 ...</td>\n",
       "      <td>84 582 583 82 83 551 582 583 584 110 585 3 586...</td>\n",
       "      <td>37 595 20001 32 37 553 596 161 202 302 302 315...</td>\n",
       "      <td>112 574 56 3 603 604 605 606 72 607 298 32 196...</td>\n",
       "      <td>605 23 58 614 615 616 346</td>\n",
       "      <td>37 617 618 196 619 37 620 612 621 74 37 622 62...</td>\n",
       "      <td>509 629 118 582 583 630 3 551 631 632 633</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37 549 788 41 20001 756 8 78 79 572</td>\n",
       "      <td>37 789 110 37 579 790 791 105 792 153 793 794 ...</td>\n",
       "      <td>808 809 810 811 627 812 32 78 79 572 6 8 253 8...</td>\n",
       "      <td>8 822 68 110 339 823 824 37 825 826 827 110 78...</td>\n",
       "      <td>8 822 37 831 832 833 826 827 238 808 809 810 8...</td>\n",
       "      <td>834 78 79 572 835 37 35 836 837 110 253 838 3 ...</td>\n",
       "      <td>843 46 126 46 269 271 110 78 79 572 105 624 13...</td>\n",
       "      <td>843 9 849 315 136 850 851 198 852 3 853</td>\n",
       "      <td>78 79 572 105 854 855 41 856 857 858 99 253 83...</td>\n",
       "      <td>153 123 859 860 110 861 153</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78 79 549 280 1168 105 1169 37 78 79 572 538 8...</td>\n",
       "      <td>37 1171 538 1179 71 280 284 9 1 1180 99 1172 9...</td>\n",
       "      <td>1185 1187 37 1188 1189 627 248 20001 1190 318 ...</td>\n",
       "      <td>1194 1195 507 9 551 1196 1188 1197 430 8 37 11...</td>\n",
       "      <td>153 105 9 720 720 1208 889 9 837 889 507 1209 ...</td>\n",
       "      <td>248 6 14 37 78 79 572 591 67 35 1211</td>\n",
       "      <td>37 551 1188 1212 1213 3 1184 15 37 799 800 801...</td>\n",
       "      <td>641 668 153 9 720 1225 1171 32 1226 435 1227</td>\n",
       "      <td>507 1209 784 32 1218 23 1228 15 536 1229 32 9 ...</td>\n",
       "      <td>1218 23 187 485 15 37 776 105 1236 102 9 907 1...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78 79 549 139 1380 1381 318 9 1382 1383 8 1384...</td>\n",
       "      <td>9 1390 1391 869 8 1185 1392 1393 609 1394 223 ...</td>\n",
       "      <td>852 8 37 1397 316 1398</td>\n",
       "      <td>37 574 56 869 8 578 3 579 580 1399 15 90 7 140...</td>\n",
       "      <td>37 869 23 1405 896 37 1406 1407 110 1408 1409 ...</td>\n",
       "      <td>455 99 37 1414 1415 316 1036 15 1416 1333 14 1...</td>\n",
       "      <td>37 869 123 1421 280 1034 1422 852 218 15 37 80...</td>\n",
       "      <td>1385 316 861 989 74 1425 1426 3 1427 32 316 14...</td>\n",
       "      <td>99 560 1173 1385 1118 196 123 1431 37 1432 110...</td>\n",
       "      <td>37 1439 110 37 1430 23 58 1440 1091</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           stokens_0  \\\n",
       "0                                    0 1 2 3 4 5 6 7   \n",
       "1  78 79 549 411 550 44 551 552 549 84 553 20001 ...   \n",
       "2                37 549 788 41 20001 756 8 78 79 572   \n",
       "3  78 79 549 280 1168 105 1169 37 78 79 572 538 8...   \n",
       "4  78 79 549 139 1380 1381 318 9 1382 1383 8 1384...   \n",
       "\n",
       "                                           stokens_1  \\\n",
       "0  20001 8 9 10 0 11 12 13 14 0 20001 15 16 17 18...   \n",
       "1  37 561 102 562 3 563 564 565 8 37 20001 23 566...   \n",
       "2  37 789 110 37 579 790 791 105 792 153 793 794 ...   \n",
       "3  37 1171 538 1179 71 280 284 9 1 1180 99 1172 9...   \n",
       "4  9 1390 1391 869 8 1185 1392 1393 609 1394 223 ...   \n",
       "\n",
       "                                           stokens_2  \\\n",
       "0  0 23 51 14 52 53 54 55 56 23 57 58 59 9 60 61 ...   \n",
       "1  37 558 102 551 84 570 571 572 23 573 74 337 26...   \n",
       "2  808 809 810 811 627 812 32 78 79 572 6 8 253 8...   \n",
       "3  1185 1187 37 1188 1189 627 248 20001 1190 318 ...   \n",
       "4                             852 8 37 1397 316 1398   \n",
       "\n",
       "                                           stokens_3  \\\n",
       "0  68 69 70 71 72 0 73 74 75 76 77 15 78 79 80 81...   \n",
       "1  394 84 570 574 56 105 558 20001 74 575 271 15 ...   \n",
       "2  8 822 68 110 339 823 824 37 825 826 827 110 78...   \n",
       "3  1194 1195 507 9 551 1196 1188 1197 430 8 37 11...   \n",
       "4  37 574 56 869 8 578 3 579 580 1399 15 90 7 140...   \n",
       "\n",
       "                                           stokens_4  \\\n",
       "0  0 94 90 37 69 14 0 95 9 26 78 79 96 20001 97 9...   \n",
       "1  84 582 583 82 83 551 582 583 584 110 585 3 586...   \n",
       "2  8 822 37 831 832 833 826 827 238 808 809 810 8...   \n",
       "3  153 105 9 720 720 1208 889 9 837 889 507 1209 ...   \n",
       "4  37 869 23 1405 896 37 1406 1407 110 1408 1409 ...   \n",
       "\n",
       "                                           stokens_5  \\\n",
       "0  37 96 107 108 15 109 4 20001 110 101 48 111 99...   \n",
       "1  37 595 20001 32 37 553 596 161 202 302 302 315...   \n",
       "2  834 78 79 572 835 37 35 836 837 110 253 838 3 ...   \n",
       "3               248 6 14 37 78 79 572 591 67 35 1211   \n",
       "4  455 99 37 1414 1415 316 1036 15 1416 1333 14 1...   \n",
       "\n",
       "                                           stokens_6  \\\n",
       "0  123 0 124 125 126 127 128 129 4 130 131 37 132...   \n",
       "1  112 574 56 3 603 604 605 606 72 607 298 32 196...   \n",
       "2  843 46 126 46 269 271 110 78 79 572 105 624 13...   \n",
       "3  37 551 1188 1212 1213 3 1184 15 37 799 800 801...   \n",
       "4  37 869 123 1421 280 1034 1422 852 218 15 37 80...   \n",
       "\n",
       "                                           stokens_7  \\\n",
       "0  62 0 136 146 147 90 9 148 110 141 3 149 150 15...   \n",
       "1                          605 23 58 614 615 616 346   \n",
       "2            843 9 849 315 136 850 851 198 852 3 853   \n",
       "3       641 668 153 9 720 1225 1171 32 1226 435 1227   \n",
       "4  1385 316 861 989 74 1425 1426 3 1427 32 316 14...   \n",
       "\n",
       "                                           stokens_8  \\\n",
       "0                    164 165 166 167 118 168 169 170   \n",
       "1  37 617 618 196 619 37 620 612 621 74 37 622 62...   \n",
       "2  78 79 572 105 854 855 41 856 857 858 99 253 83...   \n",
       "3  507 1209 784 32 1218 23 1228 15 536 1229 32 9 ...   \n",
       "4  99 560 1173 1385 1118 196 123 1431 37 1432 110...   \n",
       "\n",
       "                                           stokens_9     ...     stokens_115  \\\n",
       "0  171 172 173 174 140 175 176 177 178 179 180 18...     ...             NaN   \n",
       "1          509 629 118 582 583 630 3 551 631 632 633     ...             NaN   \n",
       "2                        153 123 859 860 110 861 153     ...             NaN   \n",
       "3  1218 23 187 485 15 37 776 105 1236 102 9 907 1...     ...             NaN   \n",
       "4                37 1439 110 37 1430 23 58 1440 1091     ...             NaN   \n",
       "\n",
       "  stokens_116 stokens_117 stokens_118 stokens_119 stokens_120 stokens_121  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  stokens_122 stokens_123 stokens_124  \n",
       "0         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_dict = {}\n",
    "sentence_idx in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch_file = '/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/sentence_tensor.pt'\n",
    "truesummary_file = '/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/true_summaries_corpus.pkl'\n",
    "pickle.dump(true_summaries, open(truesummary_file, 'wb'))\n",
    "\n",
    "torch.save(train_xs, torch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rougueScores(genSummary, refSummary):\n",
    "    genTotal, refTotal, intersection = 0, 0, 0\n",
    "    for token in list(set(list(refSummary.keys()) + list(genSummary.keys()) )):\n",
    "        intersection += min(refSummary[token], genSummary[token])\n",
    "        refTotal += refSummary[token]\n",
    "        genTotal += genSummary[token]\n",
    "\n",
    "    recall = intersection / float(refTotal) if float(refTotal) > 0 else 0\n",
    "    prec   = intersection / float(genTotal) if float(genTotal) > 0 else 0\n",
    "    f1 = (2 * recall * prec) / (recall + prec) if (recall + prec) > 0 else 0\n",
    "    \n",
    "    return recall, prec, f1\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "class BoWRegressor(nn.Module):  # inheriting from nn.Module!\n",
    "    # calls the init function of nn.Module.  Dont get confused by syntax, always do it in an nn.Module\n",
    "    def __init__(self, outputsize, vocab_size):        \n",
    "        super(BoWRegressor, self).__init__()        \n",
    "        self.linear = nn.Linear(vocab_size, outputsize)\n",
    "        \n",
    "    def forward(self, bow_vec):\n",
    "        return F.relu(self.linear(bow_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what do  I need to do\n",
    "1. need to save sentences to tensors\n",
    "2. need to save counter summaries to pickle objects\n",
    "3. need to make code run on small examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     1     1  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.FloatTensor of size 10x111212]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     1     1  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.FloatTensor of size 4x111212]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs[0:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 111212])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "['i', 'm', '45', 'and', 'my', 'son', 'is']\n"
     ]
    }
   ],
   "source": [
    "print([int(s) for s in sentences['stokens_0'][0].split(\" \") ])\n",
    "print([corpus_dict[int(w)] for w in sentences['stokens_0'][0].split(\" \") if int(w) in corpus_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trueSummary = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3])\n",
    "\n",
    "predSummary0 = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3])\n",
    "\n",
    "predSummary1 = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3, 4])\n",
    "\n",
    "predSummary2 = Counter([1, 1, 1, 2, 2, 2, 2, 3])\n",
    "\n",
    "predSummary3 = Counter([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.0, 1.0)\n",
      "(1.0, 0.9, 0.9473684210526316)\n",
      "(0.8888888888888888, 1.0, 0.9411764705882353)\n",
      "(0.0, 0.0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(rougueScores(predSummary0, trueSummary))\n",
    "print(rougueScores(predSummary1, trueSummary))\n",
    "print(rougueScores(predSummary2, trueSummary))\n",
    "print(rougueScores(predSummary3, trueSummary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputsize = 2 \n",
    "vocab_size = len(corpus_dict)\n",
    "model = BoWRegressor(outputsize, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.341431\n",
      "Variable containing:\n",
      " 0.3414\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "rougue_preds = model(autograd.Variable(train_xs))\n",
    "loss = loss_function(rougue_preds, autograd.Variable(train_ys))\n",
    "\n",
    "print(\n",
    "    (( (rougue_preds.data).cpu().numpy() - (autograd.Variable(train_ys).data).cpu().numpy() ) **2 ).mean()\n",
    "     )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAFpCAYAAACI6H7aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8db7f0cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "lossf = {'loss': [], 'epoch': []}\n",
    "for epoch in range(100):\n",
    "    model.zero_grad()\n",
    "    \n",
    "    rougue_preds = model(autograd.Variable(train_xs))\n",
    "    loss = loss_function(rougue_preds, autograd.Variable(train_ys))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lossf['loss'].append(loss.data[0])\n",
    "    lossf['epoch'].append(epoch)\n",
    "    \n",
    "perf = pd.DataFrame(lossf)\n",
    "\n",
    "perf.plot(y='loss', figsize=(12, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 10,\n",
       "         1: 1,\n",
       "         2: 1,\n",
       "         3: 13,\n",
       "         4: 2,\n",
       "         5: 1,\n",
       "         6: 4,\n",
       "         7: 1,\n",
       "         8: 11,\n",
       "         9: 14,\n",
       "         10: 1,\n",
       "         11: 1,\n",
       "         12: 1,\n",
       "         13: 1,\n",
       "         14: 5,\n",
       "         15: 17,\n",
       "         16: 1,\n",
       "         17: 1,\n",
       "         18: 1,\n",
       "         19: 1,\n",
       "         20: 1,\n",
       "         21: 1,\n",
       "         22: 1,\n",
       "         23: 11,\n",
       "         24: 1,\n",
       "         25: 1,\n",
       "         26: 2,\n",
       "         27: 1,\n",
       "         28: 1,\n",
       "         29: 1,\n",
       "         30: 1,\n",
       "         31: 2,\n",
       "         32: 12,\n",
       "         33: 1,\n",
       "         34: 1,\n",
       "         35: 2,\n",
       "         36: 1,\n",
       "         37: 24,\n",
       "         38: 1,\n",
       "         39: 1,\n",
       "         40: 1,\n",
       "         41: 4,\n",
       "         42: 1,\n",
       "         43: 1,\n",
       "         44: 6,\n",
       "         45: 1,\n",
       "         46: 2,\n",
       "         47: 2,\n",
       "         48: 2,\n",
       "         49: 2,\n",
       "         50: 1,\n",
       "         51: 1,\n",
       "         52: 1,\n",
       "         53: 1,\n",
       "         54: 1,\n",
       "         55: 1,\n",
       "         56: 1,\n",
       "         57: 2,\n",
       "         58: 1,\n",
       "         59: 1,\n",
       "         60: 2,\n",
       "         61: 3,\n",
       "         62: 3,\n",
       "         63: 1,\n",
       "         64: 1,\n",
       "         65: 3,\n",
       "         66: 1,\n",
       "         67: 1,\n",
       "         68: 4,\n",
       "         69: 1,\n",
       "         70: 1,\n",
       "         71: 1,\n",
       "         72: 2,\n",
       "         73: 1,\n",
       "         74: 7,\n",
       "         75: 1,\n",
       "         76: 1,\n",
       "         77: 1,\n",
       "         78: 3,\n",
       "         79: 3,\n",
       "         80: 3,\n",
       "         81: 3,\n",
       "         82: 1,\n",
       "         83: 1,\n",
       "         84: 1,\n",
       "         85: 2,\n",
       "         86: 1,\n",
       "         87: 4,\n",
       "         88: 4,\n",
       "         89: 5,\n",
       "         90: 4,\n",
       "         91: 1,\n",
       "         92: 1,\n",
       "         93: 1,\n",
       "         100: 4,\n",
       "         102: 7,\n",
       "         103: 2,\n",
       "         105: 2,\n",
       "         108: 1,\n",
       "         110: 13,\n",
       "         118: 6,\n",
       "         123: 2,\n",
       "         126: 1,\n",
       "         136: 4,\n",
       "         140: 1,\n",
       "         141: 3,\n",
       "         144: 1,\n",
       "         146: 4,\n",
       "         147: 1,\n",
       "         148: 1,\n",
       "         149: 3,\n",
       "         150: 1,\n",
       "         151: 1,\n",
       "         152: 1,\n",
       "         153: 1,\n",
       "         154: 1,\n",
       "         155: 1,\n",
       "         156: 1,\n",
       "         157: 1,\n",
       "         158: 3,\n",
       "         159: 4,\n",
       "         160: 1,\n",
       "         161: 3,\n",
       "         162: 1,\n",
       "         163: 1,\n",
       "         168: 1,\n",
       "         169: 2,\n",
       "         170: 2,\n",
       "         171: 1,\n",
       "         172: 1,\n",
       "         173: 1,\n",
       "         174: 2,\n",
       "         175: 1,\n",
       "         176: 1,\n",
       "         177: 1,\n",
       "         178: 1,\n",
       "         179: 3,\n",
       "         180: 1,\n",
       "         181: 1,\n",
       "         182: 1,\n",
       "         183: 2,\n",
       "         184: 1,\n",
       "         185: 1,\n",
       "         186: 1,\n",
       "         192: 3,\n",
       "         198: 5,\n",
       "         208: 1,\n",
       "         209: 1,\n",
       "         211: 4,\n",
       "         213: 1,\n",
       "         218: 1,\n",
       "         219: 5,\n",
       "         220: 1,\n",
       "         221: 1,\n",
       "         222: 1,\n",
       "         223: 1,\n",
       "         224: 1,\n",
       "         225: 1,\n",
       "         226: 1,\n",
       "         227: 1,\n",
       "         228: 1,\n",
       "         229: 1,\n",
       "         230: 1,\n",
       "         231: 1,\n",
       "         232: 1,\n",
       "         233: 2,\n",
       "         234: 3,\n",
       "         235: 2,\n",
       "         236: 5,\n",
       "         237: 1,\n",
       "         238: 4,\n",
       "         239: 2,\n",
       "         240: 4,\n",
       "         243: 1,\n",
       "         244: 1,\n",
       "         245: 1,\n",
       "         246: 2,\n",
       "         247: 2,\n",
       "         248: 1,\n",
       "         249: 2,\n",
       "         250: 3,\n",
       "         251: 2,\n",
       "         252: 1,\n",
       "         253: 1,\n",
       "         254: 1,\n",
       "         255: 1,\n",
       "         256: 1,\n",
       "         257: 1,\n",
       "         258: 1,\n",
       "         259: 2,\n",
       "         260: 1,\n",
       "         261: 1,\n",
       "         262: 1,\n",
       "         263: 1,\n",
       "         264: 3,\n",
       "         265: 3,\n",
       "         266: 1,\n",
       "         267: 3,\n",
       "         268: 1,\n",
       "         269: 3,\n",
       "         270: 1,\n",
       "         271: 1,\n",
       "         280: 2,\n",
       "         285: 1,\n",
       "         286: 1,\n",
       "         287: 1,\n",
       "         288: 1,\n",
       "         289: 9,\n",
       "         290: 1,\n",
       "         291: 1,\n",
       "         292: 1,\n",
       "         293: 1,\n",
       "         294: 6,\n",
       "         295: 5,\n",
       "         296: 2,\n",
       "         297: 1,\n",
       "         298: 3,\n",
       "         299: 1,\n",
       "         300: 2,\n",
       "         301: 1,\n",
       "         302: 2,\n",
       "         303: 1,\n",
       "         304: 1,\n",
       "         305: 1,\n",
       "         306: 1,\n",
       "         307: 1,\n",
       "         308: 1,\n",
       "         309: 1,\n",
       "         310: 2,\n",
       "         311: 1,\n",
       "         312: 3,\n",
       "         313: 1,\n",
       "         314: 1,\n",
       "         315: 1,\n",
       "         316: 1,\n",
       "         317: 1,\n",
       "         318: 1,\n",
       "         319: 1,\n",
       "         320: 2,\n",
       "         321: 3,\n",
       "         322: 1,\n",
       "         323: 1,\n",
       "         324: 2,\n",
       "         325: 1,\n",
       "         326: 1,\n",
       "         327: 1,\n",
       "         328: 1,\n",
       "         329: 2,\n",
       "         330: 1,\n",
       "         331: 1,\n",
       "         332: 1,\n",
       "         333: 2,\n",
       "         337: 1,\n",
       "         339: 1,\n",
       "         340: 1,\n",
       "         341: 1,\n",
       "         342: 1,\n",
       "         343: 1,\n",
       "         344: 1,\n",
       "         345: 1,\n",
       "         346: 1,\n",
       "         347: 1,\n",
       "         348: 1,\n",
       "         349: 1,\n",
       "         350: 1,\n",
       "         351: 1,\n",
       "         352: 1,\n",
       "         353: 1,\n",
       "         354: 1,\n",
       "         355: 1,\n",
       "         356: 2,\n",
       "         357: 1,\n",
       "         358: 1,\n",
       "         359: 1,\n",
       "         371: 1,\n",
       "         372: 1,\n",
       "         373: 1,\n",
       "         374: 1,\n",
       "         375: 1,\n",
       "         376: 1,\n",
       "         377: 1,\n",
       "         378: 1,\n",
       "         379: 1,\n",
       "         380: 1,\n",
       "         381: 1,\n",
       "         382: 1,\n",
       "         383: 1,\n",
       "         384: 1,\n",
       "         385: 1,\n",
       "         386: 1,\n",
       "         388: 1,\n",
       "         397: 2,\n",
       "         398: 1,\n",
       "         399: 1,\n",
       "         400: 1,\n",
       "         401: 1,\n",
       "         402: 1,\n",
       "         418: 1,\n",
       "         442: 1,\n",
       "         443: 1,\n",
       "         444: 1,\n",
       "         445: 1,\n",
       "         457: 1,\n",
       "         458: 1,\n",
       "         459: 1,\n",
       "         460: 1,\n",
       "         461: 1,\n",
       "         462: 2,\n",
       "         463: 1,\n",
       "         464: 1,\n",
       "         545: 1,\n",
       "         20001: 14})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_summaries[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
