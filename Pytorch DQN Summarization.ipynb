{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulateData(n = 1000, max_sentences = 50, max_tokens = 500, max_sentlen = 10):\n",
    "    xCorpus = Counter()\n",
    "    qid = list(range(n))\n",
    "    qdf = pd.DataFrame(qid, columns=['query_id'])\n",
    "    qdf['n_sentences'] = np.random.randint(low=1, high=(max_sentences + 1), size=(n,))\n",
    "    sdf = pd.DataFrame(qid, columns=['query_id'])\n",
    "    #sdf.set_index('query_id', inplace=True)\n",
    "    sdf['tstokens'] = ''\n",
    "\n",
    "    for i in range(qdf['n_sentences'].max()):\n",
    "        sdf['stokens_%i' % i] = ''\n",
    "\n",
    "    for q_i, nsent_i in zip(qdf['query_id'], qdf['n_sentences']):\n",
    "        for sent_j in range(nsent_i):\n",
    "            sentlen_i = np.random.randint(low=1, high=(nsent_i + 1), size=(1,))[0]\n",
    "            rand_sent = np.random.randint(low=1, high=(max_tokens + 1), size=(sentlen_i,)).tolist()\n",
    "            for r_l in rand_sent:\n",
    "                xCorpus[r_l] += 1\n",
    "                \n",
    "            sdf.loc[q_i, 'stokens_%i' % sent_j] = ' '.join([str(j) for j in rand_sent])\n",
    "\n",
    "        # Randomly choosing size of summary, which one of the indices to select and then subsetting them\n",
    "        summary_size_i = np.random.randint(low=1, high=(nsent_i + 1), size=(1,))[0]\n",
    "        selected_i = sorted(list(set(np.random.randint(low=0, high=(nsent_i), size=(summary_size_i,)))))\n",
    "        truesummary_i = sdf.loc[q_i,:][['stokens_%i' %i for i in selected_i]]\n",
    "\n",
    "        sdf.loc[q_i, 'tstokens'] = ' '.join(truesummary_i)\n",
    "        \n",
    "    return sdf, xCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francisco/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "inputfile = \"/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/cnn_data_corpus.csv\"\n",
    "inputdict = \"/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/cnn_total_corpus_smry.csv\"\n",
    "\n",
    "qdf = pd.read_csv(inputfile)\n",
    "qdict = pd.read_csv(inputdict)\n",
    "corpus_dict = dict(zip(qdict['id'], qdict['token']))\n",
    "\n",
    "#qdf, corpus_dict = simulateData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>qtokens</th>\n",
       "      <th>tstokens</th>\n",
       "      <th>stokens_0</th>\n",
       "      <th>stokens_1</th>\n",
       "      <th>stokens_2</th>\n",
       "      <th>stokens_3</th>\n",
       "      <th>stokens_4</th>\n",
       "      <th>stokens_5</th>\n",
       "      <th>stokens_6</th>\n",
       "      <th>...</th>\n",
       "      <th>stokens_115</th>\n",
       "      <th>stokens_116</th>\n",
       "      <th>stokens_117</th>\n",
       "      <th>stokens_118</th>\n",
       "      <th>stokens_119</th>\n",
       "      <th>stokens_120</th>\n",
       "      <th>stokens_121</th>\n",
       "      <th>stokens_122</th>\n",
       "      <th>stokens_123</th>\n",
       "      <th>stokens_124</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20001 102 33 149 105 48</td>\n",
       "      <td>0 1 2 3 4 5 6 7 20001 8 9 10 0 11 12 13 14 0 2...</td>\n",
       "      <td>0 1 2 3 4 5 6 7</td>\n",
       "      <td>20001 8 9 10 0 11 12 13 14 0 20001 15 16 17 18...</td>\n",
       "      <td>0 23 51 14 52 53 54 55 56 23 57 58 59 9 60 61 ...</td>\n",
       "      <td>68 69 70 71 72 0 73 74 75 76 77 15 78 79 80 81...</td>\n",
       "      <td>0 94 90 37 69 14 0 95 9 26 78 79 96 20001 97 9...</td>\n",
       "      <td>37 96 107 108 15 109 4 20001 110 101 48 111 99...</td>\n",
       "      <td>123 0 124 125 126 127 128 129 4 130 131 37 132...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20001 102 319 550 551 19316 549 553 566</td>\n",
       "      <td>78 79 549 411 550 44 551 552 549 84 553 20001 ...</td>\n",
       "      <td>78 79 549 411 550 44 551 552 549 84 553 20001 ...</td>\n",
       "      <td>37 561 102 562 3 563 564 565 8 37 20001 23 566...</td>\n",
       "      <td>37 558 102 551 84 570 571 572 23 573 74 337 26...</td>\n",
       "      <td>394 84 570 574 56 105 558 20001 74 575 271 15 ...</td>\n",
       "      <td>84 582 583 82 83 551 582 583 584 110 585 3 586...</td>\n",
       "      <td>37 595 20001 32 37 553 596 161 202 302 302 315...</td>\n",
       "      <td>112 574 56 3 603 604 605 606 72 607 298 32 196...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>690 691 3 19317 591 20001 37 1510</td>\n",
       "      <td>37 549 788 41 20001 756 8 78 79 572 808 809 81...</td>\n",
       "      <td>37 549 788 41 20001 756 8 78 79 572</td>\n",
       "      <td>37 789 110 37 579 790 791 105 792 153 793 794 ...</td>\n",
       "      <td>808 809 810 811 627 812 32 78 79 572 6 8 253 8...</td>\n",
       "      <td>8 822 68 110 339 823 824 37 825 826 827 110 78...</td>\n",
       "      <td>8 822 37 831 832 833 826 827 238 808 809 810 8...</td>\n",
       "      <td>834 78 79 572 835 37 35 836 837 110 253 838 3 ...</td>\n",
       "      <td>843 46 126 46 269 271 110 78 79 572 105 624 13...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>690 1289 19318 747 15 886 1170 1171 99 20001 837</td>\n",
       "      <td>78 79 549 280 1168 105 1169 37 78 79 572 538 8...</td>\n",
       "      <td>78 79 549 280 1168 105 1169 37 78 79 572 538 8...</td>\n",
       "      <td>37 1171 538 1179 71 280 284 9 1 1180 99 1172 9...</td>\n",
       "      <td>1185 1187 37 1188 1189 627 248 20001 1190 318 ...</td>\n",
       "      <td>1194 1195 507 9 551 1196 1188 1197 430 8 37 11...</td>\n",
       "      <td>153 105 9 720 720 1208 889 9 837 889 507 1209 ...</td>\n",
       "      <td>248 6 14 37 78 79 572 591 67 35 1211</td>\n",
       "      <td>37 551 1188 1212 1213 3 1184 15 37 799 800 801...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>19319 1398 46 1385 5599 1430 8 14494 20001</td>\n",
       "      <td>78 79 549 139 1380 1381 318 9 1382 1383 8 1384...</td>\n",
       "      <td>78 79 549 139 1380 1381 318 9 1382 1383 8 1384...</td>\n",
       "      <td>9 1390 1391 869 8 1185 1392 1393 609 1394 223 ...</td>\n",
       "      <td>852 8 37 1397 316 1398</td>\n",
       "      <td>37 574 56 869 8 578 3 579 580 1399 15 90 7 140...</td>\n",
       "      <td>37 869 23 1405 896 37 1406 1407 110 1408 1409 ...</td>\n",
       "      <td>455 99 37 1414 1415 316 1036 15 1416 1333 14 1...</td>\n",
       "      <td>37 869 123 1421 280 1034 1422 852 218 15 37 80...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                           qtokens  \\\n",
       "0         0                           20001 102 33 149 105 48   \n",
       "1         1           20001 102 319 550 551 19316 549 553 566   \n",
       "2         2                 690 691 3 19317 591 20001 37 1510   \n",
       "3         3  690 1289 19318 747 15 886 1170 1171 99 20001 837   \n",
       "4         4        19319 1398 46 1385 5599 1430 8 14494 20001   \n",
       "\n",
       "                                            tstokens  \\\n",
       "0  0 1 2 3 4 5 6 7 20001 8 9 10 0 11 12 13 14 0 2...   \n",
       "1  78 79 549 411 550 44 551 552 549 84 553 20001 ...   \n",
       "2  37 549 788 41 20001 756 8 78 79 572 808 809 81...   \n",
       "3  78 79 549 280 1168 105 1169 37 78 79 572 538 8...   \n",
       "4  78 79 549 139 1380 1381 318 9 1382 1383 8 1384...   \n",
       "\n",
       "                                           stokens_0  \\\n",
       "0                                    0 1 2 3 4 5 6 7   \n",
       "1  78 79 549 411 550 44 551 552 549 84 553 20001 ...   \n",
       "2                37 549 788 41 20001 756 8 78 79 572   \n",
       "3  78 79 549 280 1168 105 1169 37 78 79 572 538 8...   \n",
       "4  78 79 549 139 1380 1381 318 9 1382 1383 8 1384...   \n",
       "\n",
       "                                           stokens_1  \\\n",
       "0  20001 8 9 10 0 11 12 13 14 0 20001 15 16 17 18...   \n",
       "1  37 561 102 562 3 563 564 565 8 37 20001 23 566...   \n",
       "2  37 789 110 37 579 790 791 105 792 153 793 794 ...   \n",
       "3  37 1171 538 1179 71 280 284 9 1 1180 99 1172 9...   \n",
       "4  9 1390 1391 869 8 1185 1392 1393 609 1394 223 ...   \n",
       "\n",
       "                                           stokens_2  \\\n",
       "0  0 23 51 14 52 53 54 55 56 23 57 58 59 9 60 61 ...   \n",
       "1  37 558 102 551 84 570 571 572 23 573 74 337 26...   \n",
       "2  808 809 810 811 627 812 32 78 79 572 6 8 253 8...   \n",
       "3  1185 1187 37 1188 1189 627 248 20001 1190 318 ...   \n",
       "4                             852 8 37 1397 316 1398   \n",
       "\n",
       "                                           stokens_3  \\\n",
       "0  68 69 70 71 72 0 73 74 75 76 77 15 78 79 80 81...   \n",
       "1  394 84 570 574 56 105 558 20001 74 575 271 15 ...   \n",
       "2  8 822 68 110 339 823 824 37 825 826 827 110 78...   \n",
       "3  1194 1195 507 9 551 1196 1188 1197 430 8 37 11...   \n",
       "4  37 574 56 869 8 578 3 579 580 1399 15 90 7 140...   \n",
       "\n",
       "                                           stokens_4  \\\n",
       "0  0 94 90 37 69 14 0 95 9 26 78 79 96 20001 97 9...   \n",
       "1  84 582 583 82 83 551 582 583 584 110 585 3 586...   \n",
       "2  8 822 37 831 832 833 826 827 238 808 809 810 8...   \n",
       "3  153 105 9 720 720 1208 889 9 837 889 507 1209 ...   \n",
       "4  37 869 23 1405 896 37 1406 1407 110 1408 1409 ...   \n",
       "\n",
       "                                           stokens_5  \\\n",
       "0  37 96 107 108 15 109 4 20001 110 101 48 111 99...   \n",
       "1  37 595 20001 32 37 553 596 161 202 302 302 315...   \n",
       "2  834 78 79 572 835 37 35 836 837 110 253 838 3 ...   \n",
       "3               248 6 14 37 78 79 572 591 67 35 1211   \n",
       "4  455 99 37 1414 1415 316 1036 15 1416 1333 14 1...   \n",
       "\n",
       "                                           stokens_6     ...     stokens_115  \\\n",
       "0  123 0 124 125 126 127 128 129 4 130 131 37 132...     ...             NaN   \n",
       "1  112 574 56 3 603 604 605 606 72 607 298 32 196...     ...             NaN   \n",
       "2  843 46 126 46 269 271 110 78 79 572 105 624 13...     ...             NaN   \n",
       "3  37 551 1188 1212 1213 3 1184 15 37 799 800 801...     ...             NaN   \n",
       "4  37 869 123 1421 280 1034 1422 852 218 15 37 80...     ...             NaN   \n",
       "\n",
       "  stokens_116 stokens_117 stokens_118 stokens_119 stokens_120 stokens_121  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  stokens_122 stokens_123 stokens_124  \n",
       "0         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queries = qdf['query_id']\n",
    "sentences = qdf[[x for x in qdf.columns if 'stokens_' in x]]\n",
    "\n",
    "true_summaries = {}\n",
    "for queryid, true_summary in zip(queries, qdf['tstokens']):\n",
    "    true_summaries[queryid] = Counter([int(x) for x in true_summary.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    # tf BOW model\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for token in sentence:\n",
    "        vec[token] += 1\n",
    "    \n",
    "    return vec.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([83566, 111212])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a global variable\n",
    "xs = torch.zeros(sentences.shape[0], len(corpus_dict))\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# torch.save(tst, 'tst.pkl')\n",
    "# torch.load('tst.pkl')\n",
    "# Parallel(n_jobs=-1)(delayed(tensorSentences)(i) for i in range(sentences.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = sentences['stokens_0'][0].split(\" \")\n",
    "test = make_bow_vector([int(s) for s in tokens], corpus_dict)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs = torch.zeros(sentences.shape[1], len(corpus_dict))\n",
    "# train_ys = torch.from_numpy(np.random.random((n, 2))).float()  # Simulating the output\n",
    "\n",
    "# bow for each sentence\n",
    "#for i, row in enumerate(sentences['stokens_0']):\n",
    "idx = 0\n",
    "tmp_sentence = sentences.ix[idx,:]\n",
    "sentences_i = tmp_sentence[tmp_sentence.notnull()]\n",
    "for j, sentence_j in enumerate(sentences_i):\n",
    "    tokens = sentence_j.split(\" \")\n",
    "    if len(tokens) > 0:\n",
    "        train_xs[j, :] = make_bow_vector([int(s) for s in tokens], corpus_dict)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [2., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "torch_file = '/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/sentence_tensor.pt'\n",
    "truesummary_file = '/home/francisco/GitHub/DQN-Event-Summarization/data/cnn_tokenized/true_summaries_corpus.pkl'\n",
    "pickle.dump(true_summaries, open(truesummary_file, 'wb'))\n",
    "\n",
    "torch.save(train_xs, torch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rougueScores(genSummary, refSummary):\n",
    "    genTotal, refTotal, intersection = 0, 0, 0\n",
    "    for token in list(set(list(refSummary.keys()) + list(genSummary.keys()) )):\n",
    "        intersection += min(refSummary[token], genSummary[token])\n",
    "        refTotal += refSummary[token]\n",
    "        genTotal += genSummary[token]\n",
    "\n",
    "    recall = intersection / float(refTotal) if float(refTotal) > 0 else 0\n",
    "    prec   = intersection / float(genTotal) if float(genTotal) > 0 else 0\n",
    "    f1 = (2 * recall * prec) / (recall + prec) if (recall + prec) > 0 else 0\n",
    "    \n",
    "    return recall, prec, f1\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])\n",
    "\n",
    "class BoWRegressor(nn.Module):  # inheriting from nn.Module!\n",
    "    # calls the init function of nn.Module.  Dont get confused by syntax, always do it in an nn.Module\n",
    "    def __init__(self, outputsize, nsentences, vocab_size, nlayers, nunits):\n",
    "        super(BoWRegressor, self).__init__()        \n",
    "        self.nlayers = nlayers\n",
    "        self.inputlayer = nn.Linear(vocab_size, nunits)\n",
    "        self.hiddenlayer = nn.Linear(nunits, nunits)\n",
    "        self.outputlayer = nn.Linear(nunits, outputsize)\n",
    "        \n",
    "        \n",
    "    def forward(self, bowmatrix):\n",
    "        hiddenlayer = self.inputlayer(bowmatrix)\n",
    "        for _ in range(self.nlayers):\n",
    "            hiddenlayer = self.hiddenlayer(hiddenlayer)\n",
    "\n",
    "        return F.relu(self.outputlayer(hiddenlayer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP = 0\n",
    "SELECT = 1\n",
    "\n",
    "nsent = train_xs.shape[0]\n",
    "vsize = train_xs.shape[1]\n",
    "outsize = 2\n",
    "nhlayers = 1\n",
    "nhunits = 128\n",
    "rand_rate = 1.0\n",
    "\n",
    "model = BoWRegressor(outsize, nsent, vsize, nhlayers, nhunits)\n",
    "action = torch.from_numpy(np.zeros(shape=(nsent, 2))).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_preds = model(autograd.Variable(train_xs))\n",
    "qMax, qIndx = rouge_preds.max(dim=1)\n",
    "\n",
    "if np.random.uniform() < rand_rate and rand_rate > 0:\n",
    "    # Randomly choosing either 0 or 1 some percent of the time\n",
    "    qIndx = np.random.randint(0, 2, qIndx.shape[0])\n",
    "\n",
    "# Choosing action\n",
    "for i, q_j in enumerate(qIndx):\n",
    "    action[i, :] = 0 \n",
    "    action[i, q_j] = 1\n",
    "    \n",
    "predQonActions = torch.masked_select(rouge_preds, autograd.Variable(action.byte()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nsent):\n",
    "    if action[i, SELECT] == 1:\n",
    "        train_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf.ix[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_i[0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [0, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, prec, f1 = rougeScores(ts_tokenized, Counter(curr_summary.split(\" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "lossf = {'loss': [], 'epoch': []}\n",
    "for epoch in range(100):\n",
    "    model.zero_grad()\n",
    "    rougue_preds = model(autograd.Variable(train_xs))\n",
    "    loss = loss_function(rougue_preds, autograd.Variable(train_ys))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lossf['loss'].append(loss.data[0])\n",
    "    lossf['epoch'].append(epoch)\n",
    "    \n",
    "perf = pd.DataFrame(lossf)\n",
    "\n",
    "perf.plot(y='loss', figsize=(12, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xs[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what do  I need to do\n",
    "1. need to save sentences to tensors\n",
    "2. need to save counter summaries to pickle objects\n",
    "3. need to make code run on small examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "['i', 'm', '45', 'and', 'my', 'son', 'is']\n"
     ]
    }
   ],
   "source": [
    "print([int(s) for s in sentences['stokens_0'][0].split(\" \") ])\n",
    "print([corpus_dict[int(w)] for w in sentences['stokens_0'][0].split(\" \") if int(w) in corpus_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueSummary = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3])\n",
    "predSummary0 = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3])\n",
    "predSummary1 = Counter([1, 1, 1, 2, 2, 2, 2, 3, 3, 4])\n",
    "predSummary2 = Counter([1, 1, 1, 2, 2, 2, 2, 3])\n",
    "predSummary3 = Counter([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rougueScores(predSummary0, trueSummary))\n",
    "print(rougueScores(predSummary1, trueSummary))\n",
    "print(rougueScores(predSummary2, trueSummary))\n",
    "print(rougueScores(predSummary3, trueSummary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputsize = 2 \n",
    "vocab_size = len(corpus_dict)\n",
    "model = BoWRegressor(outputsize, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "rougue_preds = model(autograd.Variable(train_xs))\n",
    "loss = loss_function(rougue_preds, autograd.Variable(train_ys))\n",
    "\n",
    "print(\n",
    "    (( (rougue_preds.data).cpu().numpy() - (autograd.Variable(train_ys).data).cpu().numpy() ) **2 ).mean()\n",
    "     )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "lossf = {'loss': [], 'epoch': []}\n",
    "for epoch in range(100):\n",
    "    model.zero_grad()\n",
    "    \n",
    "    rougue_preds = model(autograd.Variable(train_xs))\n",
    "    loss = loss_function(rougue_preds, autograd.Variable(train_ys))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lossf['loss'].append(loss.data[0])\n",
    "    lossf['epoch'].append(epoch)\n",
    "    \n",
    "perf = pd.DataFrame(lossf)\n",
    "\n",
    "perf.plot(y='loss', figsize=(12, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_summaries[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
