{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'csvigo'\n",
    "require 'optim'\n",
    "Plot = require 'itorch.Plot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aroraname = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/2012_aurora_shooting_first_sentence_numtext.csv'\n",
    "wordfile = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/total_corpus_smry.csv'\n",
    "nuggets = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/aurora_nuggets_numtext.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...Utils file loaded\t\n",
       "\n"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dofile(\"utils.lua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/2012_aurora_shooting_first_sentence_numtext.csv\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n",
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/total_corpus_smry.csv\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n",
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/aurora_nuggets_numtext.csv\t\n",
       "<csv>\tparsing done\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = csvigo.load({path = aroraname, mode = \"large\"})\n",
    "w = csvigo.load({path = wordfile, mode = \"large\"})\n",
    "q = csvigo.load({path = nuggets, mode = \"large\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139\telements read out of \t140\t\n"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuggs = grabNsamples(q, #q-1, nil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "K = 100\n",
    "embed_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000\telements read out of \t12510\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1000\telements read out of \t12510\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--- Extracting N samples\n",
    "out = grabNsamples(m, N, K)\n",
    "\n",
    "mxl = 0\n",
    "for k,v in pairs(out) do\n",
    "    mxl = math.max(mxl, #v)\n",
    "end\n",
    "\n",
    "--- getting the length of the dictionary\n",
    "vocab_size = 0\n",
    "for k,v in pairs(out) do\n",
    "    vocab_size = math.max(vocab_size, math.max(table.unpack(v)))\n",
    "    if (k % N)==0 then\n",
    "        print(k,'elements read out of ', #m)\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "--- Padding the data by the maximum length\n",
    "xs = padZeros(out, mxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--- labels = torch.Tensor(torch.rand(#out)*20.):reshape(#out,1)\n",
    "labels = torch.Tensor(torch.round(torch.rand(#out))):reshape(#out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--- This is the correct format to input it\n",
    "input = torch.LongTensor(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1000\n",
       "    1\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.40899724714433\t\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LT = nn.LookupTableMaskZero(vocab_size, embed_dim)\n",
    "\n",
    "-- For batch inputs, it's a little easier to start with sequence-length x batch-size tensor, so we transpose songData\n",
    "myDataT = input:t()\n",
    "batchLSTM = nn.Sequential()\n",
    "batchLSTM:add(LT) -- will return a sequence-length x batch-size x embedDim tensor\n",
    "batchLSTM:add(nn.SplitTable(1, embed_dim)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "-- print(batchLSTM:forward(myDataT)) -- sanity check\n",
    "-- now let's add the LSTM stuff\n",
    "batchLSTM:add(nn.Sequencer(nn.LSTM(embed_dim, embed_dim)))\n",
    "batchLSTM:add(nn.SelectTable(-1)) -- selects last state of the LSTM\n",
    "batchLSTM:add(nn.Linear(embed_dim, 1)) -- map last state to a score for classification\n",
    "batchLSTM:add(nn.Linear(1, 1)) -- convert score to a probability\n",
    "--- batchLSTM:add(nn.Sigmoid()) -- convert score to a probability\n",
    "myPreds = batchLSTM:forward(myDataT)\n",
    "print(#myPreds)\n",
    "-- we can now call :backward() as follows\n",
    "bceCrit = nn.MSECriterion()\n",
    "\n",
    "loss = bceCrit:forward(myPreds, labels)\n",
    "dLdPreds = bceCrit:backward(myPreds, labels)\n",
    "batchLSTM:backward(myDataT, dLdPreds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "confusion = optim.ConfusionMatrix({0,1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainSet = {inputs}\n",
    "trainSet.ivocab = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lookupDim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch=1, epochs do\n",
    "   -- Single training epoch\n",
    "   trainLoss = 0\n",
    "   confusion:zero()\n",
    "   model:training()\n",
    "   for i, inputs, targets in myDataT:sampleiter(batchSize, epochSize) do\n",
    "      xlua.progress(i, epochSize)\n",
    "      trainInputs:resize(inputs:size()):copy(inputs)\n",
    "      trainTargets:resize(targets:size()):copy(targets)\n",
    "\n",
    "      local feval = function()\n",
    "         gradParameters:zero()\n",
    "\n",
    "         -- Forward\n",
    "         local outputs = model:forward(trainInputs)\n",
    "         local f = criterion:forward(outputs, trainTargets)\n",
    "         trainLoss = trainLoss + f\n",
    "\n",
    "         -- Backward\n",
    "         local df_do = criterion:backward(outputs, trainTargets)\n",
    "         model:backward(trainInputs, df_do)\n",
    "\n",
    "         confusion:batchAdd(conOutputs, conTargets)\n",
    "         return f, gradParameters\n",
    "      end\n",
    "      optimMethod(feval, parameters, optimState)\n",
    "   end\n",
    "   confusion:updateValids()\n",
    "   if best_train_accu < confusion.totalValid then\n",
    "      print(\"Best train accuracy: \".. best_train_accu ..\n",
    "                  \" current accu: \".. confusion.totalValid)\n",
    "      best_train_accu = confusion.totalValid\n",
    "      --best_train_model = model:clone()\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = {}\n",
    "for i=1, myPreds:size()[1] do\n",
    "    preds[i] = (myPreds[i][1] > 0.5) and 1 or 0 --- lua is stupid\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ys = unpackZeros(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000\t\n"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsummary = buildPredSummary(preds, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96040609137056\t\n"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rougeRecall(predsummary, nuggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.087358020131129\t\n"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rougePrecision(predsummary, nuggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16014897579143\t\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rougeF1(predsummary, nuggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
