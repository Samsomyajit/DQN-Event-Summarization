{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "\n",
    "-- our vocabulary\n",
    "V = {[\"I\"]=1, [\"you\"]=2, [\"the\"]=3, [\"this\"]=4, [\"to\"]=5, [\"fire\"]=6, [\"Hey\"]=7, [\"is\"]=8, \n",
    "    [\"just\"]=9, [\"zee\"]=10, [\"And\"]=11, [\"just\"]=12, [\"rain\"]=13, [\"cray\"]=14, [\"met\"]=15, [\"Set\"]=16}\n",
    "\n",
    "-- get indices of words in each 5-gram\n",
    "-- zero padding is the issue\n",
    "songData = torch.LongTensor({ { V[\"Hey\"],   V[\"I\"],      V[\"just\"],  V[\"met\"],    V[\"you\"] },\n",
    "                              { V[\"And\"],   V[\"this\"],   V[\"is\"],    V[\"cray\"],   0 },\n",
    "                              ---{ V[\"And\"],   V[\"this\"],   V[\"is\"],    V[\"cray\"],   V[\"zee\"] },\n",
    "                              { V[\"Set\"],   V[\"fire\"],   V[\"to\"],    V[\"the\"],    V[\"rain\"] } })\n",
    "\n",
    "masterpieceOrNot = torch.Tensor({{1},   -- #carlyrae4ever   \n",
    "                                 {1},\n",
    "                                 {0}}) \n",
    "\n",
    "print(songData)\n",
    "-- we'll use a LookupTable to map word indices into vectors in R^6\n",
    "vocab_size = 16\n",
    "embed_dim = 6\n",
    "LT = nn.LookupTable(vocab_size, embed_dim)\n",
    "\n",
    "-- For batch inputs, it's a little easier to start with sequence-length x batch-size tensor, so we transpose songData\n",
    "songDataT = songData:t()\n",
    "batchSongLSTM = nn.Sequential()\n",
    "batchSongLSTM:add(LT) -- will return a sequence-length x batch-size x embedDim tensor\n",
    "batchSongLSTM:add(nn.SplitTable(1, 3)) -- splits into a sequence-length table with batch-size x embed Dim entries\n",
    "print(batchSongLSTM:forward(songDataT)) -- sanity check\n",
    "-- now let's add the LSTM stuff\n",
    "batchSongLSTM:add(nn.Sequencer(nn.LSTM(embed_dim, embed_dim)))\n",
    "batchSongLSTM:add(nn.SelectTable(-1)) -- selects last state of the LSTM\n",
    "batchSongLSTM:add(nn.Linear(embed_dim, 1)) -- map last state to a score for classification\n",
    "batchSongLSTM:add(nn.Sigmoid()) -- convert score to a probability\n",
    "songPreds = batchSongLSTM:forward(songDataT)\n",
    "print(songPreds)\n",
    "\n",
    "-- we can now call :backward() as follows\n",
    "bceCrit = nn.BCECriterion()\n",
    "loss = bceCrit:forward(songPreds, masterpieceOrNot)\n",
    "dLdPreds = bceCrit:backward(songPreds, masterpieceOrNot)\n",
    "batchSongLSTM:backward(songDataT, dLdPreds)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3\n",
       " 5\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#songData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  7   1  12  15   2\n",
       " 11   4   8  14  10\n",
       " 16   6   5   3  13\n",
       "[torch.LongTensor of size 3x5]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 1\n",
       " 0\n",
       "[torch.DoubleTensor of size 3x1]\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterpieceOrNot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
