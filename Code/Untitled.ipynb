{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_bowmlp(nn_vocab_module, embed_dim)\n",
    "    local model = nn.Sequential()\n",
    "    :add(nn_vocab_module)            -- returns a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.Sum(1, embed_dim, true)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.Tanh())                     ---     :add(nn.ReLU()) <- this one did worse\n",
    "   return model\n",
    "end\n",
    "\n",
    "function build_lstm(nn_vocab_module, embed_dim)\n",
    "    local model = nn.Sequential()\n",
    "    :add(nn_vocab_module)            -- returns a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.SplitTable(1, embed_dim)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Sequencer(nn.LSTM(embed_dim, embed_dim)))\n",
    "    :add(nn.SelectTable(-1)) -- selects last state of the LSTM\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.Tanh())                     ---     :add(nn.ReLU()) <- this one did worse\n",
    "   return model\n",
    "end\n",
    "\n",
    "function build_model(model, vocab_size, embed_dim, outputSize, use_cuda)\n",
    "    local nn_vocab = nn.LookupTableMaskZero(vocab_size, embed_dim)\n",
    "    if model == 'bow' then\n",
    "        print(\"Running BOW model\")\n",
    "        mod1 = build_bowmlp(nn_vocab, embed_dim)\n",
    "        mod2 = build_bowmlp(nn_vocab, embed_dim)\n",
    "        mod3 = build_bowmlp(nn_vocab, embed_dim)\n",
    "    end\n",
    "    if model == 'lstm' then         \n",
    "        print(\"Running LSTM model\")\n",
    "        mod1 = build_lstm(nn_vocab, embed_dim)\n",
    "        mod2 = build_lstm(nn_vocab, embed_dim)\n",
    "        mod3 = build_lstm(nn_vocab, embed_dim)\n",
    "    end\n",
    "\n",
    "    local ParallelModel = nn.ParallelTable()\n",
    "    ParallelModel:add(mod1)\n",
    "    ParallelModel:add(mod2)\n",
    "    ParallelModel:add(mod3)\n",
    "\n",
    "    local FinalMLP = nn.Sequential()\n",
    "    FinalMLP:add(ParallelModel)\n",
    "    FinalMLP:add(nn.JoinTable(2))\n",
    "    FinalMLP:add(nn.Linear(embed_dim * 3, 2) )\n",
    "    FinalMLP:add(nn.Max(1) )\n",
    "    FinalMLP:add(nn.Tanh())\n",
    "\n",
    "    if use_cuda then\n",
    "        return FinalMLP:cuda()\n",
    "    else\n",
    "        return FinalMLP\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_data(use_cuda)    \n",
    "    if use_cuda then\n",
    "      Tensor = torch.CudaTensor\n",
    "      LongTensor = torch.CudaLongTensor\n",
    "    else\n",
    "      Tensor = torch.Tensor\n",
    "      LongTensor = torch.LongTensor\n",
    "    end\n",
    "    sentences = LongTensor{{0, 1, 3, 4}, {0, 2, 4, 3}}:t()\n",
    "    summary = LongTensor{{0, 0, 1, 4}, {0, 2, 3, 1}}:t()\n",
    "    query = LongTensor{{0, 0, 4, 3}, {0, 0, 0, 0}}:t()\n",
    "    yrouge = torch.rand(2, 1)\n",
    "    if use_cuda then\n",
    "        return sentences, summary, query, yrouge:cuda()\n",
    "    else\n",
    "        return sentences, summary, query,  yrouge\n",
    "    end \n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usecuda = true\n",
    "model = 'lstm'\n",
    "\n",
    "batch_size = 2\n",
    "vocab_size = 4\n",
    "embed_dim = 10\n",
    "outputSize = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running LSTM model\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences, summary, query, yrouge = build_data(usecuda)\n",
    "FinalMLP  = build_model(model, vocab_size, embed_dim, outputSize, usecuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSECriterion():cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 10, loss =0.330501\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20, loss =0.232346\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 30, loss =0.169405\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 40, loss =0.127769\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 50, loss =0.099261\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 60, loss =0.079104\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 70, loss =0.064436\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 80, loss =0.053486\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 90, loss =0.045125\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 100, loss =0.038609\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch = 1, 100 do\n",
    "    preds = FinalMLP:forward({sentences, summary, query})\n",
    "    loss = criterion:forward(preds, yrouge)\n",
    "    FinalMLP:zeroGradParameters()\n",
    "    -- This is where it fails\n",
    "    grads = criterion:backward(preds, yrouge)\n",
    "    FinalMLP:backward({sentences, summary, query}, grads)\n",
    "    FinalMLP:updateParameters(learning_rate)\n",
    "    if (epoch % 10)==0 then \n",
    "        print(string.format(\"Epoch %i, loss =%6f\", epoch, loss))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.6371\n",
       " 0.1516\n",
       "[torch.CudaTensor of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:forward({sentences, summary, query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : CudaTensor - size: 2x10\n",
       "  2 : CudaTensor - size: 2x10\n",
       "  3 : CudaTensor - size: 2x10\n",
       "}\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(1).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       " 0.1126 -0.0082 -0.0498 -0.0210  0.0148  0.0800  0.0855 -0.0438 -0.1928 -0.2417\n",
       " 0.0752  0.0006  0.0027 -0.0517 -0.0013  0.1085  0.1578 -0.0228 -0.2141 -0.2149\n",
       "\n",
       "Columns 11 to 20\n",
       "-0.1578  0.1624  0.1732  0.1026 -0.0580  0.2615  0.0664 -0.0732 -0.0714 -0.3815\n",
       "-0.1720  0.0506  0.2035  0.1251 -0.1271  0.0673  0.1683  0.0636  0.0172 -0.3538\n",
       "\n",
       "Columns 21 to 30\n",
       "-0.1744  0.1986  0.0049 -0.0960  0.3064  0.2876 -0.0589  0.0099  0.3616 -0.0972\n",
       "-0.0330  0.2032  0.0038 -0.0943  0.1777  0.1872  0.0145  0.0703  0.3125 -0.1944\n",
       "[torch.CudaTensor of size 2x30]\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(2).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.7474  0.1440\n",
       " 0.7532  0.1527\n",
       "[torch.CudaTensor of size 2x2]\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(3).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.7532\n",
       " 0.1527\n",
       "[torch.CudaTensor of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(4).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.9083\n",
       " 0.2019\n",
       "[torch.CudaTensor of size 2x1]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : \n",
       "    {\n",
       "      1 : 0.7473868727684\n",
       "      2 : 0.14397549629211\n",
       "    }\n",
       "  2 : \n",
       "    {\n",
       "      1 : 0.7532479763031\n",
       "      2 : 0.15273851156235\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.totable(FinalMLP:get(3).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
