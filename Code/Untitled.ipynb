{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_bowmlp(nn_vocab_module, embed_dim)\n",
    "    local model = nn.Sequential()\n",
    "    :add(nn_vocab_module)            -- returns a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.Sum(1, embed_dim, true)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.Tanh())                     ---     :add(nn.ReLU()) <- this one did worse\n",
    "   return model\n",
    "end\n",
    "\n",
    "function build_lstm(nn_vocab_module, embed_dim)\n",
    "    local model = nn.Sequential()\n",
    "    :add(nn_vocab_module)            -- returns a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.SplitTable(1, embed_dim)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Sequencer(nn.LSTM(embed_dim, embed_dim)))\n",
    "    :add(nn.SelectTable(-1)) -- selects last state of the LSTM\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.Tanh())                     ---     :add(nn.ReLU()) <- this one did worse\n",
    "   return model\n",
    "end\n",
    "\n",
    "function build_model(model, vocab_size, embed_dim, outputSize, use_cuda)\n",
    "    local nn_vocab = nn.LookupTableMaskZero(vocab_size, embed_dim)\n",
    "    if model == 'bow' then\n",
    "        print(\"Running BOW model\")\n",
    "        mod1 = build_bowmlp(nn_vocab, embed_dim)\n",
    "        mod2 = build_bowmlp(nn_vocab, embed_dim)\n",
    "        mod3 = build_bowmlp(nn_vocab, embed_dim)\n",
    "    end\n",
    "    if model == 'lstm' then         \n",
    "        print(\"Running LSTM model\")\n",
    "        mod1 = build_lstm(nn_vocab, embed_dim)\n",
    "        mod2 = build_lstm(nn_vocab, embed_dim)\n",
    "        mod3 = build_lstm(nn_vocab, embed_dim)\n",
    "    end\n",
    "\n",
    "    local ParallelModel = nn.ParallelTable()\n",
    "    ParallelModel:add(mod1)\n",
    "    ParallelModel:add(mod2)\n",
    "    ParallelModel:add(mod3)\n",
    "\n",
    "    local FinalMLP = nn.Sequential()\n",
    "    FinalMLP:add(ParallelModel)\n",
    "    FinalMLP:add(nn.JoinTable(2))\n",
    "    FinalMLP:add(nn.Linear(embed_dim * 3, 2) )\n",
    "    FinalMLP:add(nn.Max(2) )\n",
    "    FinalMLP:add(nn.Tanh())\n",
    "\n",
    "    if use_cuda then\n",
    "        return FinalMLP:cuda()\n",
    "    else\n",
    "        return FinalMLP\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_data(use_cuda)    \n",
    "    if use_cuda then\n",
    "      Tensor = torch.CudaTensor\n",
    "      LongTensor = torch.CudaLongTensor\n",
    "    else\n",
    "      Tensor = torch.Tensor\n",
    "      LongTensor = torch.LongTensor\n",
    "    end\n",
    "--     sentences = LongTensor{{0, 1, 3, 4}, {0, 2, 4, 3}}:t()\n",
    "--     summary = LongTensor{{0, 0, 1, 4}, {0, 2, 3, 1}}:t()\n",
    "--     query = LongTensor{{0, 0, 4, 3}, {0, 0, 0, 0}}:t()\n",
    "    sentences = LongTensor{{0, 1, 3, 4}}:t()\n",
    "    summary = LongTensor{{0, 0, 1, 4}}:t()\n",
    "    query = LongTensor{{0, 0, 4, 3}}:t()\n",
    "    yrouge = torch.rand(1, 1)\n",
    "    if use_cuda then\n",
    "        return sentences, summary, query, yrouge:cuda()\n",
    "    else\n",
    "        return sentences, summary, query,  yrouge\n",
    "    end \n",
    "end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usecuda = true\n",
    "model = 'lstm'\n",
    "\n",
    "batch_size = 2\n",
    "vocab_size = 4\n",
    "embed_dim = 10\n",
    "outputSize = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running LSTM model\t\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences, summary, query, yrouge = build_data(usecuda)\n",
    "FinalMLP  = build_model(model, vocab_size, embed_dim, outputSize, usecuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSECriterion():cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01 *\n",
       " 5.5973\n",
       "[torch.CudaTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:forward({sentences, summary, query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : CudaTensor - size: 1x10\n",
       "  2 : CudaTensor - size: 1x10\n",
       "  3 : CudaTensor - size: 1x10\n",
       "}\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(1).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       "-0.0205  0.1043 -0.2179 -0.0956  0.3087  0.2872 -0.0344  0.1342 -0.0806 -0.2100\n",
       "\n",
       "Columns 11 to 20\n",
       " 0.0211  0.0392  0.0362 -0.0125 -0.0987 -0.1972 -0.2201  0.0715 -0.3361 -0.1878\n",
       "\n",
       "Columns 21 to 30\n",
       "-0.0327  0.4685  0.2249  0.1029  0.3277 -0.3009 -0.1599 -0.2130 -0.1268 -0.0288\n",
       "[torch.CudaTensor of size 1x30]\n",
       "\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(2).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01 *\n",
       "  5.6031 -7.4797\n",
       "[torch.CudaTensor of size 1x2]\n",
       "\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(3).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01 *\n",
       " 5.6031\n",
       "[torch.CudaTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(4).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.4763\n",
       "[torch.CudaTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 10, loss =0.070904\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20, loss =0.027853\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 30, loss =0.011818\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 40, loss =0.005300\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 50, loss =0.002469\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 60, loss =0.001180\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 70, loss =0.000575\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 80, loss =0.000283\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 90, loss =0.000141\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 100, loss =0.000070\t\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch = 1, 100 do\n",
    "    preds = FinalMLP:forward({sentences, summary, query})\n",
    "    loss = criterion:forward(preds, yrouge)\n",
    "    FinalMLP:zeroGradParameters()\n",
    "    -- This is where it fails\n",
    "    grads = criterion:backward(preds, yrouge)\n",
    "    FinalMLP:backward({sentences, summary, query}, grads)\n",
    "    FinalMLP:updateParameters(learning_rate)\n",
    "    if (epoch % 10)==0 then \n",
    "        print(string.format(\"Epoch %i, loss =%6f\", epoch, loss))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
