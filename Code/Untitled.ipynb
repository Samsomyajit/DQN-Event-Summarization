{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_mlp(vocab_size, embed_dim)\n",
    "    local model = nn.Sequential()\n",
    "    :add(nn.LookupTableMaskZero(vocab_size, embed_dim)) -- will return a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.SplitTable(1, embed_dim)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Sequencer(nn.LSTM(embed_dim, embed_dim)))\n",
    "    :add(nn.SelectTable(-1)) -- selects last state of the LSTM\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.ReLU())\n",
    "   return model\n",
    "end\n",
    "\n",
    "function buildLSTM(vocab_size, embed_dim)\n",
    "    local lstm = nn.Sequential()\n",
    "    lstm:add(nn.LookupTableMaskZero(vsize, edim))\n",
    "    lstm:add(nn.SplitTable(1, edim))\n",
    "    lstm:add(nn.Sequencer(nn.LSTM(edim, edim)))\n",
    "    lstm:add(nn.SelectTable(-1))\n",
    "    return lstm\n",
    "end\n",
    "\n",
    "function buildFullModel(vocab_size, embed_dim, model, use_cuda)\n",
    "    if model == 'lstm' then\n",
    "        mod1 = build_mlp(vocab_size, embed_dim, usecuda)\n",
    "        mod2 = build_mlp(vocab_size, embed_dim, usecuda)\n",
    "        mod3 = build_mlp(vocab_size, embed_dim, usecuda)\n",
    "    else         \n",
    "        mod1 = buildLSTM(vocab_size, embed_dim, usecuda)\n",
    "        mod2 = buildLSTM(vocab_size, embed_dim, usecuda)\n",
    "        mod3 = buildLSTM(vocab_size, embed_dim, usecuda)\n",
    "    end\n",
    "\n",
    "    mod4 = nn.Sequential()\n",
    "    mod4:add(nn.Linear(1, embed_dim))\n",
    "\n",
    "    ParallelModel = nn.ParallelTable()\n",
    "    ParallelModel:add(mod1)\n",
    "    ParallelModel:add(mod2)\n",
    "    ParallelModel:add(mod3)\n",
    "    ParallelModel:add(mod4)\n",
    "\n",
    "    FinalMLP = nn.Sequential()\n",
    "    FinalMLP:add(ParallelModel)\n",
    "    FinalMLP:add(nn.JoinTable(2))\n",
    "    FinalMLP:add( nn.Linear(embed_dim * 4, 2) )\n",
    "    FinalMLP = FinalMLP\n",
    "    if use_cuda then\n",
    "        return FinalMLP:cuda()\n",
    "    else\n",
    "        return FinalMLP\n",
    "    end \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_data(use_cuda)    \n",
    "    if use_cuda then\n",
    "      Tensor = torch.CudaTensor\n",
    "      LongTensor = torch.CudaLongTensor\n",
    "    else\n",
    "      Tensor = torch.Tensor\n",
    "      LongTensor = torch.LongTensor\n",
    "    end\n",
    "    sentences = LongTensor{{0, 1, 3, 4}, {0, 2, 4, 3}}:t()\n",
    "    summary = LongTensor{{0, 0, 1, 4}, {0, 2, 3, 1}}:t()\n",
    "    query = LongTensor{{0, 0, 4, 3}, {0, 0, 0, 0}}:t()\n",
    "    actions = torch.round(torch.rand(2, 1))\n",
    "    yrouge = torch.rand(2, 2)\n",
    "    if use_cuda then\n",
    "        return sentences, summary, query, actions:cuda(), yrouge:cuda()\n",
    "    else\n",
    "        return sentences, summary, query, actions, yrouge\n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0\n",
       " 1  2\n",
       " 3  4\n",
       " 4  3\n",
       "[torch.CudaLongTensor of size 4x2]\n",
       "\n",
       " 0  0\n",
       " 0  2\n",
       " 1  3\n",
       " 4  1\n",
       "[torch.CudaLongTensor of size 4x2]\n",
       "\n",
       " 0  0\n",
       " 0  0\n",
       " 4  0\n",
       " 3  0\n",
       "[torch.CudaLongTensor of size 4x2]\n",
       "\n",
       " 1\n",
       " 0\n",
       "[torch.CudaTensor of size 2x1]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sumval =\t0\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 10, loss =0.031530\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20, loss =0.005607\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 30, loss =0.000926\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 40, loss =0.000147\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 50, loss =0.000023\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 60, loss =0.000004\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 70, loss =0.000001\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 80, loss =0.000000\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 90, loss =0.000000\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 100, loss =0.000000\t\n",
       " 0  0\n",
       " 1  2\n",
       " 3  4\n",
       " 4  3\n",
       "[torch.CudaLongTensor of size 4x2]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usecuda = true\n",
    "model = 'lstm'\n",
    "\n",
    "batch_size = 2\n",
    "vocab_size = 4\n",
    "embed_dim = 10\n",
    "outputSize = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "sentences, summary, query, actions, yrouge = build_data(usecuda)\n",
    "FinalMLP  = buildFullModel(vocab_size, embed_dim, model, usecuda)\n",
    "\n",
    "criterion = nn.MSECriterion():cuda()\n",
    "\n",
    "print(sentences)\n",
    "print(summary)\n",
    "print(query)\n",
    "-- actions:resize(2,1)\n",
    "print(actions)\n",
    "\n",
    "print('sumval =', sentences[1]:sum())\n",
    "\n",
    "for epoch=1, 100 do\n",
    "    preds = FinalMLP:forward({sentences, summary, query, actions})\n",
    "    loss = criterion:forward(preds, yrouge)\n",
    "    -- This is where it fails\n",
    "    grads = criterion:backward(preds, yrouge)\n",
    "    FinalMLP:backward({sentences, summary, query, actions}, grads)\n",
    "    FinalMLP:updateParameters(learning_rate)\n",
    "    FinalMLP:zeroGradParameters()\n",
    "    if (epoch % 10)==0 then \n",
    "        print(string.format(\"Epoch %i, loss =%6f\", epoch, loss))\n",
    "    end\n",
    "end\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vsize = 4\n",
    "edim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm = nn.Sequential()\n",
    "lstm:add(nn.LookupTableMaskZero(vsize, edim))\n",
    "lstm:add(nn.SplitTable(1, edim))\n",
    "lstm:add(nn.Sequencer(nn.LSTM(edim, edim)))\n",
    "lstm:add(nn.SelectTable(-1))\n",
    "lstm:cuda()\n",
    "-- lstm:add(nn.Repeater(lstm, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = query:t()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 4\n",
       " 3\n",
       "[torch.CudaLongTensor of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:67: \nIn 1 module of nn.Sequential:\n.../torch/install/share/lua/5.1/rnn/LookupTableMaskZero.lua:12: attempt to call field 'new' (a nil value)\nstack traceback:\n\t.../torch/install/share/lua/5.1/rnn/LookupTableMaskZero.lua:12: in function <.../torch/install/share/lua/5.1/rnn/LookupTableMaskZero.lua:7>\n\t[C]: in function 'xpcall'\n\t...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'\n\t...avierarceo/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'f'\n\t[string \"local f = function() return lstm:forward{q} e...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0106e2bb90\n\nWARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above.\nstack traceback:\n\t[C]: in function 'error'\n\t...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:67: in function 'rethrowErrors'\n\t...avierarceo/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'f'\n\t[string \"local f = function() return lstm:forward{q} e...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0106e2bb90",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:67: \nIn 1 module of nn.Sequential:\n.../torch/install/share/lua/5.1/rnn/LookupTableMaskZero.lua:12: attempt to call field 'new' (a nil value)\nstack traceback:\n\t.../torch/install/share/lua/5.1/rnn/LookupTableMaskZero.lua:12: in function <.../torch/install/share/lua/5.1/rnn/LookupTableMaskZero.lua:7>\n\t[C]: in function 'xpcall'\n\t...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'\n\t...avierarceo/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'f'\n\t[string \"local f = function() return lstm:forward{q} e...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0106e2bb90\n\nWARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above.\nstack traceback:\n\t[C]: in function 'error'\n\t...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:67: in function 'rethrowErrors'\n\t...avierarceo/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'f'\n\t[string \"local f = function() return lstm:forward{q} e...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0106e2bb90"
     ]
    }
   ],
   "source": [
    "lstm:forward{q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
