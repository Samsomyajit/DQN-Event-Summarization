{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each file contains four parts separated by ‘\\n\\n’. They are\n",
    "    1. url of the original article;\n",
    "    2. sentences in the article and their labels (for sentence-based extractive summarization);\n",
    "    3. extractable highlights (for word extraction-based abstractive summarization);\n",
    "    4. named entity mapping.\n",
    "\n",
    "### Sentence labels. There are three labels for the sentences: 1, 2 and 0. \n",
    "\n",
    "    - 1: sentence should extracted; \n",
    "    - 2: sentence might be extracted; \n",
    "    - 0: sentence shouldn't be extracted.\n",
    "\n",
    "### Extractable highlights\n",
    "\n",
    "The extractable highlights are created by examining if a word (or its morphological transformation) in the highlight appears in the article or a general purpose stop-word list, which together constitute the output space (i.e., the allowed vocabulary during summary generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pth = '/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data/neuralsum/cnn/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafiles = os.listdir(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83568, '000223f0c9a759b9cdd2f86ac8c2899747937263.summary')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datafiles), datafiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleandata(input_path, files):\n",
    "    f = open(os.path.join(pth, files))\n",
    "    data = f.read()\n",
    "\n",
    "    url  = data.split(\"\\n\\n\")[0]\n",
    "    article = data.split(\"\\n\\n\")[1]\n",
    "    nuggets = data.split(\"\\n\\n\")[2]\n",
    "    entities = data.split(\"\\n\\n\")[3]\n",
    "\n",
    "    # Swapping in the entity names\n",
    "    entitykey, entityname = [], []\n",
    "    for entity in entities.split(\"\\n\"):\n",
    "        entitykey.append( entity.split(\":\")[0] )\n",
    "        entityname.append( entity.split(\":\")[1] )\n",
    "\n",
    "    edict = dict(zip(entitykey, entityname))\n",
    "\n",
    "    # Parsing the sentences and substituting\n",
    "    sentencelist, sentencelabel = [], []\n",
    "    for sentence in article.split(\"\\n\"):\n",
    "        newsentence = ' '.join([edict[word] if word in edict.keys() else word for word in sentence.split(\" \")])\n",
    "        sentencelist.append(newsentence.split(\"\\t\\t\\t\")[0])\n",
    "        sentencelabel.append(int(newsentence.split(\"\\t\\t\\t\")[1]))\n",
    "\n",
    "    # Collecting the sentences in a list\n",
    "    df = pd.DataFrame(sentencelist, columns=['Sentence'])\n",
    "    df['Label'] = sentencelabel\n",
    "\n",
    "    # Extracting the nuggets\n",
    "    highlight = []\n",
    "    for nugget in nuggets.split(\"\\n\"):\n",
    "        newnugget = ' '.join([edict[word] if word in edict.keys() else word for word in nugget.split(\" \")])\n",
    "        highlight.append(newnugget)\n",
    "        \n",
    "    # Getting the title/query\n",
    "    response = urllib2.urlopen(url)\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title = soup.findAll(\"title\")[0].text\n",
    "    return title, highlight, df, df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outpath = './data2/0-output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdf = pd.DataFrame(columns=['query_id','query','streamSize','query_filename', 'outfile_name', 'nuggetfilename'])\n",
    "\n",
    "for i, datafile in enumerate(datafiles):\n",
    "    query, nuggets, stream, streamSize = cleandata(pth, datafile)\n",
    "    outfilename = 'q%i_stream.csv' % i\n",
    "    nuggetfilename = 'q%i_nuggets.csv' % i\n",
    "    tmpdf = pd.DataFrame( [i, query, streamSize, datafile, outfilename, nuggetfilename] ).T\n",
    "    tmpdf.columns = ['query_id','query','streamSize','query_filename', 'outfile_name', 'nuggetfilename']\n",
    "    outdf = pd.concat([outdf, tmpdf], axis=0)\n",
    "    stream.to_csv(outpath + )\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kyrgyzstan violence has claimed many lives , forced many from their homes',\n",
       " 'Scott Horton , Baktybek Abdrisaev say U.S. , Russia have done little in response',\n",
       " 'they say the two nations have *responsibility* to help ease the suffering',\n",
       " 'coordinated action could end the humanitarian crisis , they say']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuggets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>streamSize</th>\n",
       "      <th>query_filename</th>\n",
       "      <th>outfile_name</th>\n",
       "      <th>nuggetfilename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mistaken for your child's grandmother - CNN.com</td>\n",
       "      <td>61</td>\n",
       "      <td>000223f0c9a759b9cdd2f86ac8c2899747937263.summary</td>\n",
       "      <td>q0_stream.csv</td>\n",
       "      <td>q0_nuggets.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Arraignment for 8 current, former Bell, Califo...</td>\n",
       "      <td>36</td>\n",
       "      <td>00030b9744b6d8c21d3a9fcb35460b06d3a71e2e.summary</td>\n",
       "      <td>q1_stream.csv</td>\n",
       "      <td>q1_nuggets.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>U.S. and Russia can end the suffering - CNN.com</td>\n",
       "      <td>49</td>\n",
       "      <td>00036c4d44d9af8d34280086a887f3b7847cdae1.summary</td>\n",
       "      <td>q2_stream.csv</td>\n",
       "      <td>q2_nuggets.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id                                              query streamSize  \\\n",
       "0        0    Mistaken for your child's grandmother - CNN.com         61   \n",
       "0        1  Arraignment for 8 current, former Bell, Califo...         36   \n",
       "0        2    U.S. and Russia can end the suffering - CNN.com         49   \n",
       "\n",
       "                                     query_filename   outfile_name  \\\n",
       "0  000223f0c9a759b9cdd2f86ac8c2899747937263.summary  q0_stream.csv   \n",
       "0  00030b9744b6d8c21d3a9fcb35460b06d3a71e2e.summary  q1_stream.csv   \n",
       "0  00036c4d44d9af8d34280086a887f3b7847cdae1.summary  q2_stream.csv   \n",
       "\n",
       "   nuggetfilename  \n",
       "0  q0_nuggets.csv  \n",
       "0  q1_nuggets.csv  \n",
       "0  q2_nuggets.csv  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
