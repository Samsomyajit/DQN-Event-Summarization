{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each file contains four parts separated by ‘\\n\\n’. They are\n",
    "    1. url of the original article;\n",
    "    2. sentences in the article and their labels (for sentence-based extractive summarization);\n",
    "    3. extractable highlights (for word extraction-based abstractive summarization);\n",
    "    4. named entity mapping.\n",
    "\n",
    "### Sentence labels. There are three labels for the sentences: 1, 2 and 0. \n",
    "\n",
    "    - 1: sentence should extracted; \n",
    "    - 2: sentence might be extracted; \n",
    "    - 0: sentence shouldn't be extracted.\n",
    "\n",
    "### Extractable highlights\n",
    "\n",
    "The extractable highlights are created by examining if a word (or its morphological transformation) in the highlight appears in the article or a general purpose stop-word list, which together constitute the output space (i.e., the allowed vocabulary during summary generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import urllib2\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildEntityDictionary(input_path, filenames):\n",
    "    # Swapping in the entity names\n",
    "    entitykey, entityname = [], []\n",
    "    for filename in filenames:\n",
    "        f = open(os.path.join(input_path, filename))\n",
    "        data = f.read()\n",
    "        entities = data.split(\"\\n\\n\")[3]\n",
    "\n",
    "        for entity in entities.split(\"\\n\"):\n",
    "            entitykey.append( entity.split(\":\")[0] )\n",
    "            entityname.append( entity.split(\":\")[1] )\n",
    "\n",
    "    edictionary = dict(zip(entitykey, entityname))\n",
    "    return edictionary    \n",
    "\n",
    "def cleandata(input_path, files, edict):\n",
    "    f = open(os.path.join(input_path, files))\n",
    "    data = f.read()\n",
    "\n",
    "    url  = data.split(\"\\n\\n\")[0]\n",
    "    article = data.split(\"\\n\\n\")[1]\n",
    "    nuggets = data.split(\"\\n\\n\")[2]\n",
    "    entities = data.split(\"\\n\\n\")[3]\n",
    "\n",
    "    # Parsing the sentences and substituting\n",
    "    sentencelist, sentencelabel = [], []\n",
    "    for sentence in article.split(\"\\n\"):\n",
    "        # Swapping in the entity names\n",
    "        sentencelabel.append(int(sentence.split(\"\\t\\t\\t\")[1]))\n",
    "        sentence = sentence.split(\"\\t\\t\\t\")[0]\n",
    "        newsentence = ' '.join([edict[word] if word in edict else word for word in sentence.split(\" \")])\n",
    "        sentencelist.append(newsentence)\n",
    "\n",
    "    # Collecting the sentences in a list\n",
    "    df = pd.DataFrame(sentencelist, columns=['Sentence'])\n",
    "    df['Label'] = sentencelabel\n",
    "\n",
    "    # Extracting the nuggets\n",
    "    highlight = []\n",
    "    for nugget in nuggets.split(\"\\n\"):\n",
    "        newnugget = ' '.join([edict[word] if word in edict else word for word in nugget.split(\" \")])\n",
    "        highlight.append(newnugget)\n",
    "\n",
    "    nuggets = pd.DataFrame(highlight, columns=['Nugget'])\n",
    "    # Getting the title/query\n",
    "#    html = requests.get(url).text\n",
    "    html = urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        title = soup.findAll(\"title\")[0].text\n",
    "    except:\n",
    "        title = 'MISSING'\n",
    "    return title, nuggets, df, df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputpath = '/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data/neuralsum/cnn/training/'\n",
    "outputpath = '/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/0-output'\n",
    "# datafiles = os.listdir(inputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edict = buildEntityDictionary(inputpath, datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filelist = os.listdir(outputpath)\n",
    "finished = [int(x.replace(\"q\",'').replace(\"_stream.csv\", '')) for x in filelist if 'stream.csv' in x]\n",
    "finishedval = max(finished)\n",
    "# outdf = pd.DataFrame(columns=['query_id','query','streamSize','query_filename', 'outfile_name', 'nuggetfilename'])\n",
    "\n",
    "for i, datafile in enumerate(datafiles):\n",
    "    if i > finishedval:\n",
    "        query, nuggets, stream, streamSize = cleandata(inputpath, datafile, edict)\n",
    "        outfilename = 'q%i_stream.csv' % i\n",
    "        nuggetfilename = 'q%i_nuggets.csv' % i\n",
    "        tmpdf = pd.DataFrame( [i, query, streamSize, datafile, outfilename, nuggetfilename] ).T\n",
    "        tmpdf.columns = ['query_id','query','streamSize','query_filename', 'outfile_name', 'nuggetfilename']\n",
    "        outdf = pd.concat([outdf, tmpdf], axis=0)\n",
    "        stream.to_csv(os.path.join(outputpath, outfilename), index=False)\n",
    "        nuggets.to_csv(os.path.join(outputpath, nuggetfilename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdf.to_csv(\"/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/1-output/cnn_trainingqueries.csv\", \n",
    "             index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finalinputdir = '/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/0-output/'\n",
    "finaloutputdir = '/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/1-output/'\n",
    "\n",
    "finalinputfiles = os.listdir(finalinputdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "streams = [(int(x.split(\"_\")[0].replace(\"q\",'')), x) for x in finalinputfiles if '_stream.csv' in x]\n",
    "nuggets = [(int(x.split(\"_\")[0].replace(\"q\",'')), x) for x in finalinputfiles if '_nuggets.csv' in x]\n",
    "\n",
    "streamsummary = pd.DataFrame(streams, columns=['query_id','streamname'])\n",
    "nuggetsummary = pd.DataFrame(nuggets, columns=['query_id','nuggetname'])\n",
    "\n",
    "fulldf = pd.merge(streamsummary, nuggetsummary, how='inner', left_on = 'query_id', right_on='query_id')\n",
    "dupes = outdf.drop_duplicates(inplace=False)['query_id'].value_counts().reset_index()\n",
    "dupes.columns = ['query_id', 'count']\n",
    "dupes = dupes[dupes['count'] > 1]\n",
    "dedupefilter = outdf['query_id'].isin(dupes['query_id'])==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exporting files\n",
    "outdf[dedupefilter].to_csv(\n",
    "    \"/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/1-output/cnn_trainingqueries.csv\", \n",
    "             index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85198, 2541426)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdf.shape[0], outdf[dedupefilter]['streamSize'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.829643888354187"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdf[dedupefilter]['streamSize'].sum() / float(outdf.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data back in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib2\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalinputdir = '/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/0-output/'\n",
    "finaloutputdir = '/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/1-output/'\n",
    "\n",
    "finalinputfiles = os.listdir(finalinputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdf = pd.read_csv(\"/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/1-output/cnn_trainingqueries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(inputdir, odf_row):\n",
    "        cleanedstreams = pd.read_csv(inputdir + odf_row['outfile_name'])\n",
    "        cleanedstreams['query'] = odf_row['query'].replace(\" - CNN.com\", \"\")\n",
    "        cleanedstreams['query_id'] = odf_row['query_id']\n",
    "        cleanedstreams['true_summary'] = ' '.join(cleanedstreams[cleanedstreams['Label']==1].Sentence)\n",
    "        cleanedstreams['sentence_idx'] = cleanedstreams.index\n",
    "        return cleanedstreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "streams = Parallel(n_jobs=-1)(\n",
    "    delayed(extract_data)(finalinputdir, row) for i, row in outdf.iterrows()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanedstreams = pd.concat(streams)\n",
    "cleanedstreams = cleanedstreams[['query_id', 'sentence_idx', 'Label','query','Sentence', 'true_summary']]\n",
    "cleanedstreams.columns = [x.lower() for x in cleanedstreams.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>label</th>\n",
       "      <th>query</th>\n",
       "      <th>sentence</th>\n",
       "      <th>true_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>-- i 'm 45 , and my son is 7</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>once in a while , i still get carded when i tr...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>i was 38 when Dominican Republic Emergency Ope...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>both incidents took place after i moved from A...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>i thought about the incidents when i read a re...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  sentence_idx  label                                  query  \\\n",
       "0         0             0      1  Mistaken for your child's grandmother   \n",
       "1         0             1      1  Mistaken for your child's grandmother   \n",
       "2         0             2      1  Mistaken for your child's grandmother   \n",
       "3         0             3      1  Mistaken for your child's grandmother   \n",
       "4         0             4      2  Mistaken for your child's grandmother   \n",
       "\n",
       "                                            sentence  \\\n",
       "0                       -- i 'm 45 , and my son is 7   \n",
       "1  once in a while , i still get carded when i tr...   \n",
       "2  i was 38 when Dominican Republic Emergency Ope...   \n",
       "3  both incidents took place after i moved from A...   \n",
       "4  i thought about the incidents when i read a re...   \n",
       "\n",
       "                                        true_summary  \n",
       "0  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "1  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "2  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "3  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "4  -- i 'm 45 , and my son is 7 once in a while ,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedstreams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanedstreams.to_csv(\n",
    "    \"/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/1-output/cnn_trainingstreams.csv\", \n",
    "             index=False, encoding='utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>label</th>\n",
       "      <th>query</th>\n",
       "      <th>sentence</th>\n",
       "      <th>true_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>-- i 'm 45 , and my son is 7</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>once in a while , i still get carded when i tr...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>i was 38 when Dominican Republic Emergency Ope...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>both incidents took place after i moved from A...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>i thought about the incidents when i read a re...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  sentence_idx  label                                  query  \\\n",
       "0         0             0      1  Mistaken for your child's grandmother   \n",
       "1         0             1      1  Mistaken for your child's grandmother   \n",
       "2         0             2      1  Mistaken for your child's grandmother   \n",
       "3         0             3      1  Mistaken for your child's grandmother   \n",
       "4         0             4      2  Mistaken for your child's grandmother   \n",
       "\n",
       "                                            sentence  \\\n",
       "0                       -- i 'm 45 , and my son is 7   \n",
       "1  once in a while , i still get carded when i tr...   \n",
       "2  i was 38 when Dominican Republic Emergency Ope...   \n",
       "3  both incidents took place after i moved from A...   \n",
       "4  i thought about the incidents when i read a re...   \n",
       "\n",
       "                                        true_summary  \n",
       "0  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "1  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "2  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "3  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "4  -- i 'm 45 , and my son is 7 once in a while ,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedstreams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 750M (CNMeM is disabled, cuDNN 5004)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import gzip\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/data2/1-output/cnn_trainingstreams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>label</th>\n",
       "      <th>query</th>\n",
       "      <th>sentence</th>\n",
       "      <th>true_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>-- i 'm 45 , and my son is 7</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>once in a while , i still get carded when i tr...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>i was 38 when Dominican Republic Emergency Ope...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>both incidents took place after i moved from A...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>i thought about the incidents when i read a re...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  sentence_idx  label                                  query  \\\n",
       "0         0             0      1  Mistaken for your child's grandmother   \n",
       "1         0             1      1  Mistaken for your child's grandmother   \n",
       "2         0             2      1  Mistaken for your child's grandmother   \n",
       "3         0             3      1  Mistaken for your child's grandmother   \n",
       "4         0             4      2  Mistaken for your child's grandmother   \n",
       "\n",
       "                                            sentence  \\\n",
       "0                       -- i 'm 45 , and my son is 7   \n",
       "1  once in a while , i still get carded when i tr...   \n",
       "2  i was 38 when Dominican Republic Emergency Ope...   \n",
       "3  both incidents took place after i moved from A...   \n",
       "4  i thought about the incidents when i read a re...   \n",
       "\n",
       "                                        true_summary  \n",
       "0  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "1  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "2  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "3  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "4  -- i 'm 45 , and my son is 7 once in a while ,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "ntexts, qtexts = [], []\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "df['true_summary'] = df['true_summary'].str.replace('[^A-Za-z0-9]+', ' ').str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def str_split(string):\n",
    "    return string.split(\" \")\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "summary_texts = Parallel(n_jobs=-1)(\n",
    "    delayed(str_split)(row['true_summary'])  for i, row in df.iterrows()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "ntexts, qtexts = [], []\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "df['true_summary'] = df['true_summary'].str.replace('[^A-Za-z0-9]+', ' ').str.strip().str.lower()\n",
    "texts = [t.split(\" \") for t in df['true_summary'] ]\n",
    "\n",
    "if 'nuggets' in infilename:\n",
    "    df = pd.read_csv(infilename)\n",
    "    df['nugget_text'] = df['nugget_text'].str.replace('[^A-Za-z0-9]+', ' ').str.strip().str.lower()\n",
    "    texts = [t.split(\" \") for t in df['nugget_text'] ]\n",
    "    ntexts.append(texts)\n",
    "\n",
    "if infilename in qfilenames:\n",
    "    texts = loadQuery(infilename)\n",
    "    qtexts.append(texts)\n",
    "\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [ [token for token in text] for text in texts]\n",
    "# Collecting all the list of tokens\n",
    "all_tokens.append(texts)\n",
    "\n",
    "texts  = sum(all_tokens, [])\n",
    "qtexts = sum(qtexts, [])\n",
    "ntexts = sum(ntexts, [])\n",
    "\n",
    "# Getting the dictionary with token info\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Mapping to numeric list -- adding plus one to tokens\n",
    "dictionary.token2id = {k: v+1 for k,v in dictionary.token2id.items()}\n",
    "word2idx = dictionary.token2id\n",
    "\n",
    "dictionary.id2token = {v:k for k,v in dictionary.token2id.items()}\n",
    "idx2word = dictionary.id2token\n",
    "\n",
    "# Exporting the dictionaries\n",
    "print(\"Exporting word to index and dictionary to word indices\")\n",
    "output = open(os.path.join(inputdir,'0-output/LSTMDQN_Dic_token2id.pkl'), 'ab+')\n",
    "pickle.dump(word2idx, output)\n",
    "output.close()\n",
    "\n",
    "output = open(os.path.join(inputdir,'0-output/LSTMDQN_Dic_id2token.pkl'), 'ab+')\n",
    "pickle.dump(idx2word, output)\n",
    "output.close()\n",
    "\n",
    "# Merging the dictionaries toa pandas data frame with summary info\n",
    "odf0 = pd.DataFrame.from_dict(dictionary.dfs, orient='index').reset_index()\n",
    "odf1 = pd.DataFrame.from_dict(word2idx, orient='index').reset_index()\n",
    "\n",
    "odf0.columns = ['id', 'frequency']\n",
    "odf1.columns = ['token', 'id']\n",
    "# Merge by token id\n",
    "odf = pd.merge(left=odf0, right=odf1, on='id')\n",
    "odf = odf[['id','token', 'frequency']]\n",
    "# Exporting data\n",
    "odf.to_csv(os.path.join(inputdir, '0-output/total_corpus_smry.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>label</th>\n",
       "      <th>query</th>\n",
       "      <th>sentence</th>\n",
       "      <th>true_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>-- i 'm 45 , and my son is 7</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>once in a while , i still get carded when i tr...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>i was 38 when Dominican Republic Emergency Ope...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>both incidents took place after i moved from A...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Mistaken for your child's grandmother</td>\n",
       "      <td>i thought about the incidents when i read a re...</td>\n",
       "      <td>-- i 'm 45 , and my son is 7 once in a while ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id  sentence_idx  label                                  query  \\\n",
       "0         0             0      1  Mistaken for your child's grandmother   \n",
       "1         0             1      1  Mistaken for your child's grandmother   \n",
       "2         0             2      1  Mistaken for your child's grandmother   \n",
       "3         0             3      1  Mistaken for your child's grandmother   \n",
       "4         0             4      2  Mistaken for your child's grandmother   \n",
       "\n",
       "                                            sentence  \\\n",
       "0                       -- i 'm 45 , and my son is 7   \n",
       "1  once in a while , i still get carded when i tr...   \n",
       "2  i was 38 when Dominican Republic Emergency Ope...   \n",
       "3  both incidents took place after i moved from A...   \n",
       "4  i thought about the incidents when i read a re...   \n",
       "\n",
       "                                        true_summary  \n",
       "0  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "1  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "2  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "3  -- i 'm 45 , and my son is 7 once in a while ,...  \n",
       "4  -- i 'm 45 , and my son is 7 once in a while ,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedstreams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "streams = Parallel(n_jobs=-1)(\n",
    "    delayed(extract_data)(finalinputdir, row) for i, row in outdf.iterrows()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
