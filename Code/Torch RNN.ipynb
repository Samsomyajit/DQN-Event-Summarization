{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'rnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_network(vocab_size, embed_dim)\n",
    "    model = nn.Sequential()\n",
    "    :add(nn.LookupTableMaskZero(vocab_size, embed_dim)) -- returns a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.Sum(1, embed_dim, true)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.Tanh())                     ---     :add(nn.ReLU()) <- this one did worse\n",
    "   return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = torch.LongTensor{{0, 1, 2 ,3, 4}, {0, 0, 1, 4, 3}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnm = build_network(4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0174  0.0265 -0.1396 -0.2375  0.1837 -0.1387  0.0207 -0.1156  0.2890  0.0694\n",
       "-0.0713  0.0036 -0.1932 -0.2810  0.1266  0.0023 -0.1511 -0.1335  0.1808  0.1197\n",
       "[torch.DoubleTensor of size 2x10]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnm:forward(x:t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...Utils file loaded\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'csvigo'\n",
    "\n",
    "--- Loading utility script\n",
    "dofile(\"utils.lua\")\n",
    "dofile(\"model_utils.lua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/2012_aurora_shooting_first_sentence_numtext.csv\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n",
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/aurora_nuggets_numtext.csv\t\n",
       "<csv>\tparsing done\t\n",
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/queries_numtext.csv\t\n",
       "<csv>\tparsing done\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aurora_fn = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/2012_aurora_shooting_first_sentence_numtext.csv'\n",
    "nugget_fn = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/aurora_nuggets_numtext.csv'\n",
    "query_fn = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/queries_numtext.csv'\n",
    "\n",
    "data_file = csvigo.load({path = aurora_fn, mode = \"large\"})\n",
    "nugget_file = csvigo.load({path = nugget_fn, mode = \"large\"})\n",
    "query_file =  csvigo.load({path = query_fn, mode = \"large\"})\n",
    "\n",
    "rK = 100\n",
    "nbatches = 50\n",
    "nepochs = 100\n",
    "print_every = 10\n",
    "embed_dim = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "cuts = 4.                  --- This is the number of cuts we want\n",
    "epsilon = 1.\n",
    "base_explore_rate = 0.1\n",
    "delta = 1./(nepochs/cuts) --- Only using epsilon greedy strategy for (nepochs/cuts)% of the epochs\n",
    "\n",
    "cuda = true\n",
    "torch.manualSeed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_network(vocab_size, embed_dim)\n",
    "    model = nn.Sequential()\n",
    "    :add(nn.LookupTableMaskZero(vocab_size, embed_dim)) -- will return a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.SplitTable(1, embed_dim)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Sequencer(nn.LSTM(embed_dim, embed_dim)))\n",
    "    :add(nn.SelectTable(-1)) -- selects last state of the LSTM\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.ReLU())\n",
    "   return model\n",
    "end\n",
    "function build_model(vocab_size, embed_dim, outputSize)\n",
    "    lstm1 = build_network(vocab_size, embed_dim)\n",
    "    lstm2 = build_network(vocab_size, embed_dim)\n",
    "    lstm3 = build_network(vocab_size, embed_dim)\n",
    "\n",
    "    mlp1 = nn.Sequential()\n",
    "    mlp1:add(nn.Linear(1, embed_dim))\n",
    "    mlp1:add(nn.ReLU())\n",
    "\n",
    "    ParallelModel = nn.ParallelTable()\n",
    "    ParallelModel:add(lstm1)\n",
    "    ParallelModel:add(lstm2)\n",
    "    ParallelModel:add(lstm3)\n",
    "    ParallelModel:add(mlp1)\n",
    "\n",
    "    FinalMLP = nn.Sequential()\n",
    "    FinalMLP:add(ParallelModel)\n",
    "    FinalMLP:add(nn.JoinTable(2))\n",
    "    FinalMLP:add( nn.Linear(embed_dim * 4, outputSize) )\n",
    "    return FinalMLP\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_sized = getVocabSize(data_file)                       --- getting length of dictionary\n",
    "vocab_sizeq = getVocabSize(query_file)                      --- getting length of dictionary\n",
    "vocab_size = math.max(vocab_sized, vocab_sizeq)\n",
    "\n",
    "queries = grabNsamples(query_file, #query_file-1, nil)      --- Extracting all queries\n",
    "nuggets = grabNsamples(nugget_file, #nugget_file-1, nil)    --- Extracting all samples\n",
    "maxlend = getMaxseq(data_file)                             --- Extracting maximum sequence length\n",
    "maxlenq = getMaxseq(query_file)                            --- Extracting maximum sequence length\n",
    "maxlen = math.max(maxlenq, maxlend)\n",
    "\n",
    "batchLSTM = build_model(vocab_size, embed_dim, 1)\n",
    "crit = nn.MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dofile(\"model_utils.lua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = iterateModel( nbatches, nepochs, queries[3], data_file, batchLSTM, crit, epsilon, delta, \n",
    "                    maxlen, base_explore_rate, print_every, nuggets, learning_rate, rK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rscores, pscores, fscores = {}, {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data_file\n",
    "K = rK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_list = torch.totable(torch.round(torch.rand(#x)))\n",
    "yrouge = torch.totable(torch.randn(#x))\n",
    "summary_list = populateOnes(#x, K)\n",
    "action_list = torch.totable(torch.round(torch.randn(#x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qs = queries[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nstart = 2\n",
    "nend = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_ss  = geti_n(x, nstart, nend)\n",
    "xout  = grabNsamples(x_ss, 1, #x_ss)\n",
    "xs  = padZeros(xout, maxlen)\n",
    "qs2 = padZeros({qs}, 5)\n",
    "qrep = repeatQuery(qs2[1], #xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = geti_n(preds_list, nstart, nend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumry_ss = buildPredSummary(preds, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumry_ss2 = padZeros(sumry_ss, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yr_ss = geti_n(yrouge, nstart, nend)\n",
    "as_ss = geti_n(action_list, nstart, nend)\n",
    "sentences = torch.LongTensor(xs):t()\n",
    "summary = torch.LongTensor(sumry_ss2):t()\n",
    "query = torch.LongTensor(qrep):t()\n",
    "actions = torch.Tensor(as_ss):resize(#xs, 1)\n",
    "labels = torch.Tensor(yr_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = batchLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myPreds = model:forward({sentences, summary, query, actions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = loss + crit:forward(myPreds, labels)\n",
    "grads = crit:backward(myPreds, labels)\n",
    "model:backward({sentences, summary, query, actions}, grads)\n",
    "model:updateParameters(learning_rate)        -- Update parameters after each minibatch\n",
    "model:zeroGradParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = policy(myPreds, epsilon, #xs)\n",
    "--- Concatenating predictions into a summary\n",
    "predsummary = buildPredSummary(preds, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function getLastK(x, K)\n",
    "    out = {}\n",
    "    k = 0\n",
    "    for i=0, #x-1 do\n",
    "        if sumTable(x[#x - i])  ~= 0 then\n",
    "            if k <= K-1 then\n",
    "                --- 10 - 0 - 1 = 9..., 8, 7 ..., 1\n",
    "                out[#x-i-1] = x[#x - i]\n",
    "                k = k + 1\n",
    "            else\n",
    "                return out\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = {\n",
    "        {0, 1, 3, 4, 5}, \n",
    "        {1, 2, 3, 4, 5}, \n",
    "        {0, 0, 3, 4, 0}, \n",
    "        {0, 3, 1, 2, 5},\n",
    "        {1, 1, 1, 1, 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 2\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 5\n",
       "    }\n",
       "  2 : \n",
       "    {\n",
       "      1 : 0\n",
       "      2 : 0\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 0\n",
       "    }\n",
       "  3 : \n",
       "    {\n",
       "      1 : 0\n",
       "      2 : 3\n",
       "      3 : 1\n",
       "      4 : 2\n",
       "      5 : 5\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geti_n(x, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  2 : \n",
       "    {\n",
       "      1 : 0\n",
       "      2 : 3\n",
       "      3 : 1\n",
       "      4 : 2\n",
       "      5 : 5\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getLastK(geti_n(x, 2, 4), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : \n",
       "    {\n",
       "      1 : 1\n",
       "      2 : 2\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 5\n",
       "    }\n",
       "  2 : \n",
       "    {\n",
       "      1 : 0\n",
       "      2 : 0\n",
       "      3 : 3\n",
       "      4 : 4\n",
       "      5 : 0\n",
       "    }\n",
       "  3 : \n",
       "    {\n",
       "      1 : 0\n",
       "      2 : 3\n",
       "      3 : 1\n",
       "      4 : 2\n",
       "      5 : 5\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getLastK(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--- Initializing rouge metrics at time {t-1} and save scores\n",
    "for i=1, #predsummary do\n",
    "    --- Calculating rouge scores; Call get_i_n() to cumulatively compute rouge\n",
    "    rscores[i] = rougeRecall(geti_n(predsummary, 1, i), nuggets, K) - r_t1\n",
    "    pscores[i] = rougePrecision(geti_n(predsummary, 1, i), nuggets, K) - p_t1\n",
    "    fscores[i] = rougeF1(geti_n(predsummary, 1, i), nuggets, K) - f_t1\n",
    "    r_t1, p_t1, f_t1 = rscores[i], pscores[i], fscores[i]\n",
    "end\n",
    "--- Updating change in rouge\n",
    "yrouge = updateTable(yrouge, fscores, nstart)\n",
    "preds_list = updateTable(preds_list, preds, nstart)\n",
    "--- Calculating last one to see actual last rouge, without delta\n",
    "rscore = rougeRecall(predsummary, nuggets, K)\n",
    "pscore = rougePrecision(predsummary, nuggets, K)\n",
    "fscore = rougeF1(predsummary, nuggets, K)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
