{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'csvigo'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 'lstm'\n",
    "nepochs = 200\n",
    "K_tokens = 20\n",
    "J_sentences = 10\n",
    "batch_size = 100\n",
    "thresh = 0.00\n",
    "embed_dim = 100\n",
    "learning_rate = 0.1\n",
    "print_every = 1\n",
    "epsilon = 1\n",
    "usecuda = false\n",
    "epsilon = 1\n",
    "cuts = 4\n",
    "base_explore_rate = 0.0\n",
    "skip_rate = 0.\n",
    "metric = 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...Utils file loaded\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--- Loading utility script\n",
    "dofile(\"utils.lua\")\n",
    "dofile(\"model_utils.lua\")\n",
    "\n",
    "torch.manualSeed(420)\n",
    "math.randomseed(420)\n",
    "\n",
    "data_path = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/'\n",
    "\n",
    "query_fn = data_path .. 'queries_numtext.csv'\n",
    "query_file =  csvigo.load({path = query_fn, mode = \"large\", verbose = false})\n",
    "queries = buildTermDocumentTable(query_file, nil)\n",
    "\n",
    "pakistan = {\n",
    "        ['inputs'] = '2012_pakistan_garment_factory_fires_first_sentence_numtext2.csv',\n",
    "        ['nuggets'] ='pakistan_nuggets_numtext.csv',\n",
    "        ['query'] = queries[2],\n",
    "        ['query_name'] = 'pakistan'\n",
    "}\n",
    "aurora = {\n",
    "        ['inputs'] = '2012_aurora_shooting_first_sentence_numtext2.csv', \n",
    "        ['nuggets'] = 'aurora_nuggets_numtext.csv',\n",
    "        ['query'] = queries[3],\n",
    "        ['query_name'] = 'aurora'\n",
    "}\n",
    "sandy = {\n",
    "        ['inputs'] = 'hurricane_sandy_first_sentence_numtext2.csv',\n",
    "        ['nuggets'] ='sandy_nuggets_numtext.csv',\n",
    "        ['query'] = queries[7],\n",
    "        ['query_name'] = 'sandy'\n",
    "}\n",
    "\n",
    "inputs = {\n",
    "        aurora, \n",
    "        -- pakistan,\n",
    "        -- sandy\n",
    "    }\n",
    "--- Only using epsilon greedy strategy for (nepochs/cuts)% of the epochs\n",
    "delta = 1./(nepochs/cuts) \n",
    "crit = nn.MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path, query_file, batch_size, nepochs, inputs = data_path, query_file, batch_size, nepochs, inputs\n",
    "model, crit, thresh, embed_dim, epsilon, delta = model, crit, thresh, embed_dim, epsilon, delta\n",
    "base_explore_rate, print_every, learning_rate, J_sentences, K_tokens, use_cuda =base_explore_rate, print_every,learning_rate, J_sentences, K_tokens, usecuda\n",
    "skiprate, emetric =  skip_rate, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...running on CPU\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_cuda then\n",
    "  Tensor = torch.CudaTensor\n",
    "  LongTensor = torch.CudaLongTensor\n",
    "  crit = crit:cuda()\n",
    "  print(\"...running on GPU\")\n",
    "else\n",
    "  Tensor = torch.Tensor\n",
    "  LongTensor = torch.LongTensor\n",
    "  print(\"...running on CPU\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 0\n",
    "maxseqlen = 0\n",
    "maxseqlenq = getMaxseq(query_file)\n",
    "\n",
    "action_query_list = {}\n",
    "yrougue_query_list = {}\n",
    "pred_query_list = {}\n",
    "\n",
    "for query_id = 1, #inputs do\n",
    "    input_fn = inputs[query_id]['inputs']\n",
    "    nugget_fn = inputs[query_id]['nuggets']\n",
    "\n",
    "    input_file = csvigo.load({path = input_path .. input_fn, mode = \"large\", verbose = false})\n",
    "    nugget_file = csvigo.load({path = input_path .. nugget_fn, mode = \"large\", verbose = false})\n",
    "\n",
    "    vocab_sized = getVocabSize(input_file)\n",
    "    vocab_sizeq = getVocabSize(query_file)\n",
    "    vocab_size = math.max(vocab_size, vocab_sized, vocab_sizeq)\n",
    "\n",
    "    maxseqlend = getMaxseq(input_file)\n",
    "    maxseqlen = math.max(maxseqlen, maxseqlenq, maxseqlend)\n",
    "    action_list = torch.totable(torch.round(torch.rand(#input_file)))\n",
    "    action_list[1] = 0\n",
    "\n",
    "    --- initialize the query specific lists\n",
    "    action_query_list[query_id] = action_list\n",
    "    yrougue_query_list[query_id] = torch.totable(torch.randn(#input_file, 2)) --- Actual\n",
    "    pred_query_list[query_id] = torch.totable(torch.zeros(#input_file, 2))    --- Predicted\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running LSTM model\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- model  = build_model(model, vocab_size, embed_dim, 2, use_cuda)\n",
    "model  = build_model2(model, vocab_size, embed_dim, 1, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "minibatch = 1\n",
    "query_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unpackZeros(torch.totable(summary:t()[1])),\n",
    "unpackZeros(torch.totable(sentences:t()[1])),\n",
    "actions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst2 = buildCurrentSummary(torch.totable(actions1), xout, K_tokens * J_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function buildCurrentSummary(preds, xs, K)\n",
    "    local out = {}\n",
    "    for i = 1, #xs do\n",
    "        if i == 1 then\n",
    "            out[i] = {}\n",
    "        elseif i == 2 then\n",
    "            tmp = x_or_pass(preds[i-1], unpackZeros(xs[i-1])) \n",
    "            out[i] = getLastKElements(tmp, K)\n",
    "        else \n",
    "            local tmp = tableConcat(out[i-2], x_or_pass(preds[i-1], unpackZeros(xs[i-1])))\n",
    "            out[i] = getLastKElements(tmp, K)\n",
    "        end \n",
    "    end\n",
    "    return out \n",
    "end\n",
    "\n",
    "function buildPredSummary2(preds, xs, K)\n",
    "    --- This function is used to map the token indices to extract the summary\n",
    "    --- and produceds {token_id, 0, token_id} from any given *selected* sentence\n",
    "    local out = {}\n",
    "    for i=1, #xs do\n",
    "        if i == 1 then \n",
    "            out[i] = x_or_pass(preds[i][1], unpackZeros(xs[i]))\n",
    "        else \n",
    "            --- Update it by adding xs_i and out_{i-1}\n",
    "            local tmp = tableConcat(out[i-1], x_or_pass(preds[i][1], unpackZeros(xs[i])))\n",
    "            --- Getting the last K tokens because we want to keep last K tokens\n",
    "            out[i] =  getLastKElements(tmp, K)\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst1 = buildPredSummary(torch.totable(actions1), xout, K_tokens * J_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atmp = geti_n(torch.totable(actions1),4, 6 )\n",
    "xtmp = geti_n(xout, 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "atmp, xtmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_or_pass(atmp[1], xtmp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions1[1], buildPredSummary(geti_n(torch.totable(actions1),1, 3 ), \n",
    "    geti_n(xout, 1, 3), K_tokens * J_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions1[1], buildPredSummary(torch.totable(actions1)[1], {xout[1]}, K_tokens * J_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions0[1], buildPredSummary(torch.totable(actions0)[1], {xout[1]}, K_tokens * J_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary1[1], actions1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = 0.                    --- Compute a new MSE loss each time\n",
    "--- Grabbing all of the input data\n",
    "qs = inputs[query_id]['query']\n",
    "input_file = csvigo.load({path = input_path .. inputs[query_id]['inputs'], mode = \"large\", verbose = false})\n",
    "nugget_file = csvigo.load({path = input_path .. inputs[query_id]['nuggets'], mode = \"large\", verbose = false})\n",
    "nuggets = buildTermDocumentTable(nugget_file, nil)\n",
    "\n",
    "--- Building table of all of the input sentences\n",
    "xtdm  = buildTermDocumentTable(input_file, K_tokens)\n",
    "\n",
    "--- Extracting the query specific summaries, actions, and rougue\n",
    "action_list = action_query_list[query_id]\n",
    "yrouge = yrougue_query_list[query_id] \n",
    "preds = pred_query_list[query_id] \n",
    "\n",
    "nbatches = torch.floor( #input_file / batch_size)\n",
    "\n",
    "--- Initializing rouge metrics at time {t-1} and save scores, reset each new epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
