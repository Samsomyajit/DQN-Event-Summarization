{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying this separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nepochs = 1000\n",
    "learning_rate = 1e-6\n",
    "gamma =0.2\n",
    "cuts =4\n",
    "base_explore_rate = 0.1 \n",
    "delta = 1./(nepochs/cuts) \n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "vocabSize = 16\n",
    "embeddingSize = 64\n",
    "\n",
    "torch.manualSeed(420)\n",
    "math.randomseed(420)\n",
    "\n",
    "bow = true\n",
    "\n",
    "if bow then\n",
    "    sentenceLookup = nn.Sequential()\n",
    "                :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                :add(nn.Sum(2, 3, false))\n",
    "else\n",
    "    sentenceLookup = nn.Sequential()\n",
    "                :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                :add(nn.SplitTable(1, embeddingSize))\n",
    "                :add(nn.Sequencer(nn.LSTM(embeddingSize, embeddingSize)))\n",
    "                :add(nn.SelectTable(-1))            -- selects last state of the LSTM\n",
    "                :add(nn.Linear(embeddingSize, embeddingSize))\n",
    "                :add(nn.ReLU())\n",
    "end\n",
    "queryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\") \n",
    "summaryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\")\n",
    "\n",
    "pmodule = nn.ParallelTable()\n",
    "            :add(sentenceLookup)\n",
    "            :add(queryLookup)\n",
    "            :add(summaryLookup)\n",
    "\n",
    "model = nn.Sequential()\n",
    "        :add(pmodule)\n",
    "        :add(nn.JoinTable(2))\n",
    "        :add(nn.Tanh())\n",
    "        :add(nn.Linear(embeddingSize * 3, 2))\n",
    "\n",
    "\n",
    "criterion = nn.MSECriterion()\n",
    "params, gradParams = model:getParameters()\n",
    "\n",
    "function buildSummary(actions, sentences, buffer)\n",
    "    buffer:zero()\n",
    "\n",
    "     bufferSize = buffer:size(2)\n",
    "     actionsSize = actions:size(1)\n",
    "     sentencesSize = sentences:size(2)\n",
    "\n",
    "     mask1 = torch.eq(actions:select(2,2), 1):view(actionsSize, 1):expand(\n",
    "        actionsSize, sentencesSize)\n",
    "     allTokens = sentences:maskedSelect(mask1)\n",
    "     mask2 = torch.gt(allTokens,0)\n",
    "     allTokens = allTokens:maskedSelect(mask2)\n",
    "\n",
    "    if allTokens:dim() > 0 then\n",
    "         copySize = math.min(bufferSize, allTokens:size(1))\n",
    "\n",
    "        buffer[1]:narrow(1, bufferSize - copySize + 1, copySize):copy(\n",
    "            allTokens:narrow(1, allTokens:size(1) - copySize + 1, copySize))\n",
    "    end\n",
    "    return buffer\n",
    "end\n",
    "\n",
    "function buildTokenCounts(summary)\n",
    "    counts = {}\n",
    "    for i=1,summary:size(2) do\n",
    "        if summary[1][i] > 0 then\n",
    "             token = summary[1][i]\n",
    "            if counts[token] == nil then\n",
    "                counts[token] = 1\n",
    "            else\n",
    "                counts[token] = counts[token] + 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return counts\n",
    "end\n",
    "\n",
    "function rougeScores(genSummary, refSummary)\n",
    "     genTotal = 0\n",
    "     refTotal = 0\n",
    "     intersection = 0\n",
    "    for k, refCount in pairs(refSummary) do\n",
    "         genCount = genSummary[k]\n",
    "        if genCount == nil then genCount = 0 end\n",
    "        intersection = intersection + math.min(refCount, genCount)\n",
    "        refTotal = refTotal + refCount\n",
    "    end\n",
    "    for k,genCount in pairs(genSummary) do\n",
    "        genTotal = genTotal + genCount\n",
    "    end\n",
    "\n",
    "    if genTotal == 0 then \n",
    "        genTotal = 1 \n",
    "    end\n",
    "     recall = intersection / refTotal\n",
    "     prec = intersection / genTotal\n",
    "    if recall > 0 and prec > 0 then\n",
    "        f1 = 2 * recall * prec / (recall + prec)\n",
    "    else \n",
    "        f1 = 0\n",
    "    end\n",
    "    return recall, prec, f1\n",
    "end\n",
    "\n",
    "function backProp(input_memory, params, model, criterion, batch_size, memsize)\n",
    "    -- local input = input_memory[1]\n",
    "    -- local reward = input_memory[2]\n",
    "    local inputs = {input_memory[1], input_memory[3]}\n",
    "    local rewards = input_memory[2]\n",
    "    local dataloader = dl.TensorLoader(inputs, rewards)\n",
    "    local err = 0.    \n",
    "\n",
    "    den = 1\n",
    "    for k, xin, reward in dataloader:sampleiter(batch_size, memsize) do\n",
    "        xinput = xin[1]\n",
    "        actions_in = xin[2]\n",
    "        local function feval(params)\n",
    "            gradParams:zero()\n",
    "            local predQ = model:forward(xinput)\n",
    "            local maskLayer = nn.MaskedSelect()\n",
    "            local predQOnActions = maskLayer:forward({predQ, actions_in})\n",
    "\n",
    "            local lossf = criterion:forward(predQOnActions, reward)\n",
    "            local gradOutput = criterion(predQOnActions, reward)\n",
    "            local gradMaskLayer = maskLayer:backward({predQ, actions_in}, gradOutput)\n",
    "            model:backward(xinput, gradMaskLayer[1])\n",
    "            return lossf, gradParams\n",
    "        end\n",
    "        --- This is confusing to me...\n",
    "        _, lossv  = optim.rmsprop(feval, params, optimParams)   \n",
    "    end\n",
    "    return lossv[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRUE {RECALL = 0.714286, PREC = 1.000000, F1 = 0.833333}\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimParams = {\n",
    "    learningRate = learning_rate,\n",
    "}\n",
    "\n",
    "maxSummarySize = 36\n",
    "epsilon = 1.0\n",
    "query = torch.LongTensor{{0, 1, 4, 3}}\n",
    "sentenceStream = torch.Tensor{{0, 1, 3, 4}, \n",
    "                                {7, 6, 5 ,8}, \n",
    "                                {0, 2, 4, 3}, \n",
    "                                {7, 5, 8, 6}, \n",
    "                                {1, 4, 3, 2}, \n",
    "                                {13, 14, 15, 16}}\n",
    "\n",
    "refSummary = torch.Tensor{{1,3,4,2,4,3,1,4,3,2,9,10,12,11}}\n",
    "refCounts = buildTokenCounts(refSummary)\n",
    "\n",
    "\n",
    "streamSize = sentenceStream:size(1)\n",
    "bestActions = torch.ByteTensor{{0,1},{1,0},{0,1},{1,0},{0,1},{1,0}}\n",
    "\n",
    "\n",
    "buffer = torch.Tensor(1, maxSummarySize):zero()\n",
    "bestSummary = buildSummary(\n",
    "    bestActions:narrow(1, 1, 6), \n",
    "    sentenceStream:narrow(1, 1, 6),\n",
    "    buffer:narrow(1, 1, 1)\n",
    "    )\n",
    "\n",
    "generatedCounts = buildTokenCounts(bestSummary) \n",
    "bestrecall, bestprec, bestf1 = rougeScores(generatedCounts, refCounts)\n",
    "print(string.format(\"TRUE {RECALL = %.6f, PREC = %.6f, F1 = %.6f}\", bestrecall, bestprec, bestf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actions = torch.ByteTensor(streamSize,2):fill(0)\n",
    "exploreDraws = torch.Tensor(streamSize)\n",
    "summaryBuffer = torch.LongTensor(streamSize + 1, maxSummarySize):zero()\n",
    "qValues = torch.Tensor(streamSize, 2):zero()\n",
    "rouge = torch.Tensor(streamSize + 1):zero()\n",
    "\n",
    "rouge[1] = 1\n",
    "exploreDraws:uniform(0, 1)\n",
    "summary = summaryBuffer:zero():narrow(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = sentenceStream:narrow(1, i, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentenceLookup = nn.Sequential()\n",
    "            :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "            :add(nn.Sum(2, 3, false))\n",
    "\n",
    "sentenceLookup = nn.Sequential()\n",
    "            :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "            :add(nn.SplitTable(2))\n",
    "            :add(nn.Sequencer(nn.LSTM(embeddingSize, embeddingSize)))\n",
    "            :add(nn.SelectTable(-1))\n",
    "\n",
    "queryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\") \n",
    "summaryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\")\n",
    "\n",
    "pmodule = nn.ParallelTable()\n",
    "            :add(sentenceLookup)\n",
    "            :add(queryLookup)\n",
    "            :add(summaryLookup)\n",
    "\n",
    "model = nn.Sequential()\n",
    "        :add(pmodule)\n",
    "        :add(nn.JoinTable(2))\n",
    "        :add(nn.Tanh())\n",
    "        :add(nn.Linear(embeddingSize * 3, 2))\n",
    "\n",
    "-- tmp1 = pmodule:forward({sentence, query, summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = nn.Sequential():add(nn.LookupTableMaskZero(vocabSize, embeddingSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1\n",
       "  4\n",
       " 64\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tmp:forward(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1\n",
       " 64\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentenceLookup:forward(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1\n",
       " 64\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentenceLookup:forward(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 4x64\n",
       "  2 : DoubleTensor - size: 4x64\n",
       "  3 : DoubleTensor - size: 36x64\n",
       "}\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmodule:forward({sentence, query, summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nn.Linear(embeddingSize * 3, 2):forward( nn.JoinTable(1):forward(tmp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:67: \nIn 2 module of nn.Sequential:\n...javierarceo/torch/install/share/lua/5.1/nn/JoinTable.lua:39: inconsistent tensor size at /Users/franciscojavierarceo/torch/pkg/torch/lib/TH/generic/THTensorCopy.c:7\nstack traceback:\n\t[C]: in function 'copy'\n\t...javierarceo/torch/install/share/lua/5.1/nn/JoinTable.lua:39: in function <...javierarceo/torch/install/share/lua/5.1/nn/JoinTable.lua:21>\n\t[C]: in function 'xpcall'\n\t...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'\n\t...avierarceo/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'forward'\n\t[string \"local f = function() return #model:forward({s...\"]:1: in function 'f'\n\t[string \"local f = function() return #model:forward({s...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010c732b90\n\nWARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above.\nstack traceback:\n\t[C]: in function 'error'\n\t...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:67: in function 'rethrowErrors'\n\t...avierarceo/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'forward'\n\t[string \"local f = function() return #model:forward({s...\"]:1: in function 'f'\n\t[string \"local f = function() return #model:forward({s...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010c732b90",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:67: \nIn 2 module of nn.Sequential:\n...javierarceo/torch/install/share/lua/5.1/nn/JoinTable.lua:39: inconsistent tensor size at /Users/franciscojavierarceo/torch/pkg/torch/lib/TH/generic/THTensorCopy.c:7\nstack traceback:\n\t[C]: in function 'copy'\n\t...javierarceo/torch/install/share/lua/5.1/nn/JoinTable.lua:39: in function <...javierarceo/torch/install/share/lua/5.1/nn/JoinTable.lua:21>\n\t[C]: in function 'xpcall'\n\t...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:63: in function 'rethrowErrors'\n\t...avierarceo/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'forward'\n\t[string \"local f = function() return #model:forward({s...\"]:1: in function 'f'\n\t[string \"local f = function() return #model:forward({s...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010c732b90\n\nWARNING: If you see a stack trace below, it doesn't point to the place where this error occurred. Please use only the one above.\nstack traceback:\n\t[C]: in function 'error'\n\t...javierarceo/torch/install/share/lua/5.1/nn/Container.lua:67: in function 'rethrowErrors'\n\t...avierarceo/torch/install/share/lua/5.1/nn/Sequential.lua:44: in function 'forward'\n\t[string \"local f = function() return #model:forward({s...\"]:1: in function 'f'\n\t[string \"local f = function() return #model:forward({s...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010c732b90"
     ]
    }
   ],
   "source": [
    "#model:forward({sentence, query, summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qValues[i]:copy(model:forward({sentence, query, summary}))\n",
    "\n",
    "if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "    actions[i][SKIP] = 1\n",
    "else\n",
    "    actions[i][SELECT] = 1\n",
    "end\n",
    "\n",
    "summary = buildSummary(\n",
    "    actions:narrow(1, 1, i), \n",
    "    sentenceStream:narrow(1, 1, i),\n",
    "    summaryBuffer:narrow(1, i + 1, 1)\n",
    "    )\n",
    "generatedCounts = buildTokenCounts(summary) \n",
    "recall, prec, f1 = rougeScores(generatedCounts, refCounts)\n",
    "rouge[i + 1] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i=1, streamSize do\n",
    "    --- the i extracts individual sentences from the stream\n",
    "    sentence = sentenceStream:narrow(1, i, 1)\n",
    "    qValues[i]:copy(model:forward({sentence, query, summary}))\n",
    "\n",
    "    if exploreDraws[i] <= epsilon then\n",
    "        actions[i][torch.random(SKIP, SELECT)] = 1\n",
    "    else \n",
    "        if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "            actions[i][SKIP] = 1\n",
    "        else\n",
    "            actions[i][SELECT] = 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    summary = buildSummary(\n",
    "        actions:narrow(1, 1, i), \n",
    "        sentenceStream:narrow(1, 1, i),\n",
    "        summaryBuffer:narrow(1, i + 1, 1)\n",
    "        )\n",
    "\n",
    "    generatedCounts = buildTokenCounts(summary) \n",
    "    recall, prec, f1 = rougeScores(generatedCounts, refCounts)\n",
    "    rouge[i + 1] = f1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp0 = {}\n",
    "tmp1 = {}\n",
    "tmp2 = {}\n",
    "for epoch=1,nepochs do\n",
    "    actions = torch.ByteTensor(streamSize,2):fill(0)\n",
    "    exploreDraws = torch.Tensor(streamSize)\n",
    "    summaryBuffer = torch.LongTensor(streamSize + 1, maxSummarySize):zero()\n",
    "    qValues = torch.Tensor(streamSize, 2):zero()\n",
    "    rouge = torch.Tensor(streamSize + 1):zero()\n",
    "\n",
    "    rouge[1] = 1\n",
    "    exploreDraws:uniform(0, 1)\n",
    "\n",
    "    summary = summaryBuffer:zero():narrow(1,1,1)\n",
    "    for i=1, streamSize do\n",
    "        --- the i extracts individual sentences from the stream\n",
    "         sentence = sentenceStream:narrow(1, i, 1)\n",
    "        qValues[i]:copy(model:forward({sentence, query, summary}))\n",
    "\n",
    "        if exploreDraws[i] <= epsilon then\n",
    "            actions[i][torch.random(SKIP, SELECT)] = 1\n",
    "        else \n",
    "            if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "                actions[i][SKIP] = 1\n",
    "            else\n",
    "                actions[i][SELECT] = 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        summary = buildSummary(\n",
    "            actions:narrow(1, 1, i), \n",
    "            sentenceStream:narrow(1, 1, i),\n",
    "            summaryBuffer:narrow(1, i + 1, 1)\n",
    "            )\n",
    "\n",
    "         generatedCounts = buildTokenCounts(summary) \n",
    "         recall, prec, f1 = rougeScores(generatedCounts, refCounts)\n",
    "        rouge[i + 1] = f1\n",
    "    end\n",
    "\n",
    "    local max, argmax = torch.max(qValues, 2)\n",
    "    local reward0 = rouge:narrow(1,2, streamSize) - rouge:narrow(1,1, streamSize)\n",
    "    local reward_tp1 = gamma * reward0:narrow(1, 2, streamSize - 1):resize(streamSize)\n",
    "    --- occasionally the zeros result in a nan, which is strange\n",
    "    reward_tp1[reward_tp1:ne(reward_tp1)] = 0\n",
    "    reward_tp1 = torch.clamp(reward_tp1, -1, 1)\n",
    "    local reward = reward0 + reward_tp1\n",
    "    -- print(epoch, reward0:sum(), reward_tp1:sum(), reward:sum())\n",
    "    \n",
    "    local querySize = query:size(2)\n",
    "    local summaryBatch = summaryBuffer:narrow(1, 1, streamSize)\n",
    "    local queryBatch = query:view(1, querySize):expand(streamSize, querySize) \n",
    "\n",
    "    local input = {sentenceStream, queryBatch, summaryBatch}\n",
    "    --- Storing the data\n",
    "    memory = {input, reward, actions}\n",
    "\n",
    "    if epoch == 1 then\n",
    "        fullmemory = memory \n",
    "    else\n",
    "        tmp = buildMemory(memory, fullmemory, mem_size, batch_size)\n",
    "        fullmemory = tmp\n",
    "    end\n",
    "    --- Running backprop\n",
    "    if(epoch > n_rand) then \n",
    "        loss = backProp(memory, params, model, criterion, batch_size, mem_size)\n",
    "    else \n",
    "        loss = {0.}\n",
    "    end\n",
    "    \n",
    "    if epoch == 1 then\n",
    "        print(input)\n",
    "    end\n",
    "\n",
    "     _, loss = optim.adam(feval, params, optimParams)\n",
    "    out = string.format(\"%i; %.3f;%.6f;%.6f; {min=%.3f, max=%.3f}; {min=%.3f, max=%.3f}; {%i,%i,%i,%i,%i,%i,%i,%i,%i,%i,%i,%i}\\n\", \n",
    "            epoch, epsilon, loss[1], rouge[streamSize + 1],\n",
    "            reward:min(), reward:max(),\n",
    "            qValues:min(), qValues:max(),\n",
    "            actions[1][1], \n",
    "            actions[1][2], \n",
    "            actions[2][1], \n",
    "            actions[2][2], \n",
    "            actions[3][1], \n",
    "            actions[3][2], \n",
    "            actions[4][1],\n",
    "            actions[4][2],\n",
    "            actions[5][1], \n",
    "            actions[5][2], \n",
    "            actions[6][1], \n",
    "            actions[6][2] \n",
    "        )\n",
    "    print(out)\n",
    "\n",
    "    if (epsilon - delta) <= base_explore_rate then\n",
    "        epsilon = base_explore_rate\n",
    "    else \n",
    "        epsilon = epsilon - delta\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.clamp(tmp0[360], -0.7, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.Threshold(0.06, 0):forward(tmp1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.Threshold(-.05, 0):forward(tmp0[360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp2[360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[6][tmp1[6]:ne(tmp1[6])] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp0[6]:narrow(1, 2, streamSize-1):resize(streamSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp0[6]:narrow(1, 2, streamSize-1):resize(streamSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp0[6] + gamma * tmp0[6]:narrow(1, 2, streamSize-1):resize(streamSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp0[242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--- If tmp0[242] < thresh, out else tmp0[242]\n",
    "thresh = -0.7\n",
    "out = 99\n",
    "print(nn.Threshold(thresh, out):forward(tmp0[242]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--- If tmp0[242] < thresh, out else tmp0[242]\n",
    "thresh = -0.25\n",
    "out = 99\n",
    "print(nn.Threshold(thresh, out):forward(-tmp0[242]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.Threshold(0.01, -0.001):forward(tmp0[242])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.Threshold(0.1, 0.01):forward(nn.Threshold(-0.01, -0.01):forward(tmp0[242]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i = 1, 500 do\n",
    "    print(tmp0[i] + tmp1[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentenceStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst = torch.cat(sentenceStream, sentenceStream, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local dl = require 'dataload'\n",
    "\n",
    "inputs = torch.range(1,5)\n",
    "targets = torch.range(1,5)\n",
    "\n",
    "dataloader = dl.TensorLoader(inputs, targets)\n",
    "\n",
    "local i = 1\n",
    "for k, inputs, targets in dataloader:sampleiter(2,6) do\n",
    "   print(string.format(\"batch %d, nsampled = %d; inputs = %.i\", i, k, inputs[1]))\n",
    "--    print(string.format(\"inputs:\\n%stargets:\\n%s\", inputs, targets))\n",
    "   i = i + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = torch.randn(5, 1)\n",
    "targets = torch.LongTensor(10):random(1,10):resize(5,2)\n",
    "dataloader = dl.TensorLoader(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for k, input, target in dataloader:sampleiter(5, 20) do\n",
    "    print(string.format(\"batch %d, nsampled = %d; target {i, i}\", i, k))\n",
    "    print(target)\n",
    "   i = i + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dl = require 'dataload'\n",
    "\n",
    "inputs = torch.LongTensor({1,2, 3, 5}, {1, 2, 3}, {4, 5, 7}, {7, 8 ,8, 3, 2}, {1,2,3,4})\n",
    "targets = torch.LongTensor({1,2, 3, 5}, {1, 2, 3}, {4, 5, 7}, {7, 8 ,8, 3, 2}, {1,2,3,4})\n",
    "actions = torch.round(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = dl.TensorLoader(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for k, input, target, action in dataloader:sampleiter(1,5) do\n",
    "   print(string.format(\"batch %d, nsampled = %d\", i, k))\n",
    "   i = i + 1\n",
    "    if i==5 then\n",
    "        print(input, target, action)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting model right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'rnn'\n",
    "require 'nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabSize = 4\n",
    "embeddingSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentenceLookup = nn.Sequential()\n",
    "            :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "            :add(nn.Sum(2, 3, false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentenceLookup = nn.Sequential()\n",
    "                :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                :add(nn.SplitTable(1, embeddingSize))\n",
    "                :add(nn.Sequencer(nn.LSTM(embeddingSize, embeddingSize)))\n",
    "                :add(nn.SelectTable(-1))            -- selects last state of the LSTM\n",
    "                :add(nn.Linear(embeddingSize, embeddingSize))\n",
    "                :add(nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\") \n",
    "summaryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pmod = nn.ParallelTable()\n",
    "        :add(sentenceLookup)\n",
    "        :add(queryLookup)\n",
    "        :add(summaryLookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "        :add(pmod)\n",
    "        :add(nn.JoinTable(2))\n",
    "        :add(nn.Tanh())\n",
    "        :add(nn.Linear(embeddingSize * 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = torch.LongTensor({{1, 2, 3,4}})\n",
    "q = torch.LongTensor({{2, 3, 4, 1}})\n",
    "cs = torch.LongTensor({{0, 1 ,3 , 2}})\n",
    "input = {s,q,cs}\n",
    "input2 = {s, q}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentenceLookup:forward(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentenceLookup:forward(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.JoinTable(1):forward(pmod:forward(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pmod:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predQ = model:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maskLayer = nn.MaskedSelect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.max(predQ, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predaction , actions = torch.max(predQ, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maskLayer = nn.MaskedSelect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions_in = torch.ByteTensor(6, 2):fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predQOnActions = maskLayer:forward({predQ, actions_in})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function backProp(input_memory, params, model, criterion, batch_size, memsize)\n",
    "    -- local input = input_memory[1]\n",
    "    -- local reward = input_memory[2]\n",
    "    local inputs = {input_memory[1], input_memory[3]}\n",
    "    local rewards = input_memory[2]\n",
    "    local dataloader = dl.TensorLoader(inputs, rewards)\n",
    "    local err = 0.    \n",
    "\n",
    "    den = 1\n",
    "    for k, xin, reward in dataloader:sampleiter(batch_size, memsize) do\n",
    "        xinput = xin[1]\n",
    "        actions_in = xin[2]\n",
    "        local function feval(params)\n",
    "            gradParams:zero()\n",
    "            local predQ = model:forward(xinput)\n",
    "            local maskLayer = nn.MaskedSelect()\n",
    "            local predQOnActions = maskLayer:forward({predQ, actions_in})\n",
    "\n",
    "            local lossf = criterion:forward(predQOnActions, reward)\n",
    "            local gradOutput = criterion(predQOnActions, reward)\n",
    "            local gradMaskLayer = maskLayer:backward({predQ, actions_in}, gradOutput)\n",
    "            model:backward(xinput, gradMaskLayer[1])\n",
    "            return lossf, gradParams\n",
    "        end\n",
    "        --- This is confusing to me...\n",
    "        _, lossv  = optim.rmsprop(feval, params, optimParams)   \n",
    "    end\n",
    "    return lossv[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
