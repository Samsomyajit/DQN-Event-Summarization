{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'csvigo'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...Utils file loaded\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = 'lstm'\n",
    "nepochs = 200\n",
    "K_tokens = 20\n",
    "J_sentences = 10\n",
    "batch_size = 200\n",
    "thresh = 0.00\n",
    "embed_dim = 50\n",
    "learning_rate = 0.1\n",
    "print_every = 1\n",
    "usecuda = false\n",
    "epsilon = 1\n",
    "cuts = 4\n",
    "base_explore_rate = 0.0\n",
    "skip_rate = 0.\n",
    "metric = \"f1\"\n",
    "\n",
    "--- Loading utility script\n",
    "dofile(\"utils.lua\")\n",
    "dofile(\"model_utils.lua\")\n",
    "\n",
    "torch.manualSeed(420)\n",
    "math.randomseed(420)\n",
    "\n",
    "data_path = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/'\n",
    "\n",
    "query_fn = data_path .. 'queries_numtext.csv'\n",
    "query_file =  csvigo.load({path = query_fn, mode = \"large\", verbose = false})\n",
    "queries = buildTermDocumentTable(query_file, nil)\n",
    "\n",
    "aurora = {\n",
    "        ['inputs'] = '2012_aurora_shooting_first_sentence_numtext2.csv', \n",
    "        ['nuggets'] = 'aurora_nuggets_numtext.csv',\n",
    "        ['query'] = queries[3],\n",
    "        ['query_name'] = 'aurora'\n",
    "}\n",
    "\n",
    "inputs = {\n",
    "        aurora\n",
    "    }\n",
    "--- Only using epsilon greedy strategy for (nepochs/cuts)% of the epochs\n",
    "delta = 1./(nepochs/cuts) \n",
    "crit = nn.MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path, query_file, batch_size, nepochs, inputs = data_path, query_file, batch_size, nepochs, inputs\n",
    "nn_model, crit, thresh, embed_dim, epsilon, delta = nn_model, crit, thresh, embed_dim, epsilon, delta\n",
    "base_explore_rate, print_every = base_explore_rate, print_every\n",
    "learning_rate, J_sentences, K_tokens, use_cuda = learning_rate, J_sentences, K_tokens, usecuda\n",
    "skiprate, emetric = skip_rate, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dofile(\"model_utils.lua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running LSTM model\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "model_utils.lua:56: attempt to index global 'mod1' (a nil value)\nstack traceback:\n\tmodel_utils.lua:56: in function 'build_model'\n\t[string \"model  = build_model(nn_model, vocab_size, em...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01084b0b90",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "model_utils.lua:56: attempt to index global 'mod1' (a nil value)\nstack traceback:\n\tmodel_utils.lua:56: in function 'build_model'\n\t[string \"model  = build_model(nn_model, vocab_size, em...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01084b0b90"
     ]
    }
   ],
   "source": [
    "model  = build_model(nn_model, vocab_size, embed_dim, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "...running on CPU\t\n",
       "training model with metric = f1, learning rate = 0.100, K = 20, J = 10, threshold = 0.000, embedding size = 50\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "model_utils.lua:56: attempt to index global 'mod1' (a nil value)\nstack traceback:\n\tmodel_utils.lua:56: in function 'build_model'\n\t[string \"if use_cuda then...\"]:51: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01084b0b90",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "model_utils.lua:56: attempt to index global 'mod1' (a nil value)\nstack traceback:\n\tmodel_utils.lua:56: in function 'build_model'\n\t[string \"if use_cuda then...\"]:51: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01084b0b90"
     ]
    }
   ],
   "source": [
    "if use_cuda then\n",
    "  Tensor = torch.CudaTensor\n",
    "  LongTensor = torch.CudaLongTensor\n",
    "  crit = crit:cuda()\n",
    "  print(\"...running on GPU\")\n",
    "else\n",
    "  Tensor = torch.Tensor\n",
    "  LongTensor = torch.LongTensor\n",
    "  print(\"...running on CPU\")\n",
    "end\n",
    "\n",
    "print_string = string.format(\n",
    "    \"training model with metric = %s, learning rate = %.3f, K = %i, J = %i, threshold = %.3f, embedding size = %i\",\n",
    "            emetric, learning_rate, K_tokens, J_sentences, thresh, embed_dim, batch_size\n",
    "            )\n",
    "\n",
    "print(print_string)\n",
    "\n",
    "vocab_size = 0\n",
    "maxseqlen = 0\n",
    "maxseqlenq = getMaxseq(query_file)\n",
    "\n",
    "action_query_list = {}\n",
    "yrougue_query_list = {}\n",
    "pred_query_list = {}\n",
    "\n",
    "--- Initializing query information\n",
    "for query_id = 1, #inputs do\n",
    "    input_fn = inputs[query_id]['inputs']\n",
    "    nugget_fn = inputs[query_id]['nuggets']\n",
    "\n",
    "    input_file = csvigo.load({path = input_path .. input_fn, mode = \"large\", verbose = false})\n",
    "    nugget_file = csvigo.load({path = input_path .. nugget_fn, mode = \"large\", verbose = false})\n",
    "    input_file = geti_n(input_file, 2, #input_file) \n",
    "    nugget_file = geti_n(nugget_file, 2, #nugget_file) \n",
    "\n",
    "    vocab_sized = getVocabSize(input_file)\n",
    "    vocab_sizeq = getVocabSize(query_file)\n",
    "    vocab_size = math.max(vocab_size, vocab_sized, vocab_sizeq)\n",
    "\n",
    "    maxseqlend = getMaxseq(input_file)\n",
    "    maxseqlen = math.max(maxseqlen, maxseqlenq, maxseqlend)\n",
    "    action_list = torch.totable(torch.round(torch.rand(#input_file)))\n",
    "\n",
    "    --- initialize the query specific lists\n",
    "    action_query_list[query_id] = action_list\n",
    "    yrougue_query_list[query_id] = torch.totable(torch.randn(#input_file, 1)) --- Actual\n",
    "    pred_query_list[query_id] = torch.totable(torch.zeros(#input_file, 1))    --- Predicted\n",
    "end\n",
    "\n",
    "model  = build_model(model, vocab_size, embed_dim, use_cuda)\n",
    "\n",
    "for epoch=0, nepochs, 1 do\n",
    "    loss = 0.                    --- Compute a new MSE loss each time\n",
    "    --- Looping over each bach of sentences for a given query\n",
    "    for query_id = 1, #inputs do\n",
    "        --- Grabbing all of the input data\n",
    "        qs = inputs[query_id]['query']\n",
    "        input_file = csvigo.load({path = input_path .. inputs[query_id]['inputs'], mode = \"large\", verbose = false})\n",
    "        nugget_file = csvigo.load({path = input_path .. inputs[query_id]['nuggets'], mode = \"large\", verbose = false})\n",
    "        --- Dropping the headers\n",
    "        input_file = geti_n(input_file, 2, #input_file) \n",
    "        nugget_file = geti_n(nugget_file, 2, #nugget_file) \n",
    "\n",
    "        --- Building table of all of the input sentences\n",
    "        local nuggets = buildTermDocumentTable(nugget_file, nil)\n",
    "        local xtdm  = buildTermDocumentTable(input_file, K_tokens)\n",
    "\n",
    "        --- Extracting the query specific summaries, actions, and rougue\n",
    "        action_list = action_query_list[query_id]\n",
    "        yrougue = yrougue_query_list[query_id] \n",
    "        preds = pred_query_list[query_id]\n",
    "\n",
    "        --- Loop over file to execute forward pass to estimate expected rougue\n",
    "        for minibatch = 1, #xtdm do\n",
    "            --- Notice that the actionlist is optimized at after each iteration\n",
    "            local summaries = padZeros(buildCurrentSummary(action_list, xtdm, \n",
    "                                    K_tokens * J_sentences), \n",
    "                                    K_tokens * J_sentences)\n",
    "            sentence = LongTensor(padZeros( {xtdm[minibatch]}, K_tokens) ):t()\n",
    "            summary = LongTensor({ summaries[minibatch] }):t()\n",
    "            query = LongTensor( padZeros({qs}, 5) ):t()\n",
    "\n",
    "            --- Retrieve intermediate optimal action in model.get(3).output\n",
    "            local pred_rougue = model:forward({sentence, summary, query})   \n",
    "            local pred_actions = torch.totable(model:get(3).output)\n",
    "            opt_action = (pred_actions[1][1] > pred_actions[1][2]) and 1 or 0\n",
    "\n",
    "            -- doing this way works just fine...                \n",
    "            -- local labels = Tensor(yrougue[minibatch])\n",
    "            -- local grads = crit:backward(pred_rougue, labels)\n",
    "            -- model:zeroGradParameters()\n",
    "            -- model:backward({sentence, summary, query}, grads)\n",
    "            -- model:updateParameters(learning_rate)\n",
    "\n",
    "            -- Updating our book-keeping tables\n",
    "            preds[minibatch] = pred_rougue\n",
    "            action_list[minibatch] = opt_action\n",
    "        end\n",
    "        --- Updating variables\n",
    "        action_query_list[query_id] = action_list\n",
    "        yrougue_query_list[query_id] = yrouge\n",
    "        pred_query_list[query_id] = preds\n",
    "\n",
    "        --- Note setting the skip_rate = 0 means no random skipping of delta calculation\n",
    "        labels, opt_action = score_model(action_list, \n",
    "                                        xtdm,\n",
    "                                        epsilon, \n",
    "                                        thresh, \n",
    "                                        skiprate, \n",
    "                                        emetric)\n",
    "\n",
    "        --- Rerunning on the scoring on the full data and rescoring cumulatively\n",
    "        --- Execute policy and evaluation based on our E[ROUGUE] after all of the minibatches\n",
    "            --- Notice that pred_rougue gives us our optimal action by returning\n",
    "            ---  E[ROUGUE | Select ] > E[ROUGUE | Skip]\n",
    "        predsummary = buildPredSummary(action_list, xtdm, nil)\n",
    "        predsummary = predsummary[#predsummary]\n",
    "\n",
    "        rscore = rougeRecall({predsummary}, nuggets)\n",
    "        pscore = rougePrecision({predsummary}, nuggets)\n",
    "        fscore = rougeF1({predsummary}, nuggets)\n",
    "\n",
    "        if (epoch % print_every)==0 then\n",
    "            perf_string = string.format(\n",
    "                \"Epoch %i, epsilon = %.3f, sum(y)/len(y) = %i/%i, {Recall = %.6f, Precision = %.6f, F1 = %.6f}, query = %s\", \n",
    "                epoch, epsilon, sumTable(action_list), #action_list, rscore, pscore, fscore, inputs[query_id]['query_name']\n",
    "                )\n",
    "            print(perf_string)\n",
    "        end\n",
    "\n",
    "        --- creating the indices we want\n",
    "        -- local qindices = {}\n",
    "        local xindices = {}\n",
    "        for i=1, batch_size do\n",
    "            -- qindices[i] = math.random(1, #inputs)\n",
    "            xindices[i] = math.random(1, #xtdm)\n",
    "        end\n",
    "\n",
    "        local summaries = padZeros(buildCurrentSummary(action_list, xtdm, \n",
    "                                    K_tokens * J_sentences), \n",
    "                                    K_tokens * J_sentences)\n",
    "\n",
    "        --- Backward step\n",
    "        for i= 1, batch_size do\n",
    "            print('running backprop')\n",
    "            sentence = LongTensor(padZeros( {xtdm[xindices[i]]}, K_tokens) ):t()\n",
    "            summary = LongTensor({summaries[xindices[i]]}):t()\n",
    "            query = LongTensor(padZeros({qs}, 5)):t()\n",
    "\n",
    "            labels = Tensor(yrougue[xindices[i]])\n",
    "            pred_rougue = Tensor(preds[xindices[i]])\n",
    "\n",
    "            print(sentence:size(), summary:size(), query:size(), pred_rougue:size(), labels:size())\n",
    "            print(sentence:sum(), summary:sum(), query:sum(), pred_rougue:sum(), labels:sum())\n",
    "            -- print(xtdm[xindices[i]], summaries[xindices[i]], qs, pred_rougue, labels )\n",
    "            --- Backprop model\n",
    "            loss = loss + crit:forward(pred_rougue, labels)\n",
    "            local grads = crit:backward(pred_rougue, labels)\n",
    "            model:zeroGradParameters()\n",
    "            model:backward({sentence, summary, query}, grads)\n",
    "            model:updateParameters(learning_rate)\n",
    "            print('pass', i)\n",
    "        end \n",
    "    end -- ends the query loop\n",
    "    if (epsilon - delta) <= base_explore_rate then                --- and leaving a random exploration rate\n",
    "        epsilon = base_explore_rate\n",
    "    else \n",
    "        epsilon = epsilon - delta           --- Decreasing the epsilon greedy strategy\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
