{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'gnuplot'\n",
    "require 'rnn'\n",
    "require 'image'\n",
    "Plot = require 'itorch.Plot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpu=1\n",
    "if gpu>0 then\n",
    "  print(\"CUDA ON\")\n",
    "  require 'cutorch'\n",
    "  require 'cunn'\n",
    "  cutorch.setDevice(gpu)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nIters = 200\n",
    "batchSize = 80\n",
    "rho = 10\n",
    "hiddenSize = 300\n",
    "nIndex = 1\n",
    "lr = 0.0001\n",
    "nPredict=200\n",
    "\n",
    "rnn = nn.Sequential()\n",
    "   :add(nn.Linear(nIndex, hiddenSize))\n",
    "   :add(nn.FastLSTM(hiddenSize, hiddenSize))\n",
    "   :add(nn.NormStabilizer())\n",
    "   :add(nn.Linear(hiddenSize, nIndex))\n",
    "   :add(nn.HardTanh())\n",
    "rnn = nn.Sequencer(rnn)\n",
    "rnn:training()\n",
    "---- print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if gpu>0 then\n",
    "  rnn=rnn:cuda()\n",
    "end\n",
    "\n",
    "criterion = nn.MSECriterion()\n",
    "if gpu>0 then\n",
    "  criterion=criterion:cuda()\n",
    "end\n",
    "\n",
    "ii=torch.linspace(0,200, 2000)\n",
    "sequence=torch.cos(ii)\n",
    "if gpu>0 then\n",
    "  sequence=sequence:cuda()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offsets = {}\n",
    "for i=1,batchSize do\n",
    "   table.insert(offsets, math.ceil(math.random()* (sequence:size(1)-rho) ))\n",
    "end\n",
    "offsets = torch.LongTensor(offsets)\n",
    "if gpu>0 then\n",
    "  offsets=offsets:cuda()\n",
    "end\n",
    "\n",
    "--- local gradOutputsZeroed = {}\n",
    "gradOutputsZeroed = {}\n",
    "for step=1,rho do\n",
    "  gradOutputsZeroed[step] = torch.zeros(batchSize,1)\n",
    "  if gpu>0 then\n",
    "    gradOutputsZeroed[step] = gradOutputsZeroed[step]:cuda()\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local iteration = 5\n",
    "while iteration < nIters do\n",
    "   local inputs, targets = {}, {}\n",
    "    inputs2, targets2 = {}, {}\n",
    "   for step=1,rho do\n",
    "      inputs[step] = sequence:index(1, offsets):view(batchSize,1)\n",
    "      inputs2[step] = sequence:index(1, offsets):view(batchSize,1)\n",
    "      offsets:add(1)\n",
    "      for j=1,batchSize do\n",
    "         if offsets[j] > sequence:size(1) then\n",
    "            offsets[j] = 1\n",
    "         end\n",
    "      end\n",
    "      targets2[step] = sequence:index(1, offsets)\n",
    "      targets[step] = sequence:index(1, offsets)\n",
    "   end\n",
    "   rnn:zeroGradParameters()\n",
    "   local outputs = rnn:forward(inputs)\n",
    "   local err = criterion:forward(outputs[rho], targets[rho])\n",
    "   ---print(string.format(\"Iteration %d ; NLL err = %f \", iteration, err))\n",
    "   local gradOutputs = criterion:backward(outputs[rho], targets[rho])\n",
    "   gradOutputsZeroed[rho] = gradOutputs\n",
    "   local gradInputs = rnn:backward(inputs, gradOutputsZeroed)\n",
    "   rnn:updateParameters(lr)\n",
    "   iteration = iteration + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn:evaluate()\n",
    "predict=torch.FloatTensor(nPredict)\n",
    "if gpu>0 then\n",
    "  predict=predict:cuda()\n",
    "end\n",
    "for step=1,rho do\n",
    "  predict[step]= sequence[step]\n",
    "end\n",
    "\n",
    "start = {}\n",
    "iteration=0\n",
    "while rho + iteration < nPredict do\n",
    "  for step=1,rho do\n",
    "    start[step] = predict:index(1,torch.LongTensor({step+iteration})):view(1,1)\n",
    "  end\n",
    "\n",
    "  output = rnn:forward(start)\n",
    "\n",
    "  predict[iteration+rho+1] = (output[rho]:float())[1][1]\n",
    "\n",
    "  iteration = iteration + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- scatter plots\n",
    "plot = Plot():circle(torch.range(1, predict.size(predict)[1]), \n",
    "                predict, 'red', 'Loss Function'):draw()\n",
    "plot:line(torch.range(1, predict.size(predict)[1]), \n",
    "                predict, 'red', ''):redraw()\n",
    "plot:title('Scatter Plot Demo'):redraw()\n",
    "plot:xaxis('Iterations'):yaxis('Negative Log-Likelihood'):redraw()\n",
    "plot:legend(true)\n",
    "plot:redraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- scatter plots\n",
    "plot = Plot():circle(torch.range(1, #loss), \n",
    "                loss, 'red', 'Loss Function'):draw()\n",
    "plot:line(torch.range(1, #loss), \n",
    "                loss, 'red', ''):redraw()\n",
    "plot:title('Scatter Plot Demo'):redraw()\n",
    "plot:xaxis('Iterations'):yaxis('Negative Log-Likelihood'):redraw()\n",
    "plot:legend(true)\n",
    "plot:redraw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/2012_aurora_shooting_first_sentence_numtext.csv\t\n"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n",
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/total_corpus_smry.csv\t\n"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n",
       "<csv>\tparsing file: /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/aurora_nuggets_numtext.csv\t\n",
       "<csv>\tparsing done\t\n",
       "...Utils file loaded\t\n"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1000\telements read out of \t12510\t\n"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "139\telements read out of \t140\t\n",
       "1000\telements read out of \t12510\t\n"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 1000\n",
       "    1\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 0.1131\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'csvigo'\n",
    "\n",
    "aroraname = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/2012_aurora_shooting_first_sentence_numtext.csv'\n",
    "wordfile = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/total_corpus_smry.csv'\n",
    "nuggets = '~/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/0-output/aurora_nuggets_numtext.csv'\n",
    "\n",
    "m = csvigo.load({path = aroraname, mode = \"large\"})\n",
    "w = csvigo.load({path = wordfile, mode = \"large\"})\n",
    "q = csvigo.load({path = nuggets, mode = \"large\"})\n",
    "\n",
    "\n",
    "\n",
    "N = 1000 --- Breaks at 35\n",
    "K = 100\n",
    "embed_dim = 3\n",
    " \n",
    "dofile(\"utils.lua\")\n",
    "--- Extracting N samples\n",
    "out = grabNsamples(m, N, K)\n",
    "nuggs = grabNsamples(q, #q-1, nil)\n",
    "\n",
    "mxl = 0\n",
    "for k,v in pairs(out) do\n",
    "    mxl = math.max(mxl, #v)\n",
    "end\n",
    "\n",
    "--- getting the length of the dictionary\n",
    "vocab_size = 0\n",
    "for k,v in pairs(out) do\n",
    "    vocab_size = math.max(vocab_size, math.max(table.unpack(v)))\n",
    "    if (k % N)==0 then\n",
    "        print(k,'elements read out of ', #m)\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "--- Padding the data by the maximum length\n",
    "xs = padZeros(out, mxl)\n",
    "\n",
    "\n",
    "labels = torch.Tensor(torch.rand(#out)):reshape(#out,1)\n",
    "-- labels = torch.Tensor(torch.round(torch.rand(#out))):reshape(#out,1)\n",
    "\n",
    "--- This is the correct format to input it\n",
    "input = torch.LongTensor(xs)\n",
    "\n",
    "-- For batch inputs, it's a little easier to start with sequence-length x batch-size tensor, so we transpose songData\n",
    "myDataT = input:t()\n",
    "batchLSTM = nn.Sequential()\n",
    "batchLSTM:add(nn.LookupTableMaskZero(vocab_size, embed_dim)) -- will return a sequence-length x batch-size x embedDim tensor\n",
    "batchLSTM:add(nn.SplitTable(1, embed_dim)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "-- print(batchLSTM:forward(myDataT)) -- sanity check\n",
    "-- now let's add the LSTM stuff\n",
    "batchLSTM:add(nn.Sequencer(nn.LSTM(embed_dim, embed_dim)))\n",
    "batchLSTM:add(nn.SelectTable(-1)) -- selects last state of the LSTM\n",
    "batchLSTM:add(nn.Linear(embed_dim, 1)) -- map last state to a score for classification\n",
    "--batchLSTM:add(nn.Sigmoid()) -- convert score to a probability\n",
    "myPreds = batchLSTM:forward(myDataT)\n",
    "print(#myPreds)\n",
    "\n",
    "print(myPreds[1])\n",
    "-- we can now call :backward() as follows\n",
    "-- crit = nn.BCECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crit = nn.MSECriterion()\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = loss + crit:forward(myPreds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads = crit:backward(myPreds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchLSTM:backward(myDataT, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchLSTM:zeroGradParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = 0 \n",
    "for i=1, 5, 1 do\n",
    "    loss = loss + crit:forward(myPreds, labels)\n",
    "    grads = crit:backward(myPreds, labels)\n",
    "    batchLSTM:backward(myDataT, grads)\n",
    "\n",
    "    print('Current loss at iteration', i,' is ', loss)\n",
    "    \n",
    "    --We update params at the end of each batch\n",
    "    batchLSTM:updateParameters(0.05)\n",
    "    batchLSTM:zeroGradParameters()\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "preds = {}\n",
    "for i=1, myPreds:size()[1] do\n",
    "    preds[i] = (myPreds[i][1] > 0) and 1 or 0 --- lua is stupid\n",
    "end\n",
    "\n",
    "--- Unpacking predictions and concatenating predictions into a summary\n",
    "ys = unpackZeros(preds)\n",
    "predsummary = buildPredSummary(ys, xs)\n",
    "\n",
    "print(#predsummary)\n",
    "print('Rouge Recall =', rougeRecall(predsummary, nuggs))\n",
    "print('Rouge Precision =', rougePrecision(predsummary, nuggs))\n",
    "print('Rouge F1 =', rougeF1(predsummary, nuggs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
