{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'gnuplot'\n",
    "require 'rnn'\n",
    "require 'image'\n",
    "Plot = require 'itorch.Plot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpu=1\n",
    "if gpu>0 then\n",
    "  print(\"CUDA ON\")\n",
    "  require 'cutorch'\n",
    "  require 'cunn'\n",
    "  cutorch.setDevice(gpu)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nIters = 200\n",
    "batchSize = 80\n",
    "rho = 10\n",
    "hiddenSize = 300\n",
    "nIndex = 1\n",
    "lr = 0.0001\n",
    "nPredict=200\n",
    "\n",
    "rnn = nn.Sequential()\n",
    "   :add(nn.Linear(nIndex, hiddenSize))\n",
    "   :add(nn.FastLSTM(hiddenSize, hiddenSize))\n",
    "   :add(nn.NormStabilizer())\n",
    "   :add(nn.Linear(hiddenSize, nIndex))\n",
    "   :add(nn.HardTanh())\n",
    "rnn = nn.Sequencer(rnn)\n",
    "rnn:training()\n",
    "---- print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if gpu>0 then\n",
    "  rnn=rnn:cuda()\n",
    "end\n",
    "\n",
    "criterion = nn.MSECriterion()\n",
    "if gpu>0 then\n",
    "  criterion=criterion:cuda()\n",
    "end\n",
    "\n",
    "ii=torch.linspace(0,200, 2000)\n",
    "sequence=torch.cos(ii)\n",
    "if gpu>0 then\n",
    "  sequence=sequence:cuda()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offsets = {}\n",
    "for i=1,batchSize do\n",
    "   table.insert(offsets, math.ceil(math.random()* (sequence:size(1)-rho) ))\n",
    "end\n",
    "offsets = torch.LongTensor(offsets)\n",
    "if gpu>0 then\n",
    "  offsets=offsets:cuda()\n",
    "end\n",
    "\n",
    "--- local gradOutputsZeroed = {}\n",
    "gradOutputsZeroed = {}\n",
    "for step=1,rho do\n",
    "  gradOutputsZeroed[step] = torch.zeros(batchSize,1)\n",
    "  if gpu>0 then\n",
    "    gradOutputsZeroed[step] = gradOutputsZeroed[step]:cuda()\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local iteration = 5\n",
    "while iteration < nIters do\n",
    "   local inputs, targets = {}, {}\n",
    "    inputs2, targets2 = {}, {}\n",
    "   for step=1,rho do\n",
    "      inputs[step] = sequence:index(1, offsets):view(batchSize,1)\n",
    "      inputs2[step] = sequence:index(1, offsets):view(batchSize,1)\n",
    "      offsets:add(1)\n",
    "      for j=1,batchSize do\n",
    "         if offsets[j] > sequence:size(1) then\n",
    "            offsets[j] = 1\n",
    "         end\n",
    "      end\n",
    "      targets2[step] = sequence:index(1, offsets)\n",
    "      targets[step] = sequence:index(1, offsets)\n",
    "   end\n",
    "   rnn:zeroGradParameters()\n",
    "   local outputs = rnn:forward(inputs)\n",
    "   local err = criterion:forward(outputs[rho], targets[rho])\n",
    "   ---print(string.format(\"Iteration %d ; NLL err = %f \", iteration, err))\n",
    "   local gradOutputs = criterion:backward(outputs[rho], targets[rho])\n",
    "   gradOutputsZeroed[rho] = gradOutputs\n",
    "   local gradInputs = rnn:backward(inputs, gradOutputsZeroed)\n",
    "   rnn:updateParameters(lr)\n",
    "   iteration = iteration + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn:evaluate()\n",
    "predict=torch.FloatTensor(nPredict)\n",
    "if gpu>0 then\n",
    "  predict=predict:cuda()\n",
    "end\n",
    "for step=1,rho do\n",
    "  predict[step]= sequence[step]\n",
    "end\n",
    "\n",
    "start = {}\n",
    "iteration=0\n",
    "while rho + iteration < nPredict do\n",
    "  for step=1,rho do\n",
    "    start[step] = predict:index(1,torch.LongTensor({step+iteration})):view(1,1)\n",
    "  end\n",
    "\n",
    "  output = rnn:forward(start)\n",
    "\n",
    "  predict[iteration+rho+1] = (output[rho]:float())[1][1]\n",
    "\n",
    "  iteration = iteration + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- scatter plots\n",
    "plot = Plot():circle(torch.range(1, predict.size(predict)[1]), \n",
    "                predict, 'red', 'Loss Function'):draw()\n",
    "plot:line(torch.range(1, predict.size(predict)[1]), \n",
    "                predict, 'red', ''):redraw()\n",
    "plot:title('Scatter Plot Demo'):redraw()\n",
    "plot:xaxis('Iterations'):yaxis('Negative Log-Likelihood'):redraw()\n",
    "plot:legend(true)\n",
    "plot:redraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Start training\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t0\tloss\t0.56662445068359 in \t0.20637607574463 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t10\tloss\t0.54920355677605 in \t0.031195163726807 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t20\tloss\t0.54874401688576 in \t0.033711910247803 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t30\tloss\t0.54840999245644 in \t0.034494876861572 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t40\tloss\t0.54807159900665 in \t0.061195850372314 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t50\tloss\t0.54771014451981 in \t0.039511919021606 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t60\tloss\t0.54730515480042 in \t0.033943891525269 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t70\tloss\t0.54683074355125 in \t0.033765077590942 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t80\tloss\t0.54625191092491 in \t0.036449909210205 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t90\tloss\t0.54551874995232 in \t0.030251979827881 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch\t100\tloss\t0.54455727934837 in \t0.0414879322052 s\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'rnn'\n",
    "require 'cunn'\n",
    "cuda = true\n",
    "\n",
    "print(\"Running batch version of an RNN with continuous outcome\")\n",
    "\n",
    "function build_data()\n",
    "    local inputs = {}\n",
    "    local targets = {}\n",
    "    --Use previously created and saved data\n",
    "    for i = 1, dsSize do\n",
    "      -- populate both tables to get ready for training\n",
    "      -- local input = torch.randn(batchSize, inputSize)\n",
    "        local input = torch.Tensor({{1, 2, 3, 4}, {0, 1, 1, 3}})\n",
    "        local target = torch.randn(batchSize)\n",
    "        if cuda then\n",
    "            input = input:float():cuda()\n",
    "            target = target:float():cuda()\n",
    "        end\n",
    "            table.insert(inputs, input)\n",
    "            table.insert(targets, target)\n",
    "    end\n",
    "    return inputs, targets\n",
    "end\n",
    "\n",
    "function build_network(inputSize, hiddenSize, outputSize)\n",
    "    -- This works for the discrete\n",
    "    rnn = nn.Sequential()\n",
    "    rnn:add(nn.LookupTableMaskZero(4, hiddenSize))\n",
    "    rnn:add(nn.SeqLSTM(hiddenSize, hiddenSize))\n",
    "    rnn:add(nn.Select(1, -1))                       --- Select last embedding layer of sequence\n",
    "    rnn:add(nn.Linear(hiddenSize, outputSize))\n",
    "   -- wrap this in a Sequencer such that we can forward/backward \n",
    "   -- entire sequences of length seqLength at once\n",
    "   rnn = nn.Sequencer(rnn)\n",
    "   if cuda then\n",
    "      rnn:cuda()\n",
    "   end\n",
    "   return rnn\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "inputSize = 6\n",
    "-- Larger numbers here mean more complex problems can be solved, but can also over-fit. 256 works well for now\n",
    "hiddenSize = 8\n",
    "-- We want the network to classify the inputs using a one-hot representation of the outputs\n",
    "outputSize = 2\n",
    "\n",
    "-- the dataset size is the total number of examples we want to present to the LSTM \n",
    "dsSize=10\n",
    "\n",
    "-- We present the dataset to the network in batches where batchSize << dsSize\n",
    "batchSize=2\n",
    "\n",
    "-- And seqLength is the length of each sequence, i.e. the number of \"events\" we want to pass to the LSTM\n",
    "-- to make up a single example. I'd like this to be dynamic ideally for the YOOCHOOSE dataset..\n",
    "seqLength=8\n",
    "\n",
    "-- number of target classes or labels, needs to be the same as outputSize above\n",
    "-- or we get the dreaded \"ClassNLLCriterion.lua:46: Assertion `cur_target >= 0 && cur_target < n_classes' failed. \"\n",
    "nClass = 2\n",
    "\n",
    "-- two tables to hold the *full* dataset input and target tensors\n",
    "\n",
    "inputs, targets = build_data()\n",
    "rnn = build_network(inputSize, hiddenSize, outputSize)\n",
    "\n",
    "print('Example of inputs and outputs for a batch of data:')\n",
    "print(inputs[1], targets[2])\n",
    "\n",
    "crit = nn.MSECriterion()\n",
    "--- crit = nn.ClassNLLCriterion()\n",
    "seqC = nn.SequencerCriterion(crit)\n",
    "if cuda then\n",
    "   crit:cuda()\n",
    "   seqC:cuda()\n",
    "end\n",
    "\n",
    "rnn:training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- scatter plots\n",
    "plot = Plot():circle(torch.range(1, #loss), \n",
    "                loss, 'red', 'Loss Function'):draw()\n",
    "plot:line(torch.range(1, #loss), \n",
    "                loss, 'red', ''):redraw()\n",
    "plot:title('Scatter Plot Demo'):redraw()\n",
    "plot:xaxis('Iterations'):yaxis('Negative Log-Likelihood'):redraw()\n",
    "plot:legend(true)\n",
    "plot:redraw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
