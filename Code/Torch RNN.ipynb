{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nepochs = 250\n",
    "learning_rate = 0.1\n",
    "gamma =0.2\n",
    "cuts =4\n",
    "base_explore_rate = 0.1\n",
    "delta = 1./(nepochs/cuts) \n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "vocabSize = 16\n",
    "embeddingSize = 64\n",
    "\n",
    "torch.manualSeed(420)\n",
    "math.randomseed(420)\n",
    "\n",
    "sentenceLookup = nn.Sequential():add(\n",
    "    nn.LookupTableMaskZero(vocabSize, embeddingSize)):add(\n",
    "    nn.Sum(2, 3, false))\n",
    "\n",
    "queryLookup = sentenceLookup:clone() --\"weight\", \"gradWeight\")\n",
    "summaryLookup = sentenceLookup:clone() --\"weight\", \"gradWeight\")\n",
    "\n",
    "model = nn.Sequential():add(\n",
    "    nn.ParallelTable():add(\n",
    "        sentenceLookup):add(\n",
    "        queryLookup):add(\n",
    "        summaryLookup)):add(\n",
    "    nn.JoinTable(2)):add(\n",
    "    nn.Tanh()):add(\n",
    "    nn.Linear(embeddingSize * 3, 2)) --:add(\n",
    "    --nn.Tanh()):add(\n",
    "    --nn.Linear(embeddingSize, 2))\n",
    "criterion = nn.MSECriterion()\n",
    "params, gradParams = model:getParameters()\n",
    "\n",
    "function buildSummary(actions, sentences, buffer)\n",
    "    buffer:zero()\n",
    "\n",
    "     bufferSize = buffer:size(2)\n",
    "     actionsSize = actions:size(1)\n",
    "     sentencesSize = sentences:size(2)\n",
    "\n",
    "     mask1 = torch.eq(actions:select(2,2), 1):view(actionsSize, 1):expand(\n",
    "        actionsSize, sentencesSize)\n",
    "     allTokens = sentences:maskedSelect(mask1)\n",
    "     mask2 = torch.gt(allTokens,0)\n",
    "     allTokens = allTokens:maskedSelect(mask2)\n",
    "\n",
    "    if allTokens:dim() > 0 then\n",
    "         copySize = math.min(bufferSize, allTokens:size(1))\n",
    "\n",
    "        buffer[1]:narrow(1, bufferSize - copySize + 1, copySize):copy(\n",
    "            allTokens:narrow(1, allTokens:size(1) - copySize + 1, copySize))\n",
    "    end\n",
    "    return buffer\n",
    "end\n",
    "\n",
    "function buildTokenCounts(summary)\n",
    "    counts = {}\n",
    "    for i=1,summary:size(2) do\n",
    "        if summary[1][i] > 0 then\n",
    "             token = summary[1][i]\n",
    "            if counts[token] == nil then\n",
    "                counts[token] = 1\n",
    "            else\n",
    "                counts[token] = counts[token] + 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return counts\n",
    "end\n",
    "\n",
    "function rougeScores(genSummary, refSummary)\n",
    "     genTotal = 0\n",
    "     refTotal = 0\n",
    "     intersection = 0\n",
    "    for k, refCount in pairs(refSummary) do\n",
    "         genCount = genSummary[k]\n",
    "        if genCount == nil then genCount = 0 end\n",
    "        intersection = intersection + math.min(refCount, genCount)\n",
    "        refTotal = refTotal + refCount\n",
    "    end\n",
    "    for k,genCount in pairs(genSummary) do\n",
    "        genTotal = genTotal + genCount\n",
    "    end\n",
    "\n",
    "    if genTotal == 0 then \n",
    "        genTotal = 1 \n",
    "    end\n",
    "     recall = intersection / refTotal\n",
    "     prec = intersection / genTotal\n",
    "    if recall > 0 and prec > 0 then\n",
    "        f1 = 2 * recall * prec / (recall + prec)\n",
    "    else \n",
    "        f1 = 0\n",
    "    end\n",
    "    return recall, prec, f1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimParams = {\n",
    "    learningRate = learning_rate,\n",
    "}\n",
    "\n",
    "maxSummarySize = 36\n",
    "epsilon = 1.0\n",
    "query = torch.LongTensor{{0, 1, 4, 3}}\n",
    "sentenceStream = torch.Tensor{{0, 1, 3, 4}, \n",
    "                                {7, 6, 5 ,8}, \n",
    "                                {0, 2, 4, 3}, \n",
    "                                {7, 5, 8, 6}, \n",
    "                                {1, 4, 3, 2}, \n",
    "                                {13, 14, 15, 16}}\n",
    "\n",
    "refSummary = torch.Tensor{{1,3,4,2,4,3,1,4,3,2,9,10,12,11}}\n",
    "refCounts = buildTokenCounts(refSummary)\n",
    "\n",
    "\n",
    "streamSize = sentenceStream:size(1)\n",
    "bestActions = torch.ByteTensor{{0,1},{1,0},{0,1},{1,0},{0,1},{1,0}}\n",
    "\n",
    "\n",
    "buffer = torch.Tensor(1, maxSummarySize):zero()\n",
    "bestSummary = buildSummary(\n",
    "    bestActions:narrow(1, 1, 6), \n",
    "    sentenceStream:narrow(1, 1, 6),\n",
    "    buffer:narrow(1, 1, 1)\n",
    "    )\n",
    "\n",
    "generatedCounts = buildTokenCounts(bestSummary) \n",
    "bestrecall, bestprec, bestf1 = rougeScores(generatedCounts, refCounts)\n",
    "print(string.format(\"TRUE {RECALL = %.6f, PREC = %.6f, F1 = %.6f}\", bestrecall, bestprec, bestf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions = torch.ByteTensor(streamSize,2):fill(0)\n",
    "exploreDraws = torch.Tensor(streamSize)\n",
    "summaryBuffer = torch.LongTensor(streamSize + 1, maxSummarySize):zero()\n",
    "qValues = torch.Tensor(streamSize, 2):zero()\n",
    "rouge = torch.Tensor(streamSize + 1):zero()\n",
    "rougebp = torch.Tensor(streamSize + 1):zero()\n",
    "\n",
    "rouge[1] = 0\n",
    "exploreDraws:uniform(0, 1)\n",
    "summary = summaryBuffer:zero():narrow(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i=1, streamSize do\n",
    "    sentence = sentenceStream:narrow(1, i, 1)\n",
    "    qValues[i]:copy(model:forward({sentence, query, summary}))\n",
    "    \n",
    "    if exploreDraws[i] <= epsilon then\n",
    "        actions[i][torch.random(SKIP, SELECT)] = 1\n",
    "    else \n",
    "        if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "            actions[i][SKIP] = 1\n",
    "        else\n",
    "            actions[i][SELECT] = 1\n",
    "        end\n",
    "    end\n",
    "    summary = buildSummary(\n",
    "        actions:narrow(1, 1, i), \n",
    "        sentenceStream:narrow(1, 1, i),\n",
    "        summaryBuffer:narrow(1, i + 1, 1)\n",
    "        )\n",
    "\n",
    "    generatedCounts = buildTokenCounts(summary) \n",
    "    recall, prec, f1 = rougeScores(generatedCounts, refCounts)\n",
    "    rouge[i + 1] = f1\n",
    "    rougebp[i] = f1\n",
    "end\n",
    "\n",
    "max, argmax = torch.max(qValues, 2)\n",
    "rewards0 = rouge:narrow(1,2, streamSize) - rouge:narrow(1,1, streamSize) \n",
    "rewards = rewards0 + gamma * rewards0:narrow(1, 2, streamSize-1):resize(streamSize)\n",
    "\n",
    "querySize = query:size(2)\n",
    "summaryBatch = summaryBuffer:narrow(1, 1, streamSize)\n",
    "queryBatch = query:view(1, querySize):expand(streamSize, querySize) \n",
    "\n",
    "input = {sentenceStream, queryBatch, summaryBatch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function feval(params)\n",
    "    gradParams:zero()\n",
    "     predQ = model:forward(input)\n",
    "     maskLayer = nn.MaskedSelect()\n",
    "     predQOnActions = maskLayer:forward({predQ, actions})\n",
    "     loss = criterion:forward(predQOnActions, reward)\n",
    "     gradOutput = criterion(predQOnActions, reward)\n",
    "     gradMaskLayer = maskLayer:backward({predQ, actions}, gradOutput)\n",
    "    model:backward(input, gradMaskLayer[1])\n",
    "    return loss, gradParams    \n",
    "end\n",
    "\n",
    " _, loss = optim.adam(feval, params, optimParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = string.format(\"%i; %.3f;%.6f;%.6f; {min=%.3f, max=%.3f}; {min=%.3f, max=%.3f}; {%i,%i,%i,%i,%i,%i,%i,%i,%i,%i,%i,%i}\\n\", \n",
    "    epoch, epsilon, loss[1], rouge[streamSize + 1],\n",
    "    reward:min(), reward:max(),\n",
    "    qValues:min(), qValues:max(),\n",
    "    actions[1][1], \n",
    "    actions[1][2], \n",
    "    actions[2][1], \n",
    "    actions[2][2], \n",
    "    actions[3][1], \n",
    "    actions[3][2], \n",
    "    actions[4][1],\n",
    "    actions[4][2],\n",
    "    actions[5][1], \n",
    "    actions[5][2], \n",
    "    actions[6][1], \n",
    "    actions[6][2] \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nepochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying this separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nepochs = 1000\n",
    "learning_rate = 1e-6\n",
    "gamma =0.2\n",
    "cuts =4\n",
    "base_explore_rate = 0.1 \n",
    "delta = 1./(nepochs/cuts) \n",
    "\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "\n",
    "vocabSize = 16\n",
    "embeddingSize = 64\n",
    "\n",
    "torch.manualSeed(420)\n",
    "math.randomseed(420)\n",
    "\n",
    "sentenceLookup = nn.Sequential():add(\n",
    "    nn.LookupTableMaskZero(vocabSize, embeddingSize)):add(\n",
    "    nn.Sum(2, 3, false))\n",
    "\n",
    "queryLookup = sentenceLookup:clone() --\"weight\", \"gradWeight\")\n",
    "summaryLookup = sentenceLookup:clone() --\"weight\", \"gradWeight\")\n",
    "\n",
    "model = nn.Sequential():add(\n",
    "    nn.ParallelTable():add(\n",
    "        sentenceLookup):add(\n",
    "        queryLookup):add(\n",
    "        summaryLookup)):add(\n",
    "    nn.JoinTable(2)):add(\n",
    "    nn.Tanh()):add(\n",
    "    nn.Linear(embeddingSize * 3, 2)) --:add(\n",
    "    --nn.Tanh()):add(\n",
    "    --nn.Linear(embeddingSize, 2))\n",
    "criterion = nn.MSECriterion()\n",
    "params, gradParams = model:getParameters()\n",
    "\n",
    "function buildSummary(actions, sentences, buffer)\n",
    "    buffer:zero()\n",
    "\n",
    "     bufferSize = buffer:size(2)\n",
    "     actionsSize = actions:size(1)\n",
    "     sentencesSize = sentences:size(2)\n",
    "\n",
    "     mask1 = torch.eq(actions:select(2,2), 1):view(actionsSize, 1):expand(\n",
    "        actionsSize, sentencesSize)\n",
    "     allTokens = sentences:maskedSelect(mask1)\n",
    "     mask2 = torch.gt(allTokens,0)\n",
    "     allTokens = allTokens:maskedSelect(mask2)\n",
    "\n",
    "    if allTokens:dim() > 0 then\n",
    "         copySize = math.min(bufferSize, allTokens:size(1))\n",
    "\n",
    "        buffer[1]:narrow(1, bufferSize - copySize + 1, copySize):copy(\n",
    "            allTokens:narrow(1, allTokens:size(1) - copySize + 1, copySize))\n",
    "    end\n",
    "    return buffer\n",
    "end\n",
    "\n",
    "function buildTokenCounts(summary)\n",
    "    counts = {}\n",
    "    for i=1,summary:size(2) do\n",
    "        if summary[1][i] > 0 then\n",
    "             token = summary[1][i]\n",
    "            if counts[token] == nil then\n",
    "                counts[token] = 1\n",
    "            else\n",
    "                counts[token] = counts[token] + 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return counts\n",
    "end\n",
    "\n",
    "function rougeScores(genSummary, refSummary)\n",
    "     genTotal = 0\n",
    "     refTotal = 0\n",
    "     intersection = 0\n",
    "    for k, refCount in pairs(refSummary) do\n",
    "         genCount = genSummary[k]\n",
    "        if genCount == nil then genCount = 0 end\n",
    "        intersection = intersection + math.min(refCount, genCount)\n",
    "        refTotal = refTotal + refCount\n",
    "    end\n",
    "    for k,genCount in pairs(genSummary) do\n",
    "        genTotal = genTotal + genCount\n",
    "    end\n",
    "\n",
    "    if genTotal == 0 then \n",
    "        genTotal = 1 \n",
    "    end\n",
    "     recall = intersection / refTotal\n",
    "     prec = intersection / genTotal\n",
    "    if recall > 0 and prec > 0 then\n",
    "        f1 = 2 * recall * prec / (recall + prec)\n",
    "    else \n",
    "        f1 = 0\n",
    "    end\n",
    "    return recall, prec, f1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimParams = {\n",
    "    learningRate = learning_rate,\n",
    "}\n",
    "\n",
    "maxSummarySize = 36\n",
    "epsilon = 1.0\n",
    "query = torch.LongTensor{{0, 1, 4, 3}}\n",
    "sentenceStream = torch.Tensor{{0, 1, 3, 4}, \n",
    "                                {7, 6, 5 ,8}, \n",
    "                                {0, 2, 4, 3}, \n",
    "                                {7, 5, 8, 6}, \n",
    "                                {1, 4, 3, 2}, \n",
    "                                {13, 14, 15, 16}}\n",
    "\n",
    "refSummary = torch.Tensor{{1,3,4,2,4,3,1,4,3,2,9,10,12,11}}\n",
    "refCounts = buildTokenCounts(refSummary)\n",
    "\n",
    "\n",
    "streamSize = sentenceStream:size(1)\n",
    "bestActions = torch.ByteTensor{{0,1},{1,0},{0,1},{1,0},{0,1},{1,0}}\n",
    "\n",
    "\n",
    "buffer = torch.Tensor(1, maxSummarySize):zero()\n",
    "bestSummary = buildSummary(\n",
    "    bestActions:narrow(1, 1, 6), \n",
    "    sentenceStream:narrow(1, 1, 6),\n",
    "    buffer:narrow(1, 1, 1)\n",
    "    )\n",
    "\n",
    "generatedCounts = buildTokenCounts(bestSummary) \n",
    "bestrecall, bestprec, bestf1 = rougeScores(generatedCounts, refCounts)\n",
    "print(string.format(\"TRUE {RECALL = %.6f, PREC = %.6f, F1 = %.6f}\", bestrecall, bestprec, bestf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp0 = {}\n",
    "tmp1 = {}\n",
    "tmp2 = {}\n",
    "for epoch=1,nepochs do\n",
    "    actions = torch.ByteTensor(streamSize,2):fill(0)\n",
    "    exploreDraws = torch.Tensor(streamSize)\n",
    "    summaryBuffer = torch.LongTensor(streamSize + 1, maxSummarySize):zero()\n",
    "    qValues = torch.Tensor(streamSize, 2):zero()\n",
    "    rouge = torch.Tensor(streamSize + 1):zero()\n",
    "\n",
    "    rouge[1] = 1\n",
    "    exploreDraws:uniform(0, 1)\n",
    "\n",
    "    summary = summaryBuffer:zero():narrow(1,1,1)\n",
    "    for i=1, streamSize do\n",
    "        --- the i extracts individual sentences from the stream\n",
    "         sentence = sentenceStream:narrow(1, i, 1)\n",
    "        qValues[i]:copy(model:forward({sentence, query, summary}))\n",
    "\n",
    "        if exploreDraws[i] <= epsilon then\n",
    "            actions[i][torch.random(SKIP, SELECT)] = 1\n",
    "        else \n",
    "            if qValues[i][SKIP] > qValues[i][SELECT] then\n",
    "                actions[i][SKIP] = 1\n",
    "            else\n",
    "                actions[i][SELECT] = 1\n",
    "            end\n",
    "        end\n",
    "\n",
    "        summary = buildSummary(\n",
    "            actions:narrow(1, 1, i), \n",
    "            sentenceStream:narrow(1, 1, i),\n",
    "            summaryBuffer:narrow(1, i + 1, 1)\n",
    "            )\n",
    "\n",
    "         generatedCounts = buildTokenCounts(summary) \n",
    "         recall, prec, f1 = rougeScores(generatedCounts, refCounts)\n",
    "        rouge[i + 1] = f1\n",
    "    end\n",
    "\n",
    "     max, argmax = torch.max(qValues, 2)\n",
    "    \n",
    "     reward0 = rouge:narrow(1,2, streamSize) - rouge:narrow(1,1, streamSize)\n",
    "     reward_tp1 = gamma * reward0:narrow(1, 2, streamSize - 1):resize(streamSize)\n",
    "     reward_tp1[reward_tp1:ne(reward_tp1)] = 0\n",
    "     reward = reward0 + reward_tp1\n",
    "    \n",
    "     tmp0[epoch] = reward0\n",
    "     tmp1[epoch] = reward_tp1\n",
    "     tmp2[epoch] = reward\n",
    "    \n",
    "     querySize = query:size(2)\n",
    "     summaryBatch = summaryBuffer:narrow(1, 1, streamSize)\n",
    "     queryBatch = query:view(1, querySize):expand(streamSize, querySize) \n",
    "\n",
    "     input = {sentenceStream, queryBatch, summaryBatch}\n",
    "    if epoch == 1 then\n",
    "        print(input)\n",
    "    end\n",
    "\n",
    "     function feval(params)\n",
    "        gradParams:zero()\n",
    "         predQ = model:forward(input)\n",
    "         maskLayer = nn.MaskedSelect()\n",
    "         predQOnActions = maskLayer:forward({predQ, actions})\n",
    "\n",
    "         loss = criterion:forward(predQOnActions, reward)\n",
    "         gradOutput = criterion(predQOnActions, reward)\n",
    "         gradMaskLayer = maskLayer:backward({predQ, actions}, gradOutput)\n",
    "        model:backward(input, gradMaskLayer[1])\n",
    "        return loss, gradParams    \n",
    "    end\n",
    "\n",
    "     _, loss = optim.adam(feval, params, optimParams)\n",
    "    out = string.format(\"%i; %.3f;%.6f;%.6f; {min=%.3f, max=%.3f}; {min=%.3f, max=%.3f}; {%i,%i,%i,%i,%i,%i,%i,%i,%i,%i,%i,%i}\\n\", \n",
    "            epoch, epsilon, loss[1], rouge[streamSize + 1],\n",
    "            reward:min(), reward:max(),\n",
    "            qValues:min(), qValues:max(),\n",
    "            actions[1][1], \n",
    "            actions[1][2], \n",
    "            actions[2][1], \n",
    "            actions[2][2], \n",
    "            actions[3][1], \n",
    "            actions[3][2], \n",
    "            actions[4][1],\n",
    "            actions[4][2],\n",
    "            actions[5][1], \n",
    "            actions[5][2], \n",
    "            actions[6][1], \n",
    "            actions[6][2] \n",
    "        )\n",
    "    print(out)\n",
    "\n",
    "    if (epsilon - delta) <= base_explore_rate then\n",
    "        epsilon = base_explore_rate\n",
    "    else \n",
    "        epsilon = epsilon - delta\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.clamp(tmp0[360], -0.7, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.Threshold(0.06, 0):forward(tmp1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.Threshold(-.05, 0):forward(tmp0[360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp2[360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[6][tmp1[6]:ne(tmp1[6])] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp0[6]:narrow(1, 2, streamSize-1):resize(streamSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp0[6]:narrow(1, 2, streamSize-1):resize(streamSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp0[6] + gamma * tmp0[6]:narrow(1, 2, streamSize-1):resize(streamSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp0[242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--- If tmp0[242] < thresh, out else tmp0[242]\n",
    "thresh = -0.7\n",
    "out = 99\n",
    "print(nn.Threshold(thresh, out):forward(tmp0[242]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--- If tmp0[242] < thresh, out else tmp0[242]\n",
    "thresh = -0.25\n",
    "out = 99\n",
    "print(nn.Threshold(thresh, out):forward(-tmp0[242]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.Threshold(0.01, -0.001):forward(tmp0[242])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.Threshold(0.1, 0.01):forward(nn.Threshold(-0.01, -0.01):forward(tmp0[242]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i = 1, 500 do\n",
    "    print(tmp0[i] + tmp1[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentenceStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst = torch.cat(sentenceStream, sentenceStream, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local dl = require 'dataload'\n",
    "\n",
    "inputs = torch.range(1,5)\n",
    "targets = torch.range(1,5)\n",
    "\n",
    "dataloader = dl.TensorLoader(inputs, targets)\n",
    "\n",
    "local i = 1\n",
    "for k, inputs, targets in dataloader:sampleiter(2,6) do\n",
    "   print(string.format(\"batch %d, nsampled = %d; inputs = %.i\", i, k, inputs[1]))\n",
    "--    print(string.format(\"inputs:\\n%stargets:\\n%s\", inputs, targets))\n",
    "   i = i + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = torch.randn(5, 1)\n",
    "targets = torch.LongTensor(10):random(1,10):resize(5,2)\n",
    "dataloader = dl.TensorLoader(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch 1, nsampled = 5; target {i, i}\t\n",
       " 10   3\n",
       " 10   5\n",
       " 10   3\n",
       "  6   2\n",
       " 10   3\n",
       "[torch.LongTensor of size 5x2]\n",
       "\n",
       "batch 2, nsampled = 10; target {i, i}\t\n",
       "  1   6\n",
       " 10   3\n",
       "  6   2\n",
       " 10   5\n",
       "  3   3\n",
       "[torch.LongTensor of size 5x2]\n",
       "\n",
       "batch 3, nsampled = 15; target {i, i}\t\n",
       "  1   6\n",
       " 10   5\n",
       " 10   5\n",
       "  1   6\n",
       "  6   2\n",
       "[torch.LongTensor of size 5x2]\n",
       "\n",
       "batch 4, nsampled = 20; target {i, i}\t\n",
       "  3   3\n",
       " 10   3\n",
       "  1   6\n",
       " 10   5\n",
       "  6   2\n",
       "[torch.LongTensor of size 5x2]\n",
       "\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "for k, input, target in dataloader:sampleiter(5, 20) do\n",
    "    print(string.format(\"batch %d, nsampled = %d; target {i, i}\", i, k))\n",
    "    print(target)\n",
    "   i = i + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dl.TensorLoader\n",
       "{\n",
       "  inputs : DoubleTensor - size: 5x1\n",
       "  _indices : LongTensor - size: 2\n",
       "  gccount : 3\n",
       "  targets : LongTensor - size: 5\n",
       "  gcdelay : 200\n",
       "}\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dl = require 'dataload'\n",
    "\n",
    "inputs = torch.LongTensor({1,2, 3, 5}, {1, 2, 3}, {4, 5, 7}, {7, 8 ,8, 3, 2}, {1,2,3,4})\n",
    "targets = torch.LongTensor({1,2, 3, 5}, {1, 2, 3}, {4, 5, 7}, {7, 8 ,8, 3, 2}, {1,2,3,4})\n",
    "actions = torch.round(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "...eo/torch/install/share/lua/5.1/dataload/TensorLoader.lua:8: assertion failed!\nstack traceback:\n\t[C]: in function 'assert'\n\t...eo/torch/install/share/lua/5.1/dataload/TensorLoader.lua:8: in function '__init'\n\t...cojavierarceo/torch/install/share/lua/5.1/torch/init.lua:91: in function <...cojavierarceo/torch/install/share/lua/5.1/torch/init.lua:87>\n\t[C]: in function 'TensorLoader'\n\t[string \"dataloader = dl.TensorLoader(inputs, actions)...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010848fb90",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "...eo/torch/install/share/lua/5.1/dataload/TensorLoader.lua:8: assertion failed!\nstack traceback:\n\t[C]: in function 'assert'\n\t...eo/torch/install/share/lua/5.1/dataload/TensorLoader.lua:8: in function '__init'\n\t...cojavierarceo/torch/install/share/lua/5.1/torch/init.lua:91: in function <...cojavierarceo/torch/install/share/lua/5.1/torch/init.lua:87>\n\t[C]: in function 'TensorLoader'\n\t[string \"dataloader = dl.TensorLoader(inputs, actions)...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010848fb90"
     ]
    }
   ],
   "source": [
    "dataloader = dl.TensorLoader(inputs, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for k, input, target, action in dataloader:sampleiter(1,5) do\n",
    "   print(string.format(\"batch %d, nsampled = %d\", i, k))\n",
    "   i = i + 1\n",
    "    if i==5 then\n",
    "        print(input, target, action)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl = require 'dataload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloader = dl.TensorLoader(tst, tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, inputs, targets in dataloader:sampleiter(batchSize, tst:size()) do\n",
    "    print(i, inputs, targets)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, inputs, targets in testSet:sampleiter(batchSize, testSet:size()) do\n",
    "   trainInputs:resize(inputs:size()):copy(inputs)\n",
    "   trainTargets:resize(targets:size()):copy(targets)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst:sampleiter(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tst[indx]:resize(12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.cat(summaryBatch, summaryBatch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
