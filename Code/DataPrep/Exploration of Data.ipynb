{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to build pipeline\n",
    "\n",
    "1. Tokenize the query\n",
    "2. Tokenize the streams\n",
    "3. Tokenize the stream\n",
    "\n",
    "Run LSTM on query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/corpus-data/')\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./2012_aurora_shooting.tsv.gz', sep='\\t')\n",
    "df2 = pd.read_csv('./2012_pakistan_garment_factory_fires.tsv.gz', sep='\\t')\n",
    "df3 = pd.read_csv('./hurricane_sandy.tsv.gz', sep='\\t')\n",
    "df4 = pd.read_csv('./wisconsin_sikh_temple_shooting.tsv.gz', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( df1[df1['sentence'] < 1].shape, \n",
    "       df2[df2['sentence'] < 1].shape, \n",
    "       df3[df3['sentence'] < 1].shape, \n",
    "       df4[df4['sentence'] < 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1[df1['sentence'] < 1].to_csv(\"./2012_aurora_shooting_first_sentence.tsv\", index=False, sep='\\t') \n",
    "df2[df2['sentence'] < 1].to_csv(\"./2012_pakistan_garment_factory_fires_first_sentence.tsv\", index=False, sep='\\t') \n",
    "df3[df3['sentence'] < 1].to_csv('./hurricane_sandy_first_sentence.tsv', index=False, sep='\\t') \n",
    "df4[df4['sentence'] < 1].to_csv('./wisconsin_sikh_temple_shooting_first_sentence.tsv', index=False, sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! gzip ./2012_aurora_shooting_first_sentence.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! gzip ./2012_pakistan_garment_factory_fires_first_sentence.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! gzip ./hurricane_sandy_first_sentence.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! gzip ./wisconsin_sikh_temple_shooting_first_sentence.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.shape, df2.shape, df3.shape, df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.shape[0] + df2.shape[0] + df3.shape[0] + df4.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Title is the title of the article\n",
    "print df1[df1['stream id']=='1342767285-e9b3e7dc6a9e31c8b2301848ab082117'].title[1]\n",
    "# Each text is a stream (i.e., a sentence from the article)\n",
    "print df1[df1['stream id']=='1342767285-e9b3e7dc6a9e31c8b2301848ab082117'].text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir('/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/trec-2013-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/trec-2013-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for q in df5['query_id'].unique().tolist():\n",
    "    print(q, df5[df5['query_id']==q].shape, df5[df5['query_id']==q]['nugget_text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df5[df5['query_id']=='TS13.3'].to_csv(\"./aurora_nuggets.tsv\", sep='\\t')\n",
    "df5[df5['query_id']=='TS13.2'].to_csv(\"./pakistan_nuggets.tsv\", sep='\\t')\n",
    "df5[df5['query_id']=='TS13.6'].to_csv(\"./sandy_nuggets.tsv\", sep='\\t')\n",
    "df5[df5['query_id']=='TS13.4'].to_csv(\"./wisconsin_nuggets.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! gzip /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/trec-2013-data/aurora_nuggets.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! gzip /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/trec-2013-data/pakistan_nuggets.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! gzip /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/trec-2013-data/sandy_nuggets.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! gzip /Users/franciscojavierarceo/GitHub/DeepNLPQLearning/DO_NOT_UPLOAD_THIS_DATA/trec-2013-data/wisconsin_nuggets.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./nuggets-data/nuggets_2013.tsv.gz\", sep='\\t')\n",
    "df2 = pd.read_csv(\"./nuggets-data/nuggets_2014.tsv.gz\", sep='\\t')\n",
    "df3 = pd.read_csv(\"./nuggets-data/nuggets_2015.tsv.gz\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, x in enumerate(qdf.ix[7,:]):\n",
    "    print(idx, qdf.columns[idx], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtuple[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdf = pd.read_csv(\"./0-output/total_corpus_smry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join([str(tdf.ix[tdf['token']==token, 'id'].values[0]) for token in q.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qtokens = []\n",
    "for q in qdf[\"query\"]:\n",
    "    tokens = []\n",
    "    for token in q.split(\" \"):\n",
    "        try:\n",
    "            tval = str(tdf.ix[tdf['token']==token, 'id'].values[0])\n",
    "        except:\n",
    "            tval = str(0)\n",
    "        tokens.append(tval)\n",
    "    qtokens.append(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qdf['tokens'] = qtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qdf.to_csv(\"./0-output/dqn_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nuggfiles = [os.path.join(inputdir, 'nuggets-data/nuggets_%i.tsv.gz') % x for x in range(2013, 2016)]\n",
    "# Exporting nuggets\n",
    "for nuggfile in nuggfiles:\n",
    "    tmpnuggets = pd.read_csv(nuggfile, sep='\\t')\n",
    "    for q in tmpnuggets['query_id'].unique():\n",
    "         if \"TEST\" not in q:\n",
    "            tmpnuggets[tmpnuggets['query_id']==q].to_csv(\n",
    "                os.path.join(inputdir, \"nuggets-data/%s_nuggets.csv\" % q), index=False\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qfilenames = [os.path.join(inputdir, 'trec-data/trec%i-ts-topics-test.xml') % x for x in range(2013, 2014)]\n",
    "qtuple = list(chain(*[read_queries(xml_file) for xml_file in qfilenames ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infilelist = [os.path.join(inputdir, 'corpus-data/%s.tsv.gz' % t.replace(\" \", \"_\").lower()) for (q, i, n, t)  in qtuple if i != 7]\n",
    "# Limiting the files\n",
    "input_files = [os.path.join(inputdir, 'corpus-data/', x) for x in os.listdir(os.path.join(inputdir, 'corpus-data/')) if 'tsv.gz' in x]\n",
    "infilelist = [x for x in infilelist if x in input_files]\n",
    "\n",
    "infilelist = infilelist + qfilenames\n",
    "nuggetlist = [os.path.join(inputdir, '%s.%i_nuggets.csv' % (n, i)) for (q, i, n, t)  in qtuple]\n",
    "outfilelist = [os.path.join(inputdir, '0-output/%s_tokenized' % x.split(\"/\")[-1].split(\".\")[0]) for x in infilelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qdf = pd.DataFrame(qtuple, columns=['query', 'query_id', 'trec', 'title'])\n",
    "qdf['nugget_file'] = qdf['trec'] + \".\" + qdf['query_id'].astype(str) + \"_nuggets.csv\"\n",
    "qdf['stream_file'] = qdf['title'].str.replace(\" \", \"_\").str.lower() + \".csv\"\n",
    "qdf = qdf[['query_id','query','trec','nugget_file','stream_file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qtuple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qdf.ix[0,:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.listdir('../0-output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../0-output/2012_aurora_shooting_numtext.csv\")\n",
    "df2 = pd.read_csv(\"../0-output/2012_pakistan_garment_factory_fires_numtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxl = []\n",
    "for line in df1['Text']:\n",
    "    indices = [int(el) for el in line.split(\" \")]\n",
    "    maxl.append(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(maxl, columns=['seqlen'])\n",
    "smry = df3['seqlen'].value_counts().reset_index()\n",
    "smry.columns = ['seqlen' ,'count']\n",
    "smry['cumcount'] = smry['count'].cumsum()\n",
    "smry['percent'] = smry['count'] / smry['count'].sum()\n",
    "smry['cumpercent'] = smry['percent'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looks like the cutoff should be 30\n",
    "smry[['percent','cumpercent']].head(35).tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
