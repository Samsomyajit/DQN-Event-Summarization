{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'image'\n",
    "require 'optim'\n",
    "require 'parallel'\n",
    "dl = require 'dataload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Some useful functions\n",
    "function genNbyK(n, k, a, b)\n",
    "    out = torch.LongTensor(n, k)\n",
    "    for i=1, n do\n",
    "        for j = 1, k do\n",
    "            out[i][j] = torch.random(a, b)\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function buildModel(model, vocabSize, embeddingSize, metric, adapt, use_cuda)\n",
    "    -- Small experiments seem to show that the Tanh activations performed better\\\n",
    "    --      than the ReLU for the bow model\n",
    "    if model == 'bow' then\n",
    "        print(string.format(\"Running bag-of-words model to learn %s\", metric))\n",
    "        sentenceLookup = nn.Sequential()\n",
    "                    :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                    :add(nn.Sum(2, 3, true)) -- Not averaging blows up model so keep this true\n",
    "                    :add(nn.Tanh())\n",
    "    else\n",
    "        print(string.format(\"Running LSTM model to learn %s\", metric))\n",
    "        sentenceLookup = nn.Sequential()\n",
    "                    :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                    :add(nn.SplitTable(2))\n",
    "                    :add(nn.Sequencer(nn.LSTM(embeddingSize, embeddingSize)))\n",
    "                    :add(nn.SelectTable(-1))            -- selects last state of the LSTM\n",
    "                    :add(nn.Linear(embeddingSize, embeddingSize))\n",
    "                    :add(nn.ReLU())\n",
    "    end\n",
    "    local queryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\") \n",
    "    local summaryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\")\n",
    "    local pmodule = nn.ParallelTable()\n",
    "                :add(sentenceLookup)\n",
    "                :add(queryLookup)\n",
    "                :add(summaryLookup)\n",
    "\n",
    "    if model == 'bow' then\n",
    "        nnmodel = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(nn.Tanh())\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "    else\n",
    "        nnmodel = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(nn.ReLU())\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "    end\n",
    "\n",
    "    if adapt then \n",
    "        print(\"Adaptive regularization\")\n",
    "        local logmod = nn.Sequential()\n",
    "            :add(nn.Linear(embeddingSize * 3, 1))\n",
    "            :add(nn.LogSigmoid())\n",
    "            :add(nn.SoftMax())\n",
    "\n",
    "        local regmod = nn.Sequential()\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "\n",
    "        local fullmod = nn.ConcatTable()\n",
    "            :add(regmod)\n",
    "            :add(logmod)\n",
    "\n",
    "        local final = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(fullmod)\n",
    "\n",
    "        nnmodel = final\n",
    "    end\n",
    "\n",
    "    if use_cuda then\n",
    "        return nnmodel:cuda()\n",
    "    end\n",
    "    return nnmodel\n",
    "end\n",
    "\n",
    "function Tokenize(inputdic)\n",
    "    --- This function tokenizes the words into a unigram dictionary\n",
    "    local out = {}\n",
    "\n",
    "    for k, v in pairs(inputdic) do\n",
    "        if v ~= 0 then \n",
    "            if out[v] == nil then\n",
    "                out[v] = 1\n",
    "            else \n",
    "                out[v] = 1 + out[v]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function rougeScores(genSummary, refSummary)\n",
    "    local genTotal = 0\n",
    "    local refTotal = 0\n",
    "    local intersection = 0\n",
    "    -- Inserting the missing keys\n",
    "    for k, genCount in pairs(genSummary) do\n",
    "        if refSummary[k] == nil then\n",
    "            refSummary[k] = 0\n",
    "        end\n",
    "    end\n",
    "    for k, refCount in pairs(refSummary) do\n",
    "        local genCount = genSummary[k]\n",
    "        if genCount == nil then \n",
    "            genCount = 0 \n",
    "        end\n",
    "        intersection = intersection + math.min(refCount, genCount)\n",
    "        refTotal = refTotal + refCount\n",
    "        genTotal = genTotal + genCount\n",
    "    end\n",
    "\n",
    "    recall = intersection / refTotal\n",
    "    prec = intersection / genTotal\n",
    "    if refTotal == 0 then\n",
    "        recall = 0\n",
    "    end \n",
    "    if genTotal == 0 then\n",
    "        prec = 0\n",
    "    end\n",
    "    -- tmp = {intersection, refTotal, genTotal}\n",
    "    if recall > 0 or prec > 0 then\n",
    "        f1 = (2 * recall * prec) / (recall + prec)\n",
    "    else \n",
    "        f1 = 0\n",
    "    end\n",
    "    return recall, prec, f1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function buildPredsummary(chosenactions, inputsentences, select_index)\n",
    "    local summary = torch.zeros(inputsentences:size())\n",
    "    for i=1, chosenactions:size(1) do\n",
    "        -- the 2 is for the SELECT index, will have to make this more general later\n",
    "        if chosenactions[i][select_index] == 1 then\n",
    "            summary[i]:copy(inputsentences[i])\n",
    "        end\n",
    "    end    \n",
    "    return summary\n",
    "end\n",
    "\n",
    "function buildPredsummaryFast(chosenactions, inputsentences, select_index)\n",
    "    local n = inputsentences:size(1)\n",
    "    local k = inputsentences:size(2)\n",
    "    local summary = torch.zeros(inputsentences:size())\n",
    "    actionmatrix = chosenactions:select(2, select_index):clone():resize(n, 1):view(n, 1):expand(n, k):clone()\n",
    "    --     This line didn't work for whatever reason...gives weird indexing...\n",
    "    --     actionmatrix = chosenactions:select(2, select_index):resize(1, n):view(n, 1):expand(n, k):clone()\n",
    "    return actionmatrix:cmul(inputsentences:double())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function buildTotalSummary(predsummary, totalPredsummary)\n",
    "    nps = predsummary:size(1)\n",
    "    n_l = totalPredsummary:size(2)\n",
    "    indices = torch.linspace(1, n_l, n_l):long() \n",
    "    for i=1, predsummary:size(1) do\n",
    "        if predsummary[i]:sum() > 0 then \n",
    "            -- maxindex = 0\n",
    "            -- for j = 1, totalPredsummary[i]:size(1) do \n",
    "            --     if totalPredsummary[i][j] == 0 then\n",
    "            --         maxindex = maxindex + 1\n",
    "            --     end\n",
    "            -- end\n",
    "            -- lenx = predsummary[i]:size(1)\n",
    "            -- totalPredsummary[i][{{maxindex - lenx + 1, maxindex}}]:copy(predsummary[i])\n",
    "\n",
    "            minindex = 1\n",
    "            for j = 1, totalPredsummary[i]:size(1) do \n",
    "                if totalPredsummary[i][j] > 0 then\n",
    "                    minindex = minindex + 1\n",
    "                end\n",
    "            end\n",
    "            lenx = predsummary[i]:size(1)\n",
    "            totalPredsummary[i][{{minindex, minindex + lenx - 1}}]:copy(predsummary[i])\n",
    "\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "-- function buildTotalSummaryFast(predsummary, inputTotalSummary)\n",
    "--     totalPredsummary = inputTotalSummary:clone()\n",
    "--     nps = predsummary:size(1)\n",
    "--     n_l = inputTotalSummary:size(2)\n",
    "--     indices = torch.linspace(1, n_l, n_l):long() \n",
    "--     for i=1, predsummary:size(1) do\n",
    "--         if predsummary[i]:sum() > 0 then \n",
    "--             -- Finding the largest index with a zero\n",
    "--             -- maxindex = torch.max(indices[torch.eq(totalPredsummary[i], 0)])\n",
    "--             -- totalPredsummary[i][{{maxindex - lenx + 1, maxindex}}]:copy(predsummary[i])\n",
    "--             -- Finding the smallest index with a zero\n",
    "--             minindex = torch.min(indices[torch.eq(inputTotalSummary[i], 0)])\n",
    "--             lenx = predsummary[i]:size(1)\n",
    "--             totalPredsummary[i][{{minindex, minindex + lenx - 1}}]:copy(predsummary[i])\n",
    "--         end\n",
    "--     end\n",
    "--     return totalPredsummary\n",
    "-- end\n",
    "\n",
    "function buildTotalSummaryFast(predsummary, inputTotalSummary)\n",
    "    tmpSummary = inputTotalSummary:clone()\n",
    "    nps = predsummary:size(1)\n",
    "    n_l = inputTotalSummary:size(2)\n",
    "    indices = torch.linspace(1, n_l, n_l):long() \n",
    "    for i=1, predsummary:size(1) do\n",
    "        if predsummary[i]:sum() > 0 then \n",
    "            -- Finding the largest index with a zero\n",
    "            -- maxindex = torch.max(indices[torch.eq(totalPredsummary[i], 0)])\n",
    "            -- totalPredsummary[i][{{maxindex - lenx + 1, maxindex}}]:copy(predsummary[i])\n",
    "            -- Finding the smallest index with a zero\n",
    "            minindex = torch.min(indices[torch.eq(tmpSummary[i], 0)])\n",
    "            lenx = predsummary[i]:size(1)\n",
    "            tmpSummary[i][{{minindex, minindex + lenx - 1}}]:copy(predsummary[i])\n",
    "        end\n",
    "    end\n",
    "    return tmpSummary\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Setting parameters\n",
    "-- n = 10\n",
    "n = 1\n",
    "n_s = 10\n",
    "k = 8\n",
    "q = 5\n",
    "a = 1\n",
    "b = 1000\n",
    "embDim = 50\n",
    "gamma = 0.\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "epsilon = 1\n",
    "nepochs = 1000\n",
    "fast = true\n",
    "\n",
    "maskLayer = nn.MaskedSelect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Simulating streams and queries\n",
    "queries = genNbyK(n, q, a, b)\n",
    "\n",
    "-- Note that the sentences are batched by sentence index so sentences[1] is the first sentence of each article\n",
    "sentences = {}\n",
    "for i=1, n_s do\n",
    "    sentences[i] = genNbyK(n, k, a, b)\n",
    "end\n",
    "-- Optimal predicted summary\n",
    "trueSummary = torch.zeros(n, k * n_s)\n",
    "-- Using this to generate the optimal actions\n",
    "true_actions = {}\n",
    "\n",
    "for i=1, n_s do \n",
    "    ---- Simulating the data\n",
    "    trueqValues = torch.rand(n, 2)\n",
    "    \n",
    "     ---- Generating the max values and getting the indices\n",
    "    qMaxtrue, qindxtrue = torch.max(trueqValues, 2)\n",
    "    \n",
    "    --- I want to select the qindx elements for each row\n",
    "    true_actions[i] = torch.zeros(n, 2):scatter(2, qindxtrue, torch.ones(trueqValues:size()))\n",
    "    best_sentences = buildPredsummaryFast(true_actions[i], sentences[i], SELECT)\n",
    "    trueSummary = buildTotalSummaryFast(best_sentences, trueSummary)\n",
    "end\n",
    "\n",
    "qTokens = {}\n",
    "for i=1, n do\n",
    "    qTokens[i] = Tokenize(trueSummary[i]:totable())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the rougue metrics on the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t1\t1\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rougeScores(Tokenize(trueSummary[1]:totable()), Tokenize(trueSummary[1]:totable())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running bag-of-words model to learn f1\t\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- model = buildModel('lstm', b, embDim, 'f1', false, false)\n",
    "model = buildModel('bow', b, embDim, 'f1', false, false)\n",
    "\n",
    "params, gradParams = model:getParameters()\n",
    "criterion = nn.MSECriterion()\n",
    "maskLayer = nn.MaskedSelect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the model on the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0\n",
    "nepochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimParams = { learningRate = 1e-10}\n",
    "\n",
    "totalPredsummary = {}\n",
    "qValues = {}\n",
    "qActions = {}\n",
    "qPreds = {}\n",
    "rewards = {}\n",
    "lossfull = {}\n",
    "rouguef1 = {}\n",
    "\n",
    "totalPredsummary = torch.LongTensor(n, n_s * k):fill(0)\n",
    "\n",
    "memsize = n * n_s\n",
    "queryMemory = torch.zeros(memsize, q)\n",
    "qActionMemory = torch.zeros(memsize, 2)\n",
    "predSummaryMemory = torch.zeros(memsize, n_s * k)\n",
    "sentenceMemory = torch.zeros(memsize, k)\n",
    "qPredsMemory = torch.zeros(memsize, 2)\n",
    "qValuesMemory = torch.zeros(memsize, 1)\n",
    "rewardMemory = torch.zeros(memsize, 1)\n",
    "\n",
    "\n",
    "--- Initializing things\n",
    "for i = 1, n_s do\n",
    "    qPreds[i] = torch.zeros(n, 2)\n",
    "    qValues[i] = torch.zeros(n, 1) \n",
    "    qActions[i] = torch.zeros(n, 2)\n",
    "    rewards[i] = torch.zeros(n, 1)\n",
    "end \n",
    "\n",
    "for epoch=1, nepochs do\n",
    "    --- Reset things at the start of each epoch\n",
    "    for i=1, n_s do\n",
    "        qPreds[i]:fill(0)\n",
    "        qValues[i]:fill(0)\n",
    "        qActions[i]:fill(0)\n",
    "        rewards[i]:fill(0)\n",
    "        totalPredsummary:fill(0)\n",
    "    end\n",
    "\n",
    "    for i=1, n_s do\n",
    "        if torch.uniform(0, 1) <= epsilon then \n",
    "            qPreds[i]:copy(torch.rand(n, 2))\n",
    "            -- Need to run a forward pass for the backward to work...wonky\n",
    "            ignore = model:forward({sentences[i], queries, totalPredsummary})\n",
    "        else \n",
    "            qPreds[i]:copy(model:forward({sentences[i], queries, totalPredsummary}) )\n",
    "        end \n",
    "        if fast then \n",
    "            qMax, qindx = torch.max(qPreds[i], 2)  -- Pulling the best actions\n",
    "            -- Here's the fast way to select the optimal action for each query\n",
    "            qActions[i]:copy(qActions[i]:scatter(2, qindx, torch.ones(qPreds[i]:size())):clone())\n",
    "            qValues[i]:copy(qMax)\n",
    "            predsummary = buildPredsummaryFast(qActions[i], sentences[i], SELECT)\n",
    "            totalPredsummary = buildTotalSummaryFast(predsummary, totalPredsummary)\n",
    "        else \n",
    "            for j=1, n do\n",
    "                if qPreds[i][j][SELECT] > qPreds[i][j][SKIP] then\n",
    "                    qActions[i][j][SELECT] = 1\n",
    "                    qValues[i][j]:fill(qPreds[i][j][SELECT])\n",
    "                else\n",
    "                    qActions[i][j][SKIP] = 1\n",
    "                    qValues[i][j]:fill(qPreds[i][j][SKIP])\n",
    "                end\n",
    "            end\n",
    "            predsummary = buildPredsummary(qActions[i], sentences[i], SELECT)\n",
    "            buildTotalSummary(predsummary, totalPredsummary)\n",
    "        end\n",
    "        for j = 1, n do\n",
    "            recall, prec, f1 = rougeScores( qTokens[j],\n",
    "                                            Tokenize(totalPredsummary[j]:totable()))\n",
    "            rewards[i][j]:fill(f1)\n",
    "        end\n",
    "        if i > 1 then\n",
    "            -- Calculating change in rougue f1\n",
    "            rewards[i]:copy(rewards[i] - rewards[i-1])\n",
    "        end\n",
    "        -- Update memory sequentially until it's full \n",
    "        qActionMemory[{{n * (i-1) + 1, n * i}}]:copy(qActions[i])\n",
    "        predSummaryMemory[{{n * (i-1) + 1, n * i}}]:copy(totalPredsummary)\n",
    "        sentenceMemory[{{n * (i-1) + 1, n * i}}]:copy(sentences[i])\n",
    "        qPredsMemory[{{n * (i-1) + 1, n * i}}]:copy(qPreds[i])\n",
    "        qValuesMemory[{{n * (i-1) + 1, n * i}}]:copy(qValues[i])\n",
    "        queryMemory[{{n * (i-1) + 1, n * i}}]:copy(queries)\n",
    "        if i  < n_s then\n",
    "            rewardMemory[{{n * (i-1) + 1, n * i}}]:copy(rewards[i] + gamma * rewards[i + 1] )\n",
    "        else\n",
    "            rewardMemory[{{n * (i-1) + 1, n * i}}]:copy(rewards[i] )\n",
    "        end\n",
    "    end\n",
    "    -- Adding back the delta for the last one\n",
    "    rouguef1[epoch] = (rewards[n_s] + rewards[ n_s - 1] ):mean()\n",
    "\n",
    "    loss = {}\n",
    "    local dataloader = dl.TensorLoader({queryMemory, sentenceMemory, predSummaryMemory, \n",
    "                            qPredsMemory, qActionMemory, qValuesMemory}, rewardMemory)\n",
    "    c = 1\n",
    "    for k, xin, reward in dataloader:sampleiter(batch_size, memsize) do\n",
    "        local function feval(params)\n",
    "            gradParams:zero()\n",
    "            if adapt then\n",
    "                local ignore = model:forward({xin[1], xin[2], xin[3]})\n",
    "                local predQOnActions = maskLayer:forward({qPredsMemory, actions_in}) \n",
    "                local ones = torch.ones(predQ:size(1)):resize(predQ:size(1))\n",
    "                lossf = criterion:forward({qValuesMemory, predReg}, {reward, ones})\n",
    "                local gradOutput = criterion:backward({qActionMemory, predReg}, {reward, ones})\n",
    "                local gradMaskLayer = maskLayer:backward({qPredsMemory, qActionMemory}, gradOutput[1])\n",
    "                model:backward({xin[1], xin[2], xin[3]}, {gradMaskLayer[1], gradOutput[2]})\n",
    "            else \n",
    "                local ignore = model:forward({xin[1], xin[2], xin[3]})\n",
    "                local predQOnActions = maskLayer:forward({xin[4], xin[5]:byte()}) \n",
    "                lossf = criterion:forward(predQOnActions, reward)\n",
    "                local gradOutput = criterion:backward(predQOnActions, reward)\n",
    "                local gradMaskLayer = maskLayer:backward({xin[4], xin[5]:byte()}, gradOutput)\n",
    "                model:backward({xin[1], xin[2], xin[3]}, gradMaskLayer[1])\n",
    "            end \n",
    "            return lossf, gradParams\n",
    "        end\n",
    "        --- optim.rmsprop returns \\theta, f(\\theta):= loss function\n",
    "         _, lossv  = optim.rmsprop(feval, params, optimParams)\n",
    "        loss[c] = lossv[1]\n",
    "        c = c + 1\n",
    "    end\n",
    "\n",
    "    lossfull[epoch] = torch.Tensor(loss):sum() / #lossv\n",
    "    if print_perf then\n",
    "        print(\n",
    "            string.format('epoch = %i; rougue = %.6f; epsilon = %.6f; loss = %.6f' , \n",
    "                epoch, rouguef1[epoch], epsilon, lossfull[epoch])\n",
    "            )\n",
    "    end\n",
    "    epsilon = epsilon - (1/10.)\n",
    "    if epsilon < 0 then\n",
    "        epsilon = 0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "$(function() {\n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\"){\n",
       "  window._bokeh_onload_callbacks = [];\n",
       "    }\n",
       "    function load_lib(url, callback){\n",
       "  window._bokeh_onload_callbacks.push(callback);\n",
       "  if (window._bokeh_is_loading){\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", new Date());\n",
       "      return null;\n",
       "  }\n",
       "  console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", new Date());\n",
       "  window._bokeh_is_loading = true;\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = function(){\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh-0.7.0.min.css\");\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback){callback()});\n",
       "  };\n",
       "  s.onerror = function(){\n",
       "      console.warn(\"failed to load library \" + url);\n",
       "  };\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "\n",
       "    bokehjs_url = \"https://cdn.pydata.org/bokeh-0.7.0.min.js\"\n",
       "\n",
       "    var elt = document.getElementById(\"fab3f2f3-127e-4ce6-cc19-1c6b840c9daf\");\n",
       "    if(elt==null) {\n",
       "  console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'fab3f2f3-127e-4ce6-cc19-1c6b840c9daf'\"\n",
       "        + \"but no matching script tag was found. \")\n",
       "  return false;\n",
       "    }\n",
       "\n",
       "    if(typeof(Bokeh) !== \"undefined\") {\n",
       "  console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "  var modelid = \"22a0af10-dc51-48d6-c8af-c0428286a515\";\n",
       "  var modeltype = \"Plot\";\n",
       "  var all_models = [{\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\",\"type\":\"ColumnDataSource\",\"attributes\":{\"data\":{\"y\":[0.12063415811363,0.059093454677443,0.0617121947253,0.079433248087111,0.089094839443473,0.058748744297042,0.12318766190796,0.065280581718156,0.044400566130389,0.05613576938365,0.072443550354083,0.069753249009035,0.054106391992593,0.071959322923401,0.059268884691235,0.075037024615807,0.054259571825086,0.042297819318421,0.069887145815666,0.059010716910682,0.062968991304398,0.075601088218427,0.024094675472161,0.06772224295174,0.049398800499935,0.046777167645339,0.088182247939337,0.03759657504172,0.065800215384342,0.039022274192487,0.054052708982241,0.091789130327604,0.073871802229388,0.099830870192662,0.056779312216825,0.088772682337457,0.075434300661139,0.062085103175939,0.080239282352593,0.11447446797078,0.048412312487153,0.054678417482522,0.047931536653289,0.060639717954694,0.12208555993643,0.064130367757257,0.078613357527152,0.077670406155118,0.036214727933642,0.071678407936602,0.046369168272863,0.077626478619921,0.089865591685768,0.056989619013406,0.052493115741655,0.09299499363917,0.022133408912219,0.058212616221384,0.065796604800683,0.026465163618851,0.079419006487377,0.048240315844377,0.050998013274448,0.066917702468272,0.040052519435707,0.08478097832423,0.058794418084676,0.076387223639432,0.076632404037999,0.075964084591546,0.067572670315454,0.070982598492078,0.07842638182649,0.084970734312988,0.040994051703135,0.078565628447765,0.008643291000006,0.084833930828134,0.062482272220894,0.049792345997121,0.056476371142371,0.10632985717589,0.031632209038061,0.087034368041687,0.043138882130541,0.094615646185562,0.063681755548237,0.10745734219516,0.06843321661748,0.042069821005507,0.061583899993895,0.024496351995207,0.023222004445328,0.049838197245419,0.11612320590457,0.022791827010484,0.075603292466074,0.085447323712993,0.081146850795559,0.073585992129644,0.063357827250308,0.058707510096818,0.028475760002234,0.049548373408214,0.06533372694919,0.089337478249653,0.051442078748659,0.063896947293648,0.022485407742534,0.045160837245216,0.047676624546775,0.081938596131844,0.030768756533453,0.052371321022639,0.039105952892375,0.078380993492299,0.049843801286944,0.051672275359314,0.073619952792596,0.037192023175421,0.072827684974835,0.062008540848565,0.034341477235411,0.080171896241874,0.080026608774419,0.04674827704235,0.086271812773583,0.083196087299326,0.065113240108144,0.063677073728335,0.045347684592236,0.078395262913607,0.054970228149884,0.036246392303737,0.014801522869735,0.098678373777901,0.05607303497706,0.070040727743667,0.086641388616878,0.067005705713313,0.034879146178847,0.039141730720066,0.0509439558795,0.064493762328031,0.04827771088133,0.065585740711275,0.076520554898763,0.052198631476187,0.054640309544735,0.022933809441575,0.079546603910562,0.088686173454469,0.040861097125052,0.048694539692807,0.060438749440021,0.052864244614866,0.079526549372757,0.06581618332564,0.053191600356836,0.056983826210378,0.085101683514577,0.037585589038755,0.046477063927235,0.087029516743998,0.082353571609492,0.071418599013859,0.047887125799723,0.053657801010018,0.036882690037561,0.088235387743393,0.06102889458798,0.034159878556514,0.061624578512587,0.076685536143588,0.051230334784875,0.037593134555609,0.075869417594128,0.0594153111637,0.048851406417133,0.067409897328823,0.071216388174688,0.081216761771933,0.074453777166078,0.059263085579028,0.10184878466988,0.051381002884398,0.066377850003344,0.092712803485825,0.046337793000387,0.056776093768431,0.050783401253999,0.060192163019606,0.077316620004334,0.092309832028789,0.065188399177181,0.07827761775151,0.047817298621968,0.10003995644917,0.081972873008841,0.11451536032745,0.082550473014215,0.066888060406896,0.074485393533215,0.053638228283666,0.11247570993488,0.049699446194984,0.1099736598695,0.047972013856032,0.05651387054021,0.060520980961537,0.056586573855401,0.06542075936803,0.03692950408526,0.037549241607641,0.079958865767094,0.051529212191971,0.076449579906787,0.07266270848312,0.081081404449908,0.049735383772773,0.067990037132347,0.021718399529581,0.070131954948841,0.09158109921248,0.070315477534129,0.063384561481408,0.086166060892587,0.05094739922466,0.046056618914847,0.083358112052729,0.048436180947531,0.050880425866604,0.096569890679131,0.095810743150095,0.074941968351508,0.060099523868201,0.082452931843287,0.09343945375794,0.065183082637097,0.078404482686316,0.059468026685206,0.063446164003481,0.099575264842108,0.042633890221603,0.081208584178248,0.071652908499268,0.098967397851999,0.073731822215049,0.044123748224888,0.061132066925673,0.061467711240058,0.04053509127865,0.074717301381858,0.08209272238117,0.062351858894488,0.079466727928053,0.048170015824326,0.069683509248415,0.054740196894414,0.058553210941569,0.024958136464783,0.050936417089878,0.053520998196431,0.029918477444572,0.062565938484012,0.078593680486093,0.075766562651686,0.047884216097534,0.054208065623957,0.024442144915223,0.094556896028729,0.066098940825969,0.040132368946105,0.023977449624329,0.081642600483296,0.094859066109229,0.068637063189399,0.083547633906243,0.048359322869867,0.067378127096832,0.073984763795488,0.075435824010149,0.072026716038168,0.024813777582952,0.087399689283036,0.12811807797071,0.067193973497742,0.073290564453377,0.091827378880677,0.045329568238554,0.09364038264579,0.063593962956637,0.072353055679643,0.053080159631998,0.056415803107846,0.065008088597986,0.058890371846456,0.06163269950905,0.057873752038384,0.067751512988626,0.036794369836885,0.050860847050072,0.038927591400614,0.059106857706362,0.065081382118853,0.082736969368,0.05536894592079,0.12170646068443,0.044567869423071,0.09955030804827,0.053798826917189,0.064351342030185,0.080870960719138,0.042000253823633,0.052093795444452,0.073087880663515,0.1118338902907,0.052342406862389,0.074452318354166,0.065824207178917,0.096932127807001,0.10681551614143,0.07538280870006,0.067913289198567,0.087302155247271,0.040920014861187,0.089206435875277,0.075518872791367,0.06035241468767,0.050415847213957,0.051647168034999,0.05093641982862,0.076737144004216,0.059112422505046,0.088256680004437,0.079395113219011,0.04341148107191,0.10927462252675,0.10033783241934,0.089848172293971,0.044816130032008,0.056868218208073,0.050495062035507,0.074354360104358,0.040444575425517,0.0087195350089289,0.036544353487258,0.077008729050059,0.07767381818798,0.062378931350172,0.047998941577025,0.054125377526944,0.069102114872291,0.075565339767631,0.10344123096303,0.066680416069404,0.085578453469033,0.075330779790011,0.042677802544134,0.051160020962603,0.042697122183167,0.065280634830772,0.067209566904448,0.072756508491328,0.08880608987013,0.10188650624722,0.052005837628577,0.060786438628561,0.090153568449696,0.070783664045496,0.063717700428629,0.045033663881603,0.032123111649265,0.067338840478303,0.068238658766154,0.024037398991238,0.046168816850764,0.074072724765201,0.031092842153363,0.045658968500987,0.10018181637985,0.061356855217286,0.0650778727227,0.024779817894176,0.063516776738179,0.097025290242296,0.066826889648716,0.040306580039604,0.03885770105717,0.061549436019202,0.08976864097024,0.036370729199406,0.060056372345312,0.08145441956852,0.087446349666151,0.068140701460133,0.066995838664647,0.061477361665876,0.083600427844509,0.036363632205575,0.06066101719438,0.062613384136924,0.059986932396252,0.063852119871467,0.049842051578709,0.072366214720666,0.035683242973764,0.045638924364071,0.063746965692411,0.075440093579543,0.062561788651014,0.066595978819404,0.060784688575139,0.069232719918056,0.062901139666727,0.076262496027728,0.096715639183996,0.095890299067122,0.052442865142827,0.049314064205223,0.081589476093167,0.060234758246689,0.053611165359238,0.023828936615389,0.056106978091831,0.12139249660149,0.049847839961639,0.023513294460785,0.051777333408994,0.085232721604924,0.051737904901663,0.051877208911727,0.070582740147938,0.080544795612083,0.084410761905065,0.10336331879005,0.087020528797009,0.029205171987031,0.084490532073321,0.084809668412356,0.068371327872759,0.057282870979464,0.032853779931045,0.089468943507643,0.038140291517156,0.062638012198189,0.052736658225757,0.045615066735993,0.069850858406366,0.068149171911584,0.099600582877236,0.062575992296696,0.10323668515379,0.075363535037554,0.065003773873742,0.073575301897361,0.074897300762233,0.091414268481783,0.042605020912698,0.056160099751004,0.058119610271243,0.059803346723387,0.064396170974809,0.036465356510115,0.040341268644735,0.078213506947008,0.10032142646125,0.058097063764343,0.0657908371156,0.081326958478747,0.04963784731214,0.02093859045308,0.081119523414874,0.091459850507485,0.08619958757221,0.041073739588305,0.088323364843764,0.08439761199382,0.11480582039423,0.056169761584322,0.075376488126902,0.041739866983397,0.0609914761685,0.076282099724238,0.088020818919757,0.045904892755973,0.062101786278461,0.053008972874554,0.06084241370956,0.090977296956842,0.068851665432567,0.094941824151827,0.053386151351686,0.066941616525077,0.05874709465268,0.060173608506909,0.068305702206932,0.043875646609128,0.083056285381708,0.062351310962691],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500]},\"column_names\":[\"y\",\"x\"],\"cont_ranges\":{},\"discrete_ranges\":{},\"selected\":[],\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\",\"doc\":null,\"tags\":[]}},{\"id\":\"7bbe68dd-c0ac-4601-c690-b6a17007e869\",\"type\":\"Line\",\"attributes\":{\"fill_alpha\":{\"units\":\"data\",\"value\":0.2},\"line_alpha\":{\"units\":\"data\",\"value\":1},\"doc\":null,\"size\":{\"units\":\"screen\",\"value\":10},\"fill_color\":{\"value\":\"red\"},\"line_color\":{\"value\":\"red\"},\"x\":{\"units\":\"data\",\"field\":\"x\"},\"id\":\"7bbe68dd-c0ac-4601-c690-b6a17007e869\",\"y\":{\"units\":\"data\",\"field\":\"y\"},\"tags\":[]}},{\"id\":\"14fa8eac-f8f7-4366-c3e5-5f7646066f34\",\"type\":\"Line\",\"attributes\":{\"fill_alpha\":{\"units\":\"data\",\"value\":0.2},\"line_alpha\":{\"units\":\"data\",\"value\":1},\"doc\":null,\"size\":{\"units\":\"screen\",\"value\":10},\"fill_color\":{\"value\":\"red\"},\"line_color\":{\"value\":\"red\"},\"x\":{\"units\":\"data\",\"field\":\"x\"},\"id\":\"14fa8eac-f8f7-4366-c3e5-5f7646066f34\",\"y\":{\"units\":\"data\",\"field\":\"y\"},\"tags\":[]}},{\"id\":\"042700f1-5140-4818-c8ef-4a59310a917a\",\"type\":\"GlyphRenderer\",\"attributes\":{\"name\":null,\"nonselection_glyph\":{\"type\":\"Line\",\"id\":\"14fa8eac-f8f7-4366-c3e5-5f7646066f34\"},\"doc\":null,\"server_data_source\":null,\"data_source\":{\"type\":\"ColumnDataSource\",\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\"},\"glyph\":{\"type\":\"Line\",\"id\":\"7bbe68dd-c0ac-4601-c690-b6a17007e869\"},\"selection_glyph\":null,\"id\":\"042700f1-5140-4818-c8ef-4a59310a917a\",\"tags\":[]}},{\"id\":\"12e6d30f-f429-4fcd-cf96-5bab9578bfcc\",\"type\":\"DataRange1d\",\"attributes\":{\"sources\":[{\"columns\":[\"x\"],\"source\":{\"type\":\"ColumnDataSource\",\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\"}}],\"id\":\"12e6d30f-f429-4fcd-cf96-5bab9578bfcc\",\"tags\":[],\"doc\":null}},{\"id\":\"8d023e15-7372-48e5-c830-3a7001776575\",\"type\":\"DataRange1d\",\"attributes\":{\"sources\":[{\"columns\":[\"y\"],\"source\":{\"type\":\"ColumnDataSource\",\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\"}}],\"id\":\"8d023e15-7372-48e5-c830-3a7001776575\",\"tags\":[],\"doc\":null}},{\"id\":\"42c1fb1d-76cd-4619-c6c3-be5473d9c219\",\"type\":\"ToolEvents\",\"attributes\":{\"tags\":[],\"id\":\"42c1fb1d-76cd-4619-c6c3-be5473d9c219\",\"geometries\":[],\"doc\":null}},{\"id\":\"1ce97f20-55b2-42f3-c27d-d8df55e6fe33\",\"type\":\"BasicTickFormatter\",\"attributes\":{\"id\":\"1ce97f20-55b2-42f3-c27d-d8df55e6fe33\",\"tags\":[],\"doc\":null}},{\"id\":\"14a5a30c-4dfe-4108-c11d-c4fe72f427fb\",\"type\":\"BasicTicker\",\"attributes\":{\"num_minor_ticks\":5,\"id\":\"14a5a30c-4dfe-4108-c11d-c4fe72f427fb\",\"tags\":[],\"doc\":null}},{\"id\":\"e59ebcbd-048b-4f35-cf35-b33d0e10ba2f\",\"type\":\"LinearAxis\",\"attributes\":{\"formatter\":{\"type\":\"BasicTickFormatter\",\"id\":\"1ce97f20-55b2-42f3-c27d-d8df55e6fe33\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"14a5a30c-4dfe-4108-c11d-c4fe72f427fb\"},\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"axis_label\":null,\"id\":\"e59ebcbd-048b-4f35-cf35-b33d0e10ba2f\",\"doc\":null,\"tags\":[]}},{\"id\":\"e6d74480-15da-42c7-c2e2-f977a5907f7a\",\"type\":\"Grid\",\"attributes\":{\"dimension\":0,\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"14a5a30c-4dfe-4108-c11d-c4fe72f427fb\"},\"id\":\"e6d74480-15da-42c7-c2e2-f977a5907f7a\",\"doc\":null,\"tags\":[]}},{\"id\":\"dc3f086d-8493-4463-c446-bfa51d91ece3\",\"type\":\"BasicTickFormatter\",\"attributes\":{\"id\":\"dc3f086d-8493-4463-c446-bfa51d91ece3\",\"tags\":[],\"doc\":null}},{\"id\":\"4efe6906-7f6e-4b7a-cbb6-c9581ae09565\",\"type\":\"BasicTicker\",\"attributes\":{\"num_minor_ticks\":5,\"id\":\"4efe6906-7f6e-4b7a-cbb6-c9581ae09565\",\"tags\":[],\"doc\":null}},{\"id\":\"b31786bf-6ee1-49e7-c97e-44a5707a150b\",\"type\":\"LinearAxis\",\"attributes\":{\"formatter\":{\"type\":\"BasicTickFormatter\",\"id\":\"dc3f086d-8493-4463-c446-bfa51d91ece3\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"4efe6906-7f6e-4b7a-cbb6-c9581ae09565\"},\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"axis_label\":null,\"id\":\"b31786bf-6ee1-49e7-c97e-44a5707a150b\",\"doc\":null,\"tags\":[]}},{\"id\":\"d98a3ad8-b633-4d21-cdd0-efbbece20df6\",\"type\":\"Grid\",\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"4efe6906-7f6e-4b7a-cbb6-c9581ae09565\"},\"id\":\"d98a3ad8-b633-4d21-cdd0-efbbece20df6\",\"doc\":null,\"tags\":[]}},{\"id\":\"6489fd83-016d-405e-c085-2bd377825077\",\"type\":\"PanTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"dimensions\":[\"width\",\"height\"],\"id\":\"6489fd83-016d-405e-c085-2bd377825077\",\"doc\":null,\"tags\":[]}},{\"id\":\"9922e825-0443-475d-c72f-8c762696bc10\",\"type\":\"WheelZoomTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"dimensions\":[\"width\",\"height\"],\"id\":\"9922e825-0443-475d-c72f-8c762696bc10\",\"doc\":null,\"tags\":[]}},{\"id\":\"84a6df1f-9e7e-46d3-c6f7-ab19c296731d\",\"type\":\"BoxZoomTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"84a6df1f-9e7e-46d3-c6f7-ab19c296731d\",\"tags\":[],\"doc\":null}},{\"id\":\"769f8b92-aaae-4d8b-cd41-83186b96a017\",\"type\":\"PreviewSaveTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"769f8b92-aaae-4d8b-cd41-83186b96a017\",\"tags\":[],\"doc\":null}},{\"id\":\"1c06e864-2c5f-4804-c80b-f55d23fa588a\",\"type\":\"ResizeTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"1c06e864-2c5f-4804-c80b-f55d23fa588a\",\"tags\":[],\"doc\":null}},{\"id\":\"7fca70fd-9d1c-4648-c6e6-a30ccb24f472\",\"type\":\"ResetTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"7fca70fd-9d1c-4648-c6e6-a30ccb24f472\",\"tags\":[],\"doc\":null}},{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"attributes\":{\"x_range\":{\"type\":\"DataRange1d\",\"id\":\"12e6d30f-f429-4fcd-cf96-5bab9578bfcc\"},\"tool_events\":{\"type\":\"ToolEvents\",\"id\":\"42c1fb1d-76cd-4619-c6c3-be5473d9c219\"},\"below\":[{\"type\":\"LinearAxis\",\"id\":\"e59ebcbd-048b-4f35-cf35-b33d0e10ba2f\"}],\"renderers\":[{\"type\":\"GlyphRenderer\",\"id\":\"042700f1-5140-4818-c8ef-4a59310a917a\"},{\"type\":\"LinearAxis\",\"id\":\"e59ebcbd-048b-4f35-cf35-b33d0e10ba2f\"},{\"type\":\"Grid\",\"id\":\"e6d74480-15da-42c7-c2e2-f977a5907f7a\"},{\"type\":\"LinearAxis\",\"id\":\"b31786bf-6ee1-49e7-c97e-44a5707a150b\"},{\"type\":\"Grid\",\"id\":\"d98a3ad8-b633-4d21-cdd0-efbbece20df6\"}],\"above\":[],\"tools\":[{\"type\":\"PanTool\",\"id\":\"6489fd83-016d-405e-c085-2bd377825077\"},{\"type\":\"WheelZoomTool\",\"id\":\"9922e825-0443-475d-c72f-8c762696bc10\"},{\"type\":\"BoxZoomTool\",\"id\":\"84a6df1f-9e7e-46d3-c6f7-ab19c296731d\"},{\"type\":\"PreviewSaveTool\",\"id\":\"769f8b92-aaae-4d8b-cd41-83186b96a017\"},{\"type\":\"ResizeTool\",\"id\":\"1c06e864-2c5f-4804-c80b-f55d23fa588a\"},{\"type\":\"ResetTool\",\"id\":\"7fca70fd-9d1c-4648-c6e6-a30ccb24f472\"}],\"doc\":null,\"right\":[],\"title\":\"Plot of loss\",\"extra_x_ranges\":{},\"left\":[{\"type\":\"LinearAxis\",\"id\":\"b31786bf-6ee1-49e7-c97e-44a5707a150b\"}],\"y_range\":{\"type\":\"DataRange1d\",\"id\":\"8d023e15-7372-48e5-c830-3a7001776575\"},\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"extra_y_ranges\":{},\"tags\":[]}}];\n",
       "  Bokeh.load_models(all_models);\n",
       "  var model = Bokeh.Collections(modeltype).get(modelid);\n",
       "  $(\"#fab3f2f3-127e-4ce6-cc19-1c6b840c9daf\").html(''); // clear any previous plot in window_id\n",
       "  var view = new model.default_view({model: model, el: \"#fab3f2f3-127e-4ce6-cc19-1c6b840c9daf\"});\n",
       "    } else {\n",
       "  load_lib(bokehjs_url, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", new Date())\n",
       "      var modelid = \"22a0af10-dc51-48d6-c8af-c0428286a515\";\n",
       "      var modeltype = \"Plot\";\n",
       "      var all_models = [{\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\",\"type\":\"ColumnDataSource\",\"attributes\":{\"data\":{\"y\":[0.12063415811363,0.059093454677443,0.0617121947253,0.079433248087111,0.089094839443473,0.058748744297042,0.12318766190796,0.065280581718156,0.044400566130389,0.05613576938365,0.072443550354083,0.069753249009035,0.054106391992593,0.071959322923401,0.059268884691235,0.075037024615807,0.054259571825086,0.042297819318421,0.069887145815666,0.059010716910682,0.062968991304398,0.075601088218427,0.024094675472161,0.06772224295174,0.049398800499935,0.046777167645339,0.088182247939337,0.03759657504172,0.065800215384342,0.039022274192487,0.054052708982241,0.091789130327604,0.073871802229388,0.099830870192662,0.056779312216825,0.088772682337457,0.075434300661139,0.062085103175939,0.080239282352593,0.11447446797078,0.048412312487153,0.054678417482522,0.047931536653289,0.060639717954694,0.12208555993643,0.064130367757257,0.078613357527152,0.077670406155118,0.036214727933642,0.071678407936602,0.046369168272863,0.077626478619921,0.089865591685768,0.056989619013406,0.052493115741655,0.09299499363917,0.022133408912219,0.058212616221384,0.065796604800683,0.026465163618851,0.079419006487377,0.048240315844377,0.050998013274448,0.066917702468272,0.040052519435707,0.08478097832423,0.058794418084676,0.076387223639432,0.076632404037999,0.075964084591546,0.067572670315454,0.070982598492078,0.07842638182649,0.084970734312988,0.040994051703135,0.078565628447765,0.008643291000006,0.084833930828134,0.062482272220894,0.049792345997121,0.056476371142371,0.10632985717589,0.031632209038061,0.087034368041687,0.043138882130541,0.094615646185562,0.063681755548237,0.10745734219516,0.06843321661748,0.042069821005507,0.061583899993895,0.024496351995207,0.023222004445328,0.049838197245419,0.11612320590457,0.022791827010484,0.075603292466074,0.085447323712993,0.081146850795559,0.073585992129644,0.063357827250308,0.058707510096818,0.028475760002234,0.049548373408214,0.06533372694919,0.089337478249653,0.051442078748659,0.063896947293648,0.022485407742534,0.045160837245216,0.047676624546775,0.081938596131844,0.030768756533453,0.052371321022639,0.039105952892375,0.078380993492299,0.049843801286944,0.051672275359314,0.073619952792596,0.037192023175421,0.072827684974835,0.062008540848565,0.034341477235411,0.080171896241874,0.080026608774419,0.04674827704235,0.086271812773583,0.083196087299326,0.065113240108144,0.063677073728335,0.045347684592236,0.078395262913607,0.054970228149884,0.036246392303737,0.014801522869735,0.098678373777901,0.05607303497706,0.070040727743667,0.086641388616878,0.067005705713313,0.034879146178847,0.039141730720066,0.0509439558795,0.064493762328031,0.04827771088133,0.065585740711275,0.076520554898763,0.052198631476187,0.054640309544735,0.022933809441575,0.079546603910562,0.088686173454469,0.040861097125052,0.048694539692807,0.060438749440021,0.052864244614866,0.079526549372757,0.06581618332564,0.053191600356836,0.056983826210378,0.085101683514577,0.037585589038755,0.046477063927235,0.087029516743998,0.082353571609492,0.071418599013859,0.047887125799723,0.053657801010018,0.036882690037561,0.088235387743393,0.06102889458798,0.034159878556514,0.061624578512587,0.076685536143588,0.051230334784875,0.037593134555609,0.075869417594128,0.0594153111637,0.048851406417133,0.067409897328823,0.071216388174688,0.081216761771933,0.074453777166078,0.059263085579028,0.10184878466988,0.051381002884398,0.066377850003344,0.092712803485825,0.046337793000387,0.056776093768431,0.050783401253999,0.060192163019606,0.077316620004334,0.092309832028789,0.065188399177181,0.07827761775151,0.047817298621968,0.10003995644917,0.081972873008841,0.11451536032745,0.082550473014215,0.066888060406896,0.074485393533215,0.053638228283666,0.11247570993488,0.049699446194984,0.1099736598695,0.047972013856032,0.05651387054021,0.060520980961537,0.056586573855401,0.06542075936803,0.03692950408526,0.037549241607641,0.079958865767094,0.051529212191971,0.076449579906787,0.07266270848312,0.081081404449908,0.049735383772773,0.067990037132347,0.021718399529581,0.070131954948841,0.09158109921248,0.070315477534129,0.063384561481408,0.086166060892587,0.05094739922466,0.046056618914847,0.083358112052729,0.048436180947531,0.050880425866604,0.096569890679131,0.095810743150095,0.074941968351508,0.060099523868201,0.082452931843287,0.09343945375794,0.065183082637097,0.078404482686316,0.059468026685206,0.063446164003481,0.099575264842108,0.042633890221603,0.081208584178248,0.071652908499268,0.098967397851999,0.073731822215049,0.044123748224888,0.061132066925673,0.061467711240058,0.04053509127865,0.074717301381858,0.08209272238117,0.062351858894488,0.079466727928053,0.048170015824326,0.069683509248415,0.054740196894414,0.058553210941569,0.024958136464783,0.050936417089878,0.053520998196431,0.029918477444572,0.062565938484012,0.078593680486093,0.075766562651686,0.047884216097534,0.054208065623957,0.024442144915223,0.094556896028729,0.066098940825969,0.040132368946105,0.023977449624329,0.081642600483296,0.094859066109229,0.068637063189399,0.083547633906243,0.048359322869867,0.067378127096832,0.073984763795488,0.075435824010149,0.072026716038168,0.024813777582952,0.087399689283036,0.12811807797071,0.067193973497742,0.073290564453377,0.091827378880677,0.045329568238554,0.09364038264579,0.063593962956637,0.072353055679643,0.053080159631998,0.056415803107846,0.065008088597986,0.058890371846456,0.06163269950905,0.057873752038384,0.067751512988626,0.036794369836885,0.050860847050072,0.038927591400614,0.059106857706362,0.065081382118853,0.082736969368,0.05536894592079,0.12170646068443,0.044567869423071,0.09955030804827,0.053798826917189,0.064351342030185,0.080870960719138,0.042000253823633,0.052093795444452,0.073087880663515,0.1118338902907,0.052342406862389,0.074452318354166,0.065824207178917,0.096932127807001,0.10681551614143,0.07538280870006,0.067913289198567,0.087302155247271,0.040920014861187,0.089206435875277,0.075518872791367,0.06035241468767,0.050415847213957,0.051647168034999,0.05093641982862,0.076737144004216,0.059112422505046,0.088256680004437,0.079395113219011,0.04341148107191,0.10927462252675,0.10033783241934,0.089848172293971,0.044816130032008,0.056868218208073,0.050495062035507,0.074354360104358,0.040444575425517,0.0087195350089289,0.036544353487258,0.077008729050059,0.07767381818798,0.062378931350172,0.047998941577025,0.054125377526944,0.069102114872291,0.075565339767631,0.10344123096303,0.066680416069404,0.085578453469033,0.075330779790011,0.042677802544134,0.051160020962603,0.042697122183167,0.065280634830772,0.067209566904448,0.072756508491328,0.08880608987013,0.10188650624722,0.052005837628577,0.060786438628561,0.090153568449696,0.070783664045496,0.063717700428629,0.045033663881603,0.032123111649265,0.067338840478303,0.068238658766154,0.024037398991238,0.046168816850764,0.074072724765201,0.031092842153363,0.045658968500987,0.10018181637985,0.061356855217286,0.0650778727227,0.024779817894176,0.063516776738179,0.097025290242296,0.066826889648716,0.040306580039604,0.03885770105717,0.061549436019202,0.08976864097024,0.036370729199406,0.060056372345312,0.08145441956852,0.087446349666151,0.068140701460133,0.066995838664647,0.061477361665876,0.083600427844509,0.036363632205575,0.06066101719438,0.062613384136924,0.059986932396252,0.063852119871467,0.049842051578709,0.072366214720666,0.035683242973764,0.045638924364071,0.063746965692411,0.075440093579543,0.062561788651014,0.066595978819404,0.060784688575139,0.069232719918056,0.062901139666727,0.076262496027728,0.096715639183996,0.095890299067122,0.052442865142827,0.049314064205223,0.081589476093167,0.060234758246689,0.053611165359238,0.023828936615389,0.056106978091831,0.12139249660149,0.049847839961639,0.023513294460785,0.051777333408994,0.085232721604924,0.051737904901663,0.051877208911727,0.070582740147938,0.080544795612083,0.084410761905065,0.10336331879005,0.087020528797009,0.029205171987031,0.084490532073321,0.084809668412356,0.068371327872759,0.057282870979464,0.032853779931045,0.089468943507643,0.038140291517156,0.062638012198189,0.052736658225757,0.045615066735993,0.069850858406366,0.068149171911584,0.099600582877236,0.062575992296696,0.10323668515379,0.075363535037554,0.065003773873742,0.073575301897361,0.074897300762233,0.091414268481783,0.042605020912698,0.056160099751004,0.058119610271243,0.059803346723387,0.064396170974809,0.036465356510115,0.040341268644735,0.078213506947008,0.10032142646125,0.058097063764343,0.0657908371156,0.081326958478747,0.04963784731214,0.02093859045308,0.081119523414874,0.091459850507485,0.08619958757221,0.041073739588305,0.088323364843764,0.08439761199382,0.11480582039423,0.056169761584322,0.075376488126902,0.041739866983397,0.0609914761685,0.076282099724238,0.088020818919757,0.045904892755973,0.062101786278461,0.053008972874554,0.06084241370956,0.090977296956842,0.068851665432567,0.094941824151827,0.053386151351686,0.066941616525077,0.05874709465268,0.060173608506909,0.068305702206932,0.043875646609128,0.083056285381708,0.062351310962691],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500]},\"column_names\":[\"y\",\"x\"],\"cont_ranges\":{},\"discrete_ranges\":{},\"selected\":[],\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\",\"doc\":null,\"tags\":[]}},{\"id\":\"7bbe68dd-c0ac-4601-c690-b6a17007e869\",\"type\":\"Line\",\"attributes\":{\"fill_alpha\":{\"units\":\"data\",\"value\":0.2},\"line_alpha\":{\"units\":\"data\",\"value\":1},\"doc\":null,\"size\":{\"units\":\"screen\",\"value\":10},\"fill_color\":{\"value\":\"red\"},\"line_color\":{\"value\":\"red\"},\"x\":{\"units\":\"data\",\"field\":\"x\"},\"id\":\"7bbe68dd-c0ac-4601-c690-b6a17007e869\",\"y\":{\"units\":\"data\",\"field\":\"y\"},\"tags\":[]}},{\"id\":\"14fa8eac-f8f7-4366-c3e5-5f7646066f34\",\"type\":\"Line\",\"attributes\":{\"fill_alpha\":{\"units\":\"data\",\"value\":0.2},\"line_alpha\":{\"units\":\"data\",\"value\":1},\"doc\":null,\"size\":{\"units\":\"screen\",\"value\":10},\"fill_color\":{\"value\":\"red\"},\"line_color\":{\"value\":\"red\"},\"x\":{\"units\":\"data\",\"field\":\"x\"},\"id\":\"14fa8eac-f8f7-4366-c3e5-5f7646066f34\",\"y\":{\"units\":\"data\",\"field\":\"y\"},\"tags\":[]}},{\"id\":\"042700f1-5140-4818-c8ef-4a59310a917a\",\"type\":\"GlyphRenderer\",\"attributes\":{\"name\":null,\"nonselection_glyph\":{\"type\":\"Line\",\"id\":\"14fa8eac-f8f7-4366-c3e5-5f7646066f34\"},\"doc\":null,\"server_data_source\":null,\"data_source\":{\"type\":\"ColumnDataSource\",\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\"},\"glyph\":{\"type\":\"Line\",\"id\":\"7bbe68dd-c0ac-4601-c690-b6a17007e869\"},\"selection_glyph\":null,\"id\":\"042700f1-5140-4818-c8ef-4a59310a917a\",\"tags\":[]}},{\"id\":\"12e6d30f-f429-4fcd-cf96-5bab9578bfcc\",\"type\":\"DataRange1d\",\"attributes\":{\"sources\":[{\"columns\":[\"x\"],\"source\":{\"type\":\"ColumnDataSource\",\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\"}}],\"id\":\"12e6d30f-f429-4fcd-cf96-5bab9578bfcc\",\"tags\":[],\"doc\":null}},{\"id\":\"8d023e15-7372-48e5-c830-3a7001776575\",\"type\":\"DataRange1d\",\"attributes\":{\"sources\":[{\"columns\":[\"y\"],\"source\":{\"type\":\"ColumnDataSource\",\"id\":\"dbe35bdd-f4f1-453e-c5f3-387a765229e8\"}}],\"id\":\"8d023e15-7372-48e5-c830-3a7001776575\",\"tags\":[],\"doc\":null}},{\"id\":\"42c1fb1d-76cd-4619-c6c3-be5473d9c219\",\"type\":\"ToolEvents\",\"attributes\":{\"tags\":[],\"id\":\"42c1fb1d-76cd-4619-c6c3-be5473d9c219\",\"geometries\":[],\"doc\":null}},{\"id\":\"1ce97f20-55b2-42f3-c27d-d8df55e6fe33\",\"type\":\"BasicTickFormatter\",\"attributes\":{\"id\":\"1ce97f20-55b2-42f3-c27d-d8df55e6fe33\",\"tags\":[],\"doc\":null}},{\"id\":\"14a5a30c-4dfe-4108-c11d-c4fe72f427fb\",\"type\":\"BasicTicker\",\"attributes\":{\"num_minor_ticks\":5,\"id\":\"14a5a30c-4dfe-4108-c11d-c4fe72f427fb\",\"tags\":[],\"doc\":null}},{\"id\":\"e59ebcbd-048b-4f35-cf35-b33d0e10ba2f\",\"type\":\"LinearAxis\",\"attributes\":{\"formatter\":{\"type\":\"BasicTickFormatter\",\"id\":\"1ce97f20-55b2-42f3-c27d-d8df55e6fe33\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"14a5a30c-4dfe-4108-c11d-c4fe72f427fb\"},\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"axis_label\":null,\"id\":\"e59ebcbd-048b-4f35-cf35-b33d0e10ba2f\",\"doc\":null,\"tags\":[]}},{\"id\":\"e6d74480-15da-42c7-c2e2-f977a5907f7a\",\"type\":\"Grid\",\"attributes\":{\"dimension\":0,\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"14a5a30c-4dfe-4108-c11d-c4fe72f427fb\"},\"id\":\"e6d74480-15da-42c7-c2e2-f977a5907f7a\",\"doc\":null,\"tags\":[]}},{\"id\":\"dc3f086d-8493-4463-c446-bfa51d91ece3\",\"type\":\"BasicTickFormatter\",\"attributes\":{\"id\":\"dc3f086d-8493-4463-c446-bfa51d91ece3\",\"tags\":[],\"doc\":null}},{\"id\":\"4efe6906-7f6e-4b7a-cbb6-c9581ae09565\",\"type\":\"BasicTicker\",\"attributes\":{\"num_minor_ticks\":5,\"id\":\"4efe6906-7f6e-4b7a-cbb6-c9581ae09565\",\"tags\":[],\"doc\":null}},{\"id\":\"b31786bf-6ee1-49e7-c97e-44a5707a150b\",\"type\":\"LinearAxis\",\"attributes\":{\"formatter\":{\"type\":\"BasicTickFormatter\",\"id\":\"dc3f086d-8493-4463-c446-bfa51d91ece3\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"4efe6906-7f6e-4b7a-cbb6-c9581ae09565\"},\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"axis_label\":null,\"id\":\"b31786bf-6ee1-49e7-c97e-44a5707a150b\",\"doc\":null,\"tags\":[]}},{\"id\":\"d98a3ad8-b633-4d21-cdd0-efbbece20df6\",\"type\":\"Grid\",\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"4efe6906-7f6e-4b7a-cbb6-c9581ae09565\"},\"id\":\"d98a3ad8-b633-4d21-cdd0-efbbece20df6\",\"doc\":null,\"tags\":[]}},{\"id\":\"6489fd83-016d-405e-c085-2bd377825077\",\"type\":\"PanTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"dimensions\":[\"width\",\"height\"],\"id\":\"6489fd83-016d-405e-c085-2bd377825077\",\"doc\":null,\"tags\":[]}},{\"id\":\"9922e825-0443-475d-c72f-8c762696bc10\",\"type\":\"WheelZoomTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"dimensions\":[\"width\",\"height\"],\"id\":\"9922e825-0443-475d-c72f-8c762696bc10\",\"doc\":null,\"tags\":[]}},{\"id\":\"84a6df1f-9e7e-46d3-c6f7-ab19c296731d\",\"type\":\"BoxZoomTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"84a6df1f-9e7e-46d3-c6f7-ab19c296731d\",\"tags\":[],\"doc\":null}},{\"id\":\"769f8b92-aaae-4d8b-cd41-83186b96a017\",\"type\":\"PreviewSaveTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"769f8b92-aaae-4d8b-cd41-83186b96a017\",\"tags\":[],\"doc\":null}},{\"id\":\"1c06e864-2c5f-4804-c80b-f55d23fa588a\",\"type\":\"ResizeTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"1c06e864-2c5f-4804-c80b-f55d23fa588a\",\"tags\":[],\"doc\":null}},{\"id\":\"7fca70fd-9d1c-4648-c6e6-a30ccb24f472\",\"type\":\"ResetTool\",\"attributes\":{\"plot\":{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"7fca70fd-9d1c-4648-c6e6-a30ccb24f472\",\"tags\":[],\"doc\":null}},{\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"type\":\"Plot\",\"attributes\":{\"x_range\":{\"type\":\"DataRange1d\",\"id\":\"12e6d30f-f429-4fcd-cf96-5bab9578bfcc\"},\"tool_events\":{\"type\":\"ToolEvents\",\"id\":\"42c1fb1d-76cd-4619-c6c3-be5473d9c219\"},\"below\":[{\"type\":\"LinearAxis\",\"id\":\"e59ebcbd-048b-4f35-cf35-b33d0e10ba2f\"}],\"renderers\":[{\"type\":\"GlyphRenderer\",\"id\":\"042700f1-5140-4818-c8ef-4a59310a917a\"},{\"type\":\"LinearAxis\",\"id\":\"e59ebcbd-048b-4f35-cf35-b33d0e10ba2f\"},{\"type\":\"Grid\",\"id\":\"e6d74480-15da-42c7-c2e2-f977a5907f7a\"},{\"type\":\"LinearAxis\",\"id\":\"b31786bf-6ee1-49e7-c97e-44a5707a150b\"},{\"type\":\"Grid\",\"id\":\"d98a3ad8-b633-4d21-cdd0-efbbece20df6\"}],\"above\":[],\"tools\":[{\"type\":\"PanTool\",\"id\":\"6489fd83-016d-405e-c085-2bd377825077\"},{\"type\":\"WheelZoomTool\",\"id\":\"9922e825-0443-475d-c72f-8c762696bc10\"},{\"type\":\"BoxZoomTool\",\"id\":\"84a6df1f-9e7e-46d3-c6f7-ab19c296731d\"},{\"type\":\"PreviewSaveTool\",\"id\":\"769f8b92-aaae-4d8b-cd41-83186b96a017\"},{\"type\":\"ResizeTool\",\"id\":\"1c06e864-2c5f-4804-c80b-f55d23fa588a\"},{\"type\":\"ResetTool\",\"id\":\"7fca70fd-9d1c-4648-c6e6-a30ccb24f472\"}],\"doc\":null,\"right\":[],\"title\":\"Plot of loss\",\"extra_x_ranges\":{},\"left\":[{\"type\":\"LinearAxis\",\"id\":\"b31786bf-6ee1-49e7-c97e-44a5707a150b\"}],\"y_range\":{\"type\":\"DataRange1d\",\"id\":\"8d023e15-7372-48e5-c830-3a7001776575\"},\"id\":\"22a0af10-dc51-48d6-c8af-c0428286a515\",\"extra_y_ranges\":{},\"tags\":[]}}];\n",
       "      Bokeh.load_models(all_models);\n",
       "      var model = Bokeh.Collections(modeltype).get(modelid);\n",
       "      $(\"#fab3f2f3-127e-4ce6-cc19-1c6b840c9daf\").html(''); // clear any previous plot in window_id\n",
       "      var view = new model.default_view({model: model, el: \"#fab3f2f3-127e-4ce6-cc19-1c6b840c9daf\"});\n",
       "  });\n",
       "    }\n",
       "});\n",
       "</script>\n",
       "<div class=\"plotdiv\" id=\"fab3f2f3-127e-4ce6-cc19-1c6b840c9daf\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot = require 'itorch.Plot'\n",
    "\n",
    "loss = torch.Tensor(lossfull)\n",
    "rougue = torch.Tensor(rouguef1)\n",
    "indices = torch.linspace(1, loss:size(1), loss:size(1)):long() \n",
    "plot = Plot():line(indices, loss, 'red', 'hi'):title('Plot of loss'):draw()\n",
    "-- plot = Plot():line(indices, rougue, 'blue', 'hi'):title('Plot of Rougue-F1'):draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25\t0.2\t0.22222222222222\t\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rougeScores( Tokenize(trueSummary:resize(40):totable()), \n",
    "                Tokenize(totalPredsummary:totable()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.unpack(true_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 0  1\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n",
       " 1  0\n",
       "[torch.DoubleTensor of size 1x2]\n",
       "\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.unpack(qActions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
