{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'image'\n",
    "require 'optim'\n",
    "require 'parallel'\n",
    "dl = require 'dataload'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Some useful functions\n",
    "function genNbyK(n, k, a, b)\n",
    "    out = torch.LongTensor(n, k)\n",
    "    for i=1, n do\n",
    "        for j = 1, k do\n",
    "            out[i][j] = torch.random(a, b)\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function buildModel(model, vocabSize, embeddingSize, metric, adapt, use_cuda)\n",
    "    -- Small experiments seem to show that the Tanh activations performed better\\\n",
    "    --      than the ReLU for the bow model\n",
    "    if model == 'bow' then\n",
    "        print(string.format(\"Running bag-of-words model to learn %s\", metric))\n",
    "        sentenceLookup = nn.Sequential()\n",
    "                    :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                    :add(nn.Sum(2, 3, true)) -- Not averaging blows up model so keep this true\n",
    "                    :add(nn.Tanh())\n",
    "    else\n",
    "        print(string.format(\"Running LSTM model to learn %s\", metric))\n",
    "        sentenceLookup = nn.Sequential()\n",
    "                    :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                    :add(nn.SplitTable(2))\n",
    "                    :add(nn.Sequencer(nn.LSTM(embeddingSize, embeddingSize)))\n",
    "                    :add(nn.SelectTable(-1))            -- selects last state of the LSTM\n",
    "                    :add(nn.Linear(embeddingSize, embeddingSize))\n",
    "                    :add(nn.ReLU())\n",
    "    end\n",
    "    local queryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\") \n",
    "    local summaryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\")\n",
    "    local pmodule = nn.ParallelTable()\n",
    "                :add(sentenceLookup)\n",
    "                :add(queryLookup)\n",
    "                :add(summaryLookup)\n",
    "\n",
    "    if model == 'bow' then\n",
    "        nnmodel = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(nn.Tanh())\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "    else\n",
    "        nnmodel = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(nn.ReLU())\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "    end\n",
    "\n",
    "    if adapt then \n",
    "        print(\"Adaptive regularization\")\n",
    "        local logmod = nn.Sequential()\n",
    "            :add(nn.Linear(embeddingSize * 3, 1))\n",
    "            :add(nn.LogSigmoid())\n",
    "            :add(nn.SoftMax())\n",
    "\n",
    "        local regmod = nn.Sequential()\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "\n",
    "        local fullmod = nn.ConcatTable()\n",
    "            :add(regmod)\n",
    "            :add(logmod)\n",
    "\n",
    "        local final = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(fullmod)\n",
    "\n",
    "        nnmodel = final\n",
    "    end\n",
    "\n",
    "    if use_cuda then\n",
    "        return nnmodel:cuda()\n",
    "    end\n",
    "    return nnmodel\n",
    "end\n",
    "\n",
    "function Tokenize(inputdic)\n",
    "    --- This function tokenizes the words into a unigram dictionary\n",
    "    local out = {}\n",
    "\n",
    "    for k, v in pairs(inputdic) do\n",
    "        if out[v] == nil then\n",
    "            out[v] = 1\n",
    "        else \n",
    "            out[v] = 1 + out[v]\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function rougeScores(genSummary, refSummary)\n",
    "    local genTotal = 0\n",
    "    local refTotal = 0\n",
    "    local intersection = 0\n",
    "    -- Inserting the missing keys\n",
    "    for k, genCount in pairs(genSummary) do\n",
    "        if refSummary[k] == nil then\n",
    "            refSummary[k] = 0\n",
    "        end\n",
    "    end\n",
    "    for k, refCount in pairs(refSummary) do\n",
    "        local genCount = genSummary[k]\n",
    "        if genCount == nil then \n",
    "            genCount = 0 \n",
    "        end\n",
    "        intersection = intersection + math.min(refCount, genCount)\n",
    "        refTotal = refTotal + refCount\n",
    "        genTotal = genTotal + genCount\n",
    "    end\n",
    "\n",
    "    recall = intersection / refTotal\n",
    "    prec = intersection / genTotal\n",
    "    if refTotal == 0 then\n",
    "        recall = 0\n",
    "    end \n",
    "    if genTotal == 0 then\n",
    "        prec = 0\n",
    "    end\n",
    "    -- tmp = {intersection, refTotal, genTotal}\n",
    "    if recall > 0 or prec > 0 then\n",
    "        f1 = (2 * recall * prec) / (recall + prec)\n",
    "    else \n",
    "        f1 = 0\n",
    "    end\n",
    "    return recall, prec, f1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function buildPredsummary(summary, chosenactions, inputsentences, select_index)\n",
    "    if summary == nil then\n",
    "        summary = torch.zeros(inputsentences:size())\n",
    "    end\n",
    "    for i=1, chosenactions:size(1) do\n",
    "        -- the 2 is for the SELECT index, will have to make this more general later\n",
    "        if chosenactions[i][select_index] == 1 then\n",
    "            summary[i]:copy(inputsentences[i])\n",
    "        end\n",
    "    end    \n",
    "    return summary\n",
    "end\n",
    "\n",
    "function buildPredsummaryFast(summary, chosenactions, inputsentences, select_index)\n",
    "    n = inputsentences:size(1)\n",
    "    k = inputsentences:size(2)\n",
    "    if summary == nil then\n",
    "        summary = torch.zeros(inputsentences:size())\n",
    "    end\n",
    "    actionmatrix = chosenactions:select(2, select_index):clone():resize(n, 1):view(n, 1):expand(n, k):clone()\n",
    "    --     This line didn't work for whatever reason...gives weird indexing...\n",
    "    --     actionmatrix = chosenactions:select(2, select_index):resize(1, n):view(n, 1):expand(n, k):clone()\n",
    "    return actionmatrix:cmul(inputsentences:double())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function buildTotalSummary(predsummary, totalPredsummary)\n",
    "    nps = predsummary:size(1)\n",
    "    n_l = totalPredsummary:size(2)\n",
    "    indices = torch.linspace(1, n_l, n_l):long() \n",
    "    for i=1, predsummary:size(1) do\n",
    "        if predsummary[i]:sum() > 0 then \n",
    "            -- maxindex = 0\n",
    "            -- for j = 1, totalPredsummary[i]:size(1) do \n",
    "            --     if totalPredsummary[i][j] == 0 then\n",
    "            --         maxindex = maxindex + 1\n",
    "            --     end\n",
    "            -- end\n",
    "            -- lenx = predsummary[i]:size(1)\n",
    "            -- totalPredsummary[i][{{maxindex - lenx + 1, maxindex}}]:copy(predsummary[i])\n",
    "\n",
    "            minindex = 1\n",
    "            for j = 1, totalPredsummary[i]:size(1) do \n",
    "                if totalPredsummary[i][j] > 0 then\n",
    "                    minindex = minindex + 1\n",
    "                end\n",
    "            end\n",
    "            lenx = predsummary[i]:size(1)\n",
    "            totalPredsummary[i][{{minindex, minindex + lenx - 1}}]:copy(predsummary[i])\n",
    "\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function buildTotalSummaryFast(predsummary, totalPredsummary)\n",
    "    nps = predsummary:size(1)\n",
    "    n_l = totalPredsummary:size(2)\n",
    "    indices = torch.linspace(1, n_l, n_l):long() \n",
    "    for i=1, predsummary:size(1) do\n",
    "        if predsummary[i]:sum() > 0 then \n",
    "            -- Finding the largest index with a zero\n",
    "            -- maxindex = torch.max(indices[torch.eq(totalPredsummary[i], 0)])\n",
    "            -- totalPredsummary[i][{{maxindex - lenx + 1, maxindex}}]:copy(predsummary[i])\n",
    "            -- Finding the smallest index with a zero\n",
    "            minindex = torch.min(indices[torch.eq(totalPredsummary[i], 0)])\n",
    "            lenx = predsummary[i]:size(1)\n",
    "            totalPredsummary[i][{{minindex, minindex + lenx - 1}}]:copy(predsummary[i])\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Setting parameters\n",
    "n = 10\n",
    "n_s = 5\n",
    "k = 7\n",
    "q = 5\n",
    "a = 1\n",
    "b = 1000\n",
    "embDim = 50\n",
    "gamma = 0.\n",
    "SKIP = 1\n",
    "SELECT = 2\n",
    "epsilon = 1\n",
    "nepochs = 1000\n",
    "fast = true\n",
    "\n",
    "maskLayer = nn.MaskedSelect()\n",
    "optimParams = { learningRate = 0.1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Simulating streams and queries\n",
    "queries = genNbyK(n, q, a, b)\n",
    "\n",
    "-- Note that the sentences are batched by sentence index so sentences[1] is the first sentence of each article\n",
    "sentences = {}\n",
    "for i=1, n_s do\n",
    "    sentences[i] = genNbyK(n, k, a, b)\n",
    "end\n",
    "\n",
    "-- Optimal predicted summary\n",
    "trueSummary = torch.zeros(n, k * n_s)\n",
    "-- Using this to generate the optimal actions\n",
    "true_actions = {}\n",
    "for i=1, n_s do \n",
    "    ---- Simulating the data\n",
    "    trueqValues = torch.rand(n, 2)\n",
    "    \n",
    "     ---- Generating the max values and getting the indices\n",
    "    qMaxtrue, qindxtrue = torch.max(trueqValues, 2)\n",
    "    \n",
    "    --- I want to select the qindx elements for each row\n",
    "    true_actions[i] = torch.zeros(n, 2):scatter(2, qindxtrue, torch.ones(trueqValues:size()))\n",
    "    best_sentences = buildPredsummaryFast(best_sentences, true_actions[i], sentences[i], SELECT)\n",
    "    buildTotalSummaryFast(best_sentences, trueSummary)\n",
    "end\n",
    "\n",
    "qTokens = {}\n",
    "for i=1, n do\n",
    "    qTokens[i] = Tokenize(trueSummary[i]:totable())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the rougue metrics on the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t1\t1\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rougeScores(Tokenize(trueSummary[1]:totable()), Tokenize(trueSummary[1]:totable())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running bag-of-words model to learn f1\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = buildModel('bow', b, embDim, 'f1', false, false)\n",
    "\n",
    "params, gradParams = model:getParameters()\n",
    "criterion = nn.MSECriterion()\n",
    "maskLayer = nn.MaskedSelect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the model on the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalPredsummary = {}\n",
    "qValues = {}\n",
    "qActions = {}\n",
    "qPreds = {}\n",
    "rewards = {}\n",
    "lossfull = {}\n",
    "rouguef1 = {}\n",
    "\n",
    "memsize = n * n_s\n",
    "queryMemory = torch.zeros(memsize, q)\n",
    "qActionMemory = torch.zeros(memsize, 2)\n",
    "predSummaryMemory = torch.zeros(memsize, n_s * k)\n",
    "sentenceMemory = torch.zeros(memsize, k)\n",
    "qPredsMemory = torch.zeros(memsize, 2)\n",
    "qValuesMemory = torch.zeros(memsize, 1)\n",
    "rewardMemory = torch.zeros(memsize, 1)\n",
    "\n",
    "for epoch=1, nepochs do\n",
    "    for i = 1, n_s do\n",
    "        --- Initializing things\n",
    "        if epoch == 1 then \n",
    "            qPreds[i] = torch.zeros(n, 2)\n",
    "            qValues[i] = torch.zeros(n, 1) \n",
    "            qActions[i] = torch.zeros(n, 2)\n",
    "            rewards[i] = torch.zeros(n, 1)\n",
    "            totalPredsummary[i] = torch.LongTensor(n, n_s * k):fill(0)\n",
    "        else\n",
    "            --- Reset things\n",
    "            qPreds[i]:fill(0)\n",
    "            qValues[i]:fill(0)\n",
    "            qActions[i]:fill(0)\n",
    "            rewards[i]:fill(0)\n",
    "            totalPredsummary[i]:fill(0)\n",
    "        end \n",
    "    end\n",
    "    for i=1, n_s do\n",
    "        if torch.uniform(0, 1) <= epsilon then \n",
    "            qPreds[i]:copy(torch.rand(n, 2))\n",
    "            -- Need to run a forward pass for the backward to work...wonky\n",
    "            ignore = model:forward({sentences[i], queries, totalPredsummary[i]})\n",
    "        else \n",
    "            qPreds[i]:copy(model:forward({sentences[i], queries, totalPredsummary[i]}) )\n",
    "        end \n",
    "        if fast then \n",
    "            qMax, qindx = torch.max(qPreds[i], 2)  -- Pulling the best actions\n",
    "            -- Here's the fast way to select the optimal action for each query\n",
    "            qActions[i]:copy(qActions[i]:scatter(2, qindx, torch.ones(qPreds[i]:size())):clone())\n",
    "            qValues[i]:copy(qMax)\n",
    "            predsummary = buildPredsummaryFast(predsummary, qActions[i], sentences[i], SELECT)\n",
    "            buildTotalSummaryFast(predsummary, totalPredsummary[i])\n",
    "        else \n",
    "            for j=1, n do\n",
    "                if qPreds[i][j][SELECT] > qPreds[i][j][SKIP] then\n",
    "                    qActions[i][j][SELECT] = 1\n",
    "                    qValues[i][j]:fill(qPreds[i][j][SELECT])\n",
    "                else\n",
    "                    qActions[i][j][SKIP] = 1\n",
    "                    qValues[i][j]:fill(qPreds[i][j][SKIP])\n",
    "                end\n",
    "            end\n",
    "            predsummary = buildPredsummary(predsummary, qActions[i], sentences[i], SELECT)\n",
    "            buildTotalSummary(predsummary, totalPredsummary[i])\n",
    "        end\n",
    "        for j = 1, n do\n",
    "            recall, prec, f1 = rougeScores( qTokens[j],\n",
    "                                            Tokenize(totalPredsummary[i][j]:totable()))\n",
    "            rewards[i][j]:fill(f1)\n",
    "        end\n",
    "        if i > 1 then\n",
    "            -- Calculating change in rougue f1\n",
    "            rewards[i]:copy(rewards[i] - rewards[i-1])\n",
    "        end\n",
    "        -- Update memory sequentially until it's full \n",
    "        qActionMemory[{{n * (i-1) + 1, n * i}}]:copy(qActions[i])\n",
    "        predSummaryMemory[{{n * (i-1) + 1, n * i}}]:copy(totalPredsummary[i])\n",
    "        sentenceMemory[{{n * (i-1) + 1, n * i}}]:copy(sentences[i])\n",
    "        qPredsMemory[{{n * (i-1) + 1, n * i}}]:copy(qPreds[i])\n",
    "        qValuesMemory[{{n * (i-1) + 1, n * i}}]:copy(qValues[i])\n",
    "        queryMemory[{{n * (i-1) + 1, n * i}}]:copy(queries)\n",
    "        if i  < n_s then\n",
    "            rewardMemory[{{n * (i-1) + 1, n * i}}]:copy(rewards[i] + gamma * rewards[i + 1] )\n",
    "        else\n",
    "            rewardMemory[{{n * (i-1) + 1, n * i}}]:copy(rewards[i] )\n",
    "        end\n",
    "    end\n",
    "    -- Adding back the delta for the last one\n",
    "    rouguef1[epoch] = (rewards[n_s] + rewards[ n_s - 1] ):mean()\n",
    "    -- rouguef1[epoch] = rewards[n_s]:mean()\n",
    "\n",
    "    loss = {}\n",
    "    local dataloader = dl.TensorLoader({queryMemory, sentenceMemory, predSummaryMemory, qPredsMemory, qActionMemory, qValuesMemory}, rewardMemory)\n",
    "    c = 1\n",
    "    for k, xin, reward in dataloader:sampleiter(batch_size, memsize) do\n",
    "        local function feval(params)\n",
    "            gradParams:zero()\n",
    "            if adapt then\n",
    "                local ignore = model:forward({xin[1], xin[2], xin[3]})\n",
    "                local predQOnActions = maskLayer:forward({qPredsMemory, actions_in}) \n",
    "                local ones = torch.ones(predQ:size(1)):resize(predQ:size(1))\n",
    "                lossf = criterion:forward({qValuesMemory, predReg}, {reward, ones})\n",
    "                local gradOutput = criterion:backward({qActionMemory, predReg}, {reward, ones})\n",
    "                local gradMaskLayer = maskLayer:backward({qPredsMemory, qActionMemory}, gradOutput[1])\n",
    "                model:backward({queryMemory, sentenceMemory, predSummaryMemory}, {gradMaskLayer[1], gradOutput[2]})\n",
    "            else \n",
    "                local ignore = model:forward({xin[1], xin[2], xin[3]})\n",
    "                local predQOnActions = maskLayer:forward({xin[4], xin[5]:byte()}) \n",
    "                lossf = criterion:forward(predQOnActions, reward)\n",
    "                local gradOutput = criterion:backward(predQOnActions, reward)\n",
    "                local gradMaskLayer = maskLayer:backward({xin[4], xin[5]:byte()}, gradOutput)\n",
    "                model:backward({xin[1], xin[2], xin[3]}, gradMaskLayer[1])\n",
    "            end \n",
    "            return lossf, gradParams\n",
    "        end\n",
    "        --- optim.rmsprop returns \\theta, f(\\theta):= loss function\n",
    "         _, lossv  = optim.rmsprop(feval, params, optimParams)\n",
    "        loss[c] = lossv[1]\n",
    "        c = c + 1\n",
    "    end\n",
    "\n",
    "    lossfull[epoch] = torch.Tensor(loss):sum() / #lossv\n",
    "    if print_perf then\n",
    "        print(\n",
    "            string.format('epoch = %i; rougue = %.6f; epsilon = %.6f; loss = %.6f' , \n",
    "                epoch, rouguef1[epoch], epsilon, lossfull[epoch])\n",
    "            )\n",
    "    end\n",
    "    epsilon = epsilon - (1/10.)\n",
    "    if epsilon < 0 then\n",
    "        epsilon = 0\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Plot = require 'itorch.Plot'\n",
    "\n",
    "loss = torch.Tensor(lossfull)\n",
    "rougue = torch.Tensor(rouguef1)\n",
    "indices = torch.linspace(1, loss:size(1), loss:size(1)):long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "$(function() {\n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\"){\n",
       "  window._bokeh_onload_callbacks = [];\n",
       "    }\n",
       "    function load_lib(url, callback){\n",
       "  window._bokeh_onload_callbacks.push(callback);\n",
       "  if (window._bokeh_is_loading){\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", new Date());\n",
       "      return null;\n",
       "  }\n",
       "  console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", new Date());\n",
       "  window._bokeh_is_loading = true;\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = function(){\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh-0.7.0.min.css\");\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback){callback()});\n",
       "  };\n",
       "  s.onerror = function(){\n",
       "      console.warn(\"failed to load library \" + url);\n",
       "  };\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "\n",
       "    bokehjs_url = \"https://cdn.pydata.org/bokeh-0.7.0.min.js\"\n",
       "\n",
       "    var elt = document.getElementById(\"7c1c3b2b-9737-4c82-cc53-e49f48d9a50e\");\n",
       "    if(elt==null) {\n",
       "  console.log(\"Bokeh: ERROR: autoload.js configured with elementid '7c1c3b2b-9737-4c82-cc53-e49f48d9a50e'\"\n",
       "        + \"but no matching script tag was found. \")\n",
       "  return false;\n",
       "    }\n",
       "\n",
       "    if(typeof(Bokeh) !== \"undefined\") {\n",
       "  console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "  var modelid = \"c2b03050-7182-4818-c81f-517947bf8a35\";\n",
       "  var modeltype = \"Plot\";\n",
       "  var all_models = [{\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\",\"type\":\"ColumnDataSource\",\"attributes\":{\"data\":{\"y\":[0.64,0.58,0.6,0.58,0.62,0.64,0.56,0.62,0.64,0.6,0.6,0.6,0.6,0.6,0.6,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.6,0.58,0.58,0.58,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.6,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.58,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.58,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.58,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000]},\"column_names\":[\"y\",\"x\"],\"cont_ranges\":{},\"discrete_ranges\":{},\"selected\":[],\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\",\"doc\":null,\"tags\":[]}},{\"id\":\"d8f84276-0c60-46a2-c679-e3d3417d7849\",\"type\":\"Line\",\"attributes\":{\"fill_alpha\":{\"units\":\"data\",\"value\":0.2},\"line_alpha\":{\"units\":\"data\",\"value\":1},\"doc\":null,\"size\":{\"units\":\"screen\",\"value\":10},\"fill_color\":{\"value\":\"blue\"},\"line_color\":{\"value\":\"blue\"},\"x\":{\"units\":\"data\",\"field\":\"x\"},\"id\":\"d8f84276-0c60-46a2-c679-e3d3417d7849\",\"y\":{\"units\":\"data\",\"field\":\"y\"},\"tags\":[]}},{\"id\":\"78b1c040-27e8-48fc-c89a-a00850c8fc2e\",\"type\":\"Line\",\"attributes\":{\"fill_alpha\":{\"units\":\"data\",\"value\":0.2},\"line_alpha\":{\"units\":\"data\",\"value\":1},\"doc\":null,\"size\":{\"units\":\"screen\",\"value\":10},\"fill_color\":{\"value\":\"blue\"},\"line_color\":{\"value\":\"blue\"},\"x\":{\"units\":\"data\",\"field\":\"x\"},\"id\":\"78b1c040-27e8-48fc-c89a-a00850c8fc2e\",\"y\":{\"units\":\"data\",\"field\":\"y\"},\"tags\":[]}},{\"id\":\"58a0b646-0879-4622-c6ba-6be7f1680868\",\"type\":\"GlyphRenderer\",\"attributes\":{\"name\":null,\"nonselection_glyph\":{\"type\":\"Line\",\"id\":\"78b1c040-27e8-48fc-c89a-a00850c8fc2e\"},\"doc\":null,\"server_data_source\":null,\"data_source\":{\"type\":\"ColumnDataSource\",\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\"},\"glyph\":{\"type\":\"Line\",\"id\":\"d8f84276-0c60-46a2-c679-e3d3417d7849\"},\"selection_glyph\":null,\"id\":\"58a0b646-0879-4622-c6ba-6be7f1680868\",\"tags\":[]}},{\"id\":\"90cd3bab-7862-4102-c12a-1a4193098f73\",\"type\":\"DataRange1d\",\"attributes\":{\"sources\":[{\"columns\":[\"x\"],\"source\":{\"type\":\"ColumnDataSource\",\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\"}}],\"id\":\"90cd3bab-7862-4102-c12a-1a4193098f73\",\"tags\":[],\"doc\":null}},{\"id\":\"7d2b0a47-170c-4ac1-ca4a-6685398c9c2b\",\"type\":\"DataRange1d\",\"attributes\":{\"sources\":[{\"columns\":[\"y\"],\"source\":{\"type\":\"ColumnDataSource\",\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\"}}],\"id\":\"7d2b0a47-170c-4ac1-ca4a-6685398c9c2b\",\"tags\":[],\"doc\":null}},{\"id\":\"79655b13-5385-4dc0-cd9f-9c4590daca1a\",\"type\":\"ToolEvents\",\"attributes\":{\"tags\":[],\"id\":\"79655b13-5385-4dc0-cd9f-9c4590daca1a\",\"geometries\":[],\"doc\":null}},{\"id\":\"49639db4-a51b-49a2-c935-bff03b70d736\",\"type\":\"BasicTickFormatter\",\"attributes\":{\"id\":\"49639db4-a51b-49a2-c935-bff03b70d736\",\"tags\":[],\"doc\":null}},{\"id\":\"ae0cac3b-e2e6-4604-c6ee-599419a12508\",\"type\":\"BasicTicker\",\"attributes\":{\"num_minor_ticks\":5,\"id\":\"ae0cac3b-e2e6-4604-c6ee-599419a12508\",\"tags\":[],\"doc\":null}},{\"id\":\"68582311-abde-4789-c715-78a4d0c0d2cc\",\"type\":\"LinearAxis\",\"attributes\":{\"formatter\":{\"type\":\"BasicTickFormatter\",\"id\":\"49639db4-a51b-49a2-c935-bff03b70d736\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"ae0cac3b-e2e6-4604-c6ee-599419a12508\"},\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"axis_label\":null,\"id\":\"68582311-abde-4789-c715-78a4d0c0d2cc\",\"doc\":null,\"tags\":[]}},{\"id\":\"54fb40ed-43a2-470e-c73d-0ef9f3665fbd\",\"type\":\"Grid\",\"attributes\":{\"dimension\":0,\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"ae0cac3b-e2e6-4604-c6ee-599419a12508\"},\"id\":\"54fb40ed-43a2-470e-c73d-0ef9f3665fbd\",\"doc\":null,\"tags\":[]}},{\"id\":\"238a02b3-e1bd-462f-c61c-130de7b273f2\",\"type\":\"BasicTickFormatter\",\"attributes\":{\"id\":\"238a02b3-e1bd-462f-c61c-130de7b273f2\",\"tags\":[],\"doc\":null}},{\"id\":\"1f4bd097-4ffe-4fdd-cf4e-0f2c2a6b99f4\",\"type\":\"BasicTicker\",\"attributes\":{\"num_minor_ticks\":5,\"id\":\"1f4bd097-4ffe-4fdd-cf4e-0f2c2a6b99f4\",\"tags\":[],\"doc\":null}},{\"id\":\"1f07709c-9180-46ad-c656-0a5c28549279\",\"type\":\"LinearAxis\",\"attributes\":{\"formatter\":{\"type\":\"BasicTickFormatter\",\"id\":\"238a02b3-e1bd-462f-c61c-130de7b273f2\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"1f4bd097-4ffe-4fdd-cf4e-0f2c2a6b99f4\"},\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"axis_label\":null,\"id\":\"1f07709c-9180-46ad-c656-0a5c28549279\",\"doc\":null,\"tags\":[]}},{\"id\":\"c9ad566e-7db4-47e1-c7e4-45f268caa4b7\",\"type\":\"Grid\",\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"1f4bd097-4ffe-4fdd-cf4e-0f2c2a6b99f4\"},\"id\":\"c9ad566e-7db4-47e1-c7e4-45f268caa4b7\",\"doc\":null,\"tags\":[]}},{\"id\":\"726d9651-26a7-4dbc-cde2-0196622ddb44\",\"type\":\"PanTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"dimensions\":[\"width\",\"height\"],\"id\":\"726d9651-26a7-4dbc-cde2-0196622ddb44\",\"doc\":null,\"tags\":[]}},{\"id\":\"86917684-608d-4f6b-cff3-146a5c5197c7\",\"type\":\"WheelZoomTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"dimensions\":[\"width\",\"height\"],\"id\":\"86917684-608d-4f6b-cff3-146a5c5197c7\",\"doc\":null,\"tags\":[]}},{\"id\":\"c63eef67-c46d-48fa-c885-6d2dba752924\",\"type\":\"BoxZoomTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"c63eef67-c46d-48fa-c885-6d2dba752924\",\"tags\":[],\"doc\":null}},{\"id\":\"fa53e8bb-63ea-4b35-cbbb-060d9521a3d0\",\"type\":\"PreviewSaveTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"fa53e8bb-63ea-4b35-cbbb-060d9521a3d0\",\"tags\":[],\"doc\":null}},{\"id\":\"26b910f7-7142-4da8-cdf7-b9d847846dc8\",\"type\":\"ResizeTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"26b910f7-7142-4da8-cdf7-b9d847846dc8\",\"tags\":[],\"doc\":null}},{\"id\":\"7e53a95b-08ef-4339-c32e-16902ef9f67f\",\"type\":\"ResetTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"7e53a95b-08ef-4339-c32e-16902ef9f67f\",\"tags\":[],\"doc\":null}},{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"attributes\":{\"x_range\":{\"type\":\"DataRange1d\",\"id\":\"90cd3bab-7862-4102-c12a-1a4193098f73\"},\"tool_events\":{\"type\":\"ToolEvents\",\"id\":\"79655b13-5385-4dc0-cd9f-9c4590daca1a\"},\"below\":[{\"type\":\"LinearAxis\",\"id\":\"68582311-abde-4789-c715-78a4d0c0d2cc\"}],\"renderers\":[{\"type\":\"GlyphRenderer\",\"id\":\"58a0b646-0879-4622-c6ba-6be7f1680868\"},{\"type\":\"LinearAxis\",\"id\":\"68582311-abde-4789-c715-78a4d0c0d2cc\"},{\"type\":\"Grid\",\"id\":\"54fb40ed-43a2-470e-c73d-0ef9f3665fbd\"},{\"type\":\"LinearAxis\",\"id\":\"1f07709c-9180-46ad-c656-0a5c28549279\"},{\"type\":\"Grid\",\"id\":\"c9ad566e-7db4-47e1-c7e4-45f268caa4b7\"}],\"above\":[],\"tools\":[{\"type\":\"PanTool\",\"id\":\"726d9651-26a7-4dbc-cde2-0196622ddb44\"},{\"type\":\"WheelZoomTool\",\"id\":\"86917684-608d-4f6b-cff3-146a5c5197c7\"},{\"type\":\"BoxZoomTool\",\"id\":\"c63eef67-c46d-48fa-c885-6d2dba752924\"},{\"type\":\"PreviewSaveTool\",\"id\":\"fa53e8bb-63ea-4b35-cbbb-060d9521a3d0\"},{\"type\":\"ResizeTool\",\"id\":\"26b910f7-7142-4da8-cdf7-b9d847846dc8\"},{\"type\":\"ResetTool\",\"id\":\"7e53a95b-08ef-4339-c32e-16902ef9f67f\"}],\"doc\":null,\"right\":[],\"title\":\"Plot of Rougue-F1\",\"extra_x_ranges\":{},\"left\":[{\"type\":\"LinearAxis\",\"id\":\"1f07709c-9180-46ad-c656-0a5c28549279\"}],\"y_range\":{\"type\":\"DataRange1d\",\"id\":\"7d2b0a47-170c-4ac1-ca4a-6685398c9c2b\"},\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"extra_y_ranges\":{},\"tags\":[]}}];\n",
       "  Bokeh.load_models(all_models);\n",
       "  var model = Bokeh.Collections(modeltype).get(modelid);\n",
       "  $(\"#7c1c3b2b-9737-4c82-cc53-e49f48d9a50e\").html(''); // clear any previous plot in window_id\n",
       "  var view = new model.default_view({model: model, el: \"#7c1c3b2b-9737-4c82-cc53-e49f48d9a50e\"});\n",
       "    } else {\n",
       "  load_lib(bokehjs_url, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", new Date())\n",
       "      var modelid = \"c2b03050-7182-4818-c81f-517947bf8a35\";\n",
       "      var modeltype = \"Plot\";\n",
       "      var all_models = [{\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\",\"type\":\"ColumnDataSource\",\"attributes\":{\"data\":{\"y\":[0.64,0.58,0.6,0.58,0.62,0.64,0.56,0.62,0.64,0.6,0.6,0.6,0.6,0.6,0.6,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.6,0.58,0.58,0.58,0.62,0.62,0.62,0.62,0.62,0.62,0.62,0.6,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.58,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.56,0.58,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.58,0.58,0.58,0.56,0.56,0.58,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56],\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000]},\"column_names\":[\"y\",\"x\"],\"cont_ranges\":{},\"discrete_ranges\":{},\"selected\":[],\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\",\"doc\":null,\"tags\":[]}},{\"id\":\"d8f84276-0c60-46a2-c679-e3d3417d7849\",\"type\":\"Line\",\"attributes\":{\"fill_alpha\":{\"units\":\"data\",\"value\":0.2},\"line_alpha\":{\"units\":\"data\",\"value\":1},\"doc\":null,\"size\":{\"units\":\"screen\",\"value\":10},\"fill_color\":{\"value\":\"blue\"},\"line_color\":{\"value\":\"blue\"},\"x\":{\"units\":\"data\",\"field\":\"x\"},\"id\":\"d8f84276-0c60-46a2-c679-e3d3417d7849\",\"y\":{\"units\":\"data\",\"field\":\"y\"},\"tags\":[]}},{\"id\":\"78b1c040-27e8-48fc-c89a-a00850c8fc2e\",\"type\":\"Line\",\"attributes\":{\"fill_alpha\":{\"units\":\"data\",\"value\":0.2},\"line_alpha\":{\"units\":\"data\",\"value\":1},\"doc\":null,\"size\":{\"units\":\"screen\",\"value\":10},\"fill_color\":{\"value\":\"blue\"},\"line_color\":{\"value\":\"blue\"},\"x\":{\"units\":\"data\",\"field\":\"x\"},\"id\":\"78b1c040-27e8-48fc-c89a-a00850c8fc2e\",\"y\":{\"units\":\"data\",\"field\":\"y\"},\"tags\":[]}},{\"id\":\"58a0b646-0879-4622-c6ba-6be7f1680868\",\"type\":\"GlyphRenderer\",\"attributes\":{\"name\":null,\"nonselection_glyph\":{\"type\":\"Line\",\"id\":\"78b1c040-27e8-48fc-c89a-a00850c8fc2e\"},\"doc\":null,\"server_data_source\":null,\"data_source\":{\"type\":\"ColumnDataSource\",\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\"},\"glyph\":{\"type\":\"Line\",\"id\":\"d8f84276-0c60-46a2-c679-e3d3417d7849\"},\"selection_glyph\":null,\"id\":\"58a0b646-0879-4622-c6ba-6be7f1680868\",\"tags\":[]}},{\"id\":\"90cd3bab-7862-4102-c12a-1a4193098f73\",\"type\":\"DataRange1d\",\"attributes\":{\"sources\":[{\"columns\":[\"x\"],\"source\":{\"type\":\"ColumnDataSource\",\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\"}}],\"id\":\"90cd3bab-7862-4102-c12a-1a4193098f73\",\"tags\":[],\"doc\":null}},{\"id\":\"7d2b0a47-170c-4ac1-ca4a-6685398c9c2b\",\"type\":\"DataRange1d\",\"attributes\":{\"sources\":[{\"columns\":[\"y\"],\"source\":{\"type\":\"ColumnDataSource\",\"id\":\"70af5f75-a406-4cb3-ccd2-c2d320ffe43a\"}}],\"id\":\"7d2b0a47-170c-4ac1-ca4a-6685398c9c2b\",\"tags\":[],\"doc\":null}},{\"id\":\"79655b13-5385-4dc0-cd9f-9c4590daca1a\",\"type\":\"ToolEvents\",\"attributes\":{\"tags\":[],\"id\":\"79655b13-5385-4dc0-cd9f-9c4590daca1a\",\"geometries\":[],\"doc\":null}},{\"id\":\"49639db4-a51b-49a2-c935-bff03b70d736\",\"type\":\"BasicTickFormatter\",\"attributes\":{\"id\":\"49639db4-a51b-49a2-c935-bff03b70d736\",\"tags\":[],\"doc\":null}},{\"id\":\"ae0cac3b-e2e6-4604-c6ee-599419a12508\",\"type\":\"BasicTicker\",\"attributes\":{\"num_minor_ticks\":5,\"id\":\"ae0cac3b-e2e6-4604-c6ee-599419a12508\",\"tags\":[],\"doc\":null}},{\"id\":\"68582311-abde-4789-c715-78a4d0c0d2cc\",\"type\":\"LinearAxis\",\"attributes\":{\"formatter\":{\"type\":\"BasicTickFormatter\",\"id\":\"49639db4-a51b-49a2-c935-bff03b70d736\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"ae0cac3b-e2e6-4604-c6ee-599419a12508\"},\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"axis_label\":null,\"id\":\"68582311-abde-4789-c715-78a4d0c0d2cc\",\"doc\":null,\"tags\":[]}},{\"id\":\"54fb40ed-43a2-470e-c73d-0ef9f3665fbd\",\"type\":\"Grid\",\"attributes\":{\"dimension\":0,\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"ae0cac3b-e2e6-4604-c6ee-599419a12508\"},\"id\":\"54fb40ed-43a2-470e-c73d-0ef9f3665fbd\",\"doc\":null,\"tags\":[]}},{\"id\":\"238a02b3-e1bd-462f-c61c-130de7b273f2\",\"type\":\"BasicTickFormatter\",\"attributes\":{\"id\":\"238a02b3-e1bd-462f-c61c-130de7b273f2\",\"tags\":[],\"doc\":null}},{\"id\":\"1f4bd097-4ffe-4fdd-cf4e-0f2c2a6b99f4\",\"type\":\"BasicTicker\",\"attributes\":{\"num_minor_ticks\":5,\"id\":\"1f4bd097-4ffe-4fdd-cf4e-0f2c2a6b99f4\",\"tags\":[],\"doc\":null}},{\"id\":\"1f07709c-9180-46ad-c656-0a5c28549279\",\"type\":\"LinearAxis\",\"attributes\":{\"formatter\":{\"type\":\"BasicTickFormatter\",\"id\":\"238a02b3-e1bd-462f-c61c-130de7b273f2\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"1f4bd097-4ffe-4fdd-cf4e-0f2c2a6b99f4\"},\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"axis_label\":null,\"id\":\"1f07709c-9180-46ad-c656-0a5c28549279\",\"doc\":null,\"tags\":[]}},{\"id\":\"c9ad566e-7db4-47e1-c7e4-45f268caa4b7\",\"type\":\"Grid\",\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"ticker\":{\"type\":\"BasicTicker\",\"id\":\"1f4bd097-4ffe-4fdd-cf4e-0f2c2a6b99f4\"},\"id\":\"c9ad566e-7db4-47e1-c7e4-45f268caa4b7\",\"doc\":null,\"tags\":[]}},{\"id\":\"726d9651-26a7-4dbc-cde2-0196622ddb44\",\"type\":\"PanTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"dimensions\":[\"width\",\"height\"],\"id\":\"726d9651-26a7-4dbc-cde2-0196622ddb44\",\"doc\":null,\"tags\":[]}},{\"id\":\"86917684-608d-4f6b-cff3-146a5c5197c7\",\"type\":\"WheelZoomTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"dimensions\":[\"width\",\"height\"],\"id\":\"86917684-608d-4f6b-cff3-146a5c5197c7\",\"doc\":null,\"tags\":[]}},{\"id\":\"c63eef67-c46d-48fa-c885-6d2dba752924\",\"type\":\"BoxZoomTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"c63eef67-c46d-48fa-c885-6d2dba752924\",\"tags\":[],\"doc\":null}},{\"id\":\"fa53e8bb-63ea-4b35-cbbb-060d9521a3d0\",\"type\":\"PreviewSaveTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"fa53e8bb-63ea-4b35-cbbb-060d9521a3d0\",\"tags\":[],\"doc\":null}},{\"id\":\"26b910f7-7142-4da8-cdf7-b9d847846dc8\",\"type\":\"ResizeTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"26b910f7-7142-4da8-cdf7-b9d847846dc8\",\"tags\":[],\"doc\":null}},{\"id\":\"7e53a95b-08ef-4339-c32e-16902ef9f67f\",\"type\":\"ResetTool\",\"attributes\":{\"plot\":{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"subtype\":\"Figure\"},\"id\":\"7e53a95b-08ef-4339-c32e-16902ef9f67f\",\"tags\":[],\"doc\":null}},{\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"type\":\"Plot\",\"attributes\":{\"x_range\":{\"type\":\"DataRange1d\",\"id\":\"90cd3bab-7862-4102-c12a-1a4193098f73\"},\"tool_events\":{\"type\":\"ToolEvents\",\"id\":\"79655b13-5385-4dc0-cd9f-9c4590daca1a\"},\"below\":[{\"type\":\"LinearAxis\",\"id\":\"68582311-abde-4789-c715-78a4d0c0d2cc\"}],\"renderers\":[{\"type\":\"GlyphRenderer\",\"id\":\"58a0b646-0879-4622-c6ba-6be7f1680868\"},{\"type\":\"LinearAxis\",\"id\":\"68582311-abde-4789-c715-78a4d0c0d2cc\"},{\"type\":\"Grid\",\"id\":\"54fb40ed-43a2-470e-c73d-0ef9f3665fbd\"},{\"type\":\"LinearAxis\",\"id\":\"1f07709c-9180-46ad-c656-0a5c28549279\"},{\"type\":\"Grid\",\"id\":\"c9ad566e-7db4-47e1-c7e4-45f268caa4b7\"}],\"above\":[],\"tools\":[{\"type\":\"PanTool\",\"id\":\"726d9651-26a7-4dbc-cde2-0196622ddb44\"},{\"type\":\"WheelZoomTool\",\"id\":\"86917684-608d-4f6b-cff3-146a5c5197c7\"},{\"type\":\"BoxZoomTool\",\"id\":\"c63eef67-c46d-48fa-c885-6d2dba752924\"},{\"type\":\"PreviewSaveTool\",\"id\":\"fa53e8bb-63ea-4b35-cbbb-060d9521a3d0\"},{\"type\":\"ResizeTool\",\"id\":\"26b910f7-7142-4da8-cdf7-b9d847846dc8\"},{\"type\":\"ResetTool\",\"id\":\"7e53a95b-08ef-4339-c32e-16902ef9f67f\"}],\"doc\":null,\"right\":[],\"title\":\"Plot of Rougue-F1\",\"extra_x_ranges\":{},\"left\":[{\"type\":\"LinearAxis\",\"id\":\"1f07709c-9180-46ad-c656-0a5c28549279\"}],\"y_range\":{\"type\":\"DataRange1d\",\"id\":\"7d2b0a47-170c-4ac1-ca4a-6685398c9c2b\"},\"id\":\"c2b03050-7182-4818-c81f-517947bf8a35\",\"extra_y_ranges\":{},\"tags\":[]}}];\n",
       "      Bokeh.load_models(all_models);\n",
       "      var model = Bokeh.Collections(modeltype).get(modelid);\n",
       "      $(\"#7c1c3b2b-9737-4c82-cc53-e49f48d9a50e\").html(''); // clear any previous plot in window_id\n",
       "      var view = new model.default_view({model: model, el: \"#7c1c3b2b-9737-4c82-cc53-e49f48d9a50e\"});\n",
       "  });\n",
       "    }\n",
       "});\n",
       "</script>\n",
       "<div class=\"plotdiv\" id=\"7c1c3b2b-9737-4c82-cc53-e49f48d9a50e\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- plot = Plot():line(indices, loss, 'red', 'hi'):title('Plot of loss'):draw()\n",
    "plot = Plot():line(indices, rougue, 'blue', 'hi'):title('Plot of Rougue-F1'):draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
