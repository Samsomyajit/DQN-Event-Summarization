{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Some useful functions\n",
    "function genNbyK(n, k, a, b)\n",
    "    out = torch.LongTensor(n, k)\n",
    "    for i=1, n do\n",
    "        for j = 1, k do\n",
    "            out[i][j] = torch.random(a, b)\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function buildModel(model, vocabSize, embeddingSize, metric, adapt, use_cuda)\n",
    "    -- Small experiments seem to show that the Tanh activations performed better\\\n",
    "    --      than the ReLU for the bow model\n",
    "    if model == 'bow' then\n",
    "        print(string.format(\"Running bag-of-words model to learn %s\", metric))\n",
    "        sentenceLookup = nn.Sequential()\n",
    "                    :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                    :add(nn.Sum(2, 3, true)) -- Not averaging blows up model so keep this true\n",
    "                    :add(nn.Tanh())\n",
    "    else\n",
    "        print(string.format(\"Running LSTM model to learn %s\", metric))\n",
    "        sentenceLookup = nn.Sequential()\n",
    "                    :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                    :add(nn.SplitTable(2))\n",
    "                    :add(nn.Sequencer(nn.LSTM(embeddingSize, embeddingSize)))\n",
    "                    :add(nn.SelectTable(-1))            -- selects last state of the LSTM\n",
    "                    :add(nn.Linear(embeddingSize, embeddingSize))\n",
    "                    :add(nn.ReLU())\n",
    "    end\n",
    "    local queryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\") \n",
    "    local summaryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\")\n",
    "    local pmodule = nn.ParallelTable()\n",
    "                :add(sentenceLookup)\n",
    "                :add(queryLookup)\n",
    "                :add(summaryLookup)\n",
    "\n",
    "    if model == 'bow' then\n",
    "        nnmodel = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(nn.Tanh())\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "    else\n",
    "        nnmodel = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(nn.ReLU())\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "    end\n",
    "\n",
    "    if adapt then \n",
    "        print(\"Adaptive regularization\")\n",
    "        local logmod = nn.Sequential()\n",
    "            :add(nn.Linear(embeddingSize * 3, 1))\n",
    "            :add(nn.LogSigmoid())\n",
    "            :add(nn.SoftMax())\n",
    "\n",
    "        local regmod = nn.Sequential()\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "\n",
    "        local fullmod = nn.ConcatTable()\n",
    "            :add(regmod)\n",
    "            :add(logmod)\n",
    "\n",
    "        local final = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(fullmod)\n",
    "\n",
    "        nnmodel = final\n",
    "    end\n",
    "\n",
    "    if use_cuda then\n",
    "        return nnmodel:cuda()\n",
    "    end\n",
    "    return nnmodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Setting parameters\n",
    "n = 10\n",
    "n_s = 5\n",
    "k = 7\n",
    "q = 5\n",
    "a = 1\n",
    "b = 100\n",
    "embDim = 50\n",
    "SELECT = 2\n",
    "SKIP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Simulating streams and queries\n",
    "queries = genNbyK(n, q, a, b)\n",
    "\n",
    "-- Note that the sentences are batched by sentence index so sentences[1] is the first sentence of each article\n",
    "sentences = {}\n",
    "for i=1, n_s do\n",
    "    sentences[i] = genNbyK(n, k, a, b)\n",
    "end\n",
    "\n",
    "-- Using this to generate the optimal actions\n",
    "true_actions = {}\n",
    "for i=1, n_s do \n",
    "    ---- Simulating the data\n",
    "    trueqValues = torch.rand(n, 2)                   \n",
    "     ---- Generating the max values and getting the indices\n",
    "    qMaxtrue, qindxtrue = torch.max(trueqValues, 2) \n",
    "    --- I want to select the qindx elements for each row\n",
    "    true_actions[i] = torch.zeros(n, 2):scatter(2, qindxtrue, torch.ones(trueqValues:size()))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function stackMemory(newinput, memory_hist, memsize, adapt, use_cuda)\n",
    "    local sentMemory = torch.cat(newinput[1][1]:double(), memory_hist[1][1]:double(), 1)\n",
    "    local queryMemory = torch.cat(newinput[1][2]:double(), memory_hist[1][2]:double(), 1)\n",
    "    local sumryMemory = torch.cat(newinput[1][3]:double(), memory_hist[1][3]:double(), 1)\n",
    "    local rewardMemory = torch.cat(newinput[2]:double(), memory_hist[2]:double(), 1)\n",
    "\n",
    "    if adapt then\n",
    "        regMemory = torch.cat(newinput[4]:double(), memory_hist[4]:double(), 1)\n",
    "    end \n",
    "\n",
    "    if use_cuda then \n",
    "        actionMemory = torch.cat(newinput[3]:double(), memory_hist[3]:double(), 1)\n",
    "    else \n",
    "        actionMemory = torch.cat(newinput[3], memory_hist[3], 1)\n",
    "    end\n",
    "    --- specifying rows to index \n",
    "    if sentMemory:size(1) <= memsize then\n",
    "        nend = sentMemory:size(1)\n",
    "        nstart = 1\n",
    "    else \n",
    "        nstart = math.max(memsize - sentMemory:size(1), 1)\n",
    "        nend = memsize + nstart\n",
    "    end\n",
    "    --- Selecting n last data points\n",
    "    sentMemory = sentMemory[{{nstart, nend}}]\n",
    "    queryMemory = queryMemory[{{nstart, nend}}]\n",
    "    sumryMemory = sumryMemory[{{nstart, nend}}]\n",
    "    rewardMemory = rewardMemory[{{nstart, nend}}]\n",
    "    actionMemory = actionMemory[{{nstart, nend}}]\n",
    "\n",
    "    if use_cuda then\n",
    "        inputMemory = {sentMemory:cuda(), queryMemory:cuda(), sumryMemory:cuda()}\n",
    "        rewardMemory = rewardMemory:cuda()\n",
    "        actionMemory = torch.ByteTensor(#actionMemory):copy(actionMemory):cuda()\n",
    "    end\n",
    "\n",
    "    inputMemory = {sentMemory, queryMemory, sumryMemory}\n",
    "    if adapt then\n",
    "        regMemory = regMemory[{{nstart, nend}}]\n",
    "        return {inputMemory, rewardMemory, actionMemory, regMemory}\n",
    "    end \n",
    "    return {inputMemory, rewardMemory, actionMemory}\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "querySize = queries:size(2)\n",
    "streamSize = sentences[1]:size(2)\n",
    "-- summaryBatch = summaryBuffer:narrow(1, 1, streamSize)\n",
    "-- queryBatch = queries:view(1, querySize):expand(streamSize, querySize) \n",
    "-- input = {sentenceStream, queryBatch, summaryBatch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running bag-of-words model to learn f1\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = buildModel('bow', b, embDim, 'f1', false, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0133  0.3126\n",
       " 0.0867  0.2945\n",
       "-0.0580  0.0579\n",
       " 0.2729  0.0461\n",
       "-0.1056 -0.1760\n",
       "-0.1638 -0.1753\n",
       " 0.1614 -0.3803\n",
       " 0.0252 -0.0558\n",
       " 0.0155 -0.5019\n",
       " 0.1707 -0.0464\n",
       "[torch.DoubleTensor of size 10x2]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model:forward({sentences[1], queries, torch.zeros(n, q)})\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qMax, qindx = torch.max(preds, 2)\n",
    "actions = torch.zeros(n, 2):scatter(2, qindx, torch.ones(preds:size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsummary = torch.zeros(sentences[1]:size())\n",
    "for i=1, actions:size(1) do\n",
    "    if actions[i][2]==1 then\n",
    "        predsummary[i]:copy(sentences[1][i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = torch.linspace(1, actions:size(1), actions:size(1) ):long()\n",
    "selected = indices[actions:select(2,1):eq(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : 4\n",
       "  2 : 5\n",
       "  3 : 6\n",
       "  4 : 7\n",
       "  5 : 8\n",
       "  6 : 9\n",
       "  7 : 10\n",
       "}\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.totable(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsummary = torch.zeros(sentences[1]:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  62   34   41    8   13    4    3\n",
       "  36   69   64   82   25   77   39\n",
       "  15   74   19   54   10   22   91\n",
       "  36   99    5   50   56   31   79\n",
       "  88   75   79  100    5   31   10\n",
       "  55   33   43   50   70   32   20\n",
       "  22   67   31   21   50   14   46\n",
       "[torch.DoubleTensor of size 7x7]\n",
       "\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]:index(1, torch.LongTensor(selected)):double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- predsummary:scatter(1, torch.LongTensor(selected), sentences[1]:double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  62   34   41    8   13    4    3\n",
       "  36   69   64   82   25   77   39\n",
       "  15   74   19   54   10   22   91\n",
       "  36   99    5   50   56   31   79\n",
       "  88   75   79  100    5   31   10\n",
       "  55   33   43   50   70   32   20\n",
       "  22   67   31   21   50   14   46\n",
       "[torch.DoubleTensor of size 7x7]\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary:index(1, torch.LongTensor(selected)):copy(sentences[1]:index(1, torch.LongTensor(selected)):double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  1  1  1  1  1  1\n",
       " 1  1  1  1  1  1  1\n",
       " 1  1  1  1  1  1  1\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       "[torch.ByteTensor of size 10x7]\n",
       "\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(actions:select(2,2), 1):view(n, 1):expand(n, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0\n",
       "[torch.DoubleTensor of size 10x7]\n",
       "\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = torch.zeros(n, 7)\n",
    "-- test:copy(actions:selec(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- torch.zeros(n, 7):scatter(2, actions:select(2, 1), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maskedSelect = nn.MaskedSelect()\n",
    "mask1 = torch.eq(actions:select(2,2), 1):view(n, 1):expand(n, k)\n",
    "allTokens = sentences[1]:maskedSelect(mask1)\n",
    "mask2 = torch.gt(allTokens,0)\n",
    "allTokens = allTokens:maskedSelect(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0  61   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0  49   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0  25   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       " 62   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       " 36   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       " 15   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       " 36   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       " 88   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       " 55   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       " 22   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "[torch.DoubleTensor of size 10x15]\n",
       "\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(n, 15):scatter(2, qindx, sentences[1]:double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  61   48    7   38   28   14    6\n",
       "  49   25   35   96   57   83   24\n",
       "  25   41    6   54   90   87   65\n",
       "  62   34   41    8   13    4    3\n",
       "  36   69   64   82   25   77   39\n",
       "  15   74   19   54   10   22   91\n",
       "  36   99    5   50   56   31   79\n",
       "  88   75   79  100    5   31   10\n",
       "  55   33   43   50   70   32   20\n",
       "  22   67   31   21   50   14   46\n",
       "[torch.LongTensor of size 10x7]\n",
       "\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = torch.linspace(1, x:size(1), x:size(1) ):long()\n",
    "selected = indices[x:eq(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indx = torch.range(1, 10)\n",
    "-- Summary index for selecting the words\n",
    "sumindx = nn.MaskedSelect():forward({indx, actions:select(2,1):resize(10, 1):byte()})  --- sentences\n",
    "-- need a LongTensor to do the selection\n",
    "-- sumindx = torch.LongTensor(sumindx:size(1)):copy(sumindx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indx = torch.range(1, 10)\n",
    "-- Summary index for selecting the words\n",
    "sumindx = nn.MaskedSelect():forward({indx, actions:select(2,1):resize(10, 1):byte()})  --- sentences\n",
    "-- need a LongTensor to do the selection\n",
    "sumindx = torch.LongTensor(sumindx:size(1)):copy(sumindx)\n",
    "--- This gives the wrong selection we want\n",
    "print(sentences:index(1, sumindx))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
