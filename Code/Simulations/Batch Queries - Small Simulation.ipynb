{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Some useful functions\n",
    "function genNbyK(n, k, a, b)\n",
    "    out = torch.LongTensor(n, k)\n",
    "    for i=1, n do\n",
    "        for j = 1, k do\n",
    "            out[i][j] = torch.random(a, b)\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function buildModel(model, vocabSize, embeddingSize, metric, adapt, use_cuda)\n",
    "    -- Small experiments seem to show that the Tanh activations performed better\\\n",
    "    --      than the ReLU for the bow model\n",
    "    if model == 'bow' then\n",
    "        print(string.format(\"Running bag-of-words model to learn %s\", metric))\n",
    "        sentenceLookup = nn.Sequential()\n",
    "                    :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                    :add(nn.Sum(2, 3, true)) -- Not averaging blows up model so keep this true\n",
    "                    :add(nn.Tanh())\n",
    "    else\n",
    "        print(string.format(\"Running LSTM model to learn %s\", metric))\n",
    "        sentenceLookup = nn.Sequential()\n",
    "                    :add(nn.LookupTableMaskZero(vocabSize, embeddingSize))\n",
    "                    :add(nn.SplitTable(2))\n",
    "                    :add(nn.Sequencer(nn.LSTM(embeddingSize, embeddingSize)))\n",
    "                    :add(nn.SelectTable(-1))            -- selects last state of the LSTM\n",
    "                    :add(nn.Linear(embeddingSize, embeddingSize))\n",
    "                    :add(nn.ReLU())\n",
    "    end\n",
    "    local queryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\") \n",
    "    local summaryLookup = sentenceLookup:clone(\"weight\", \"gradWeight\")\n",
    "    local pmodule = nn.ParallelTable()\n",
    "                :add(sentenceLookup)\n",
    "                :add(queryLookup)\n",
    "                :add(summaryLookup)\n",
    "\n",
    "    if model == 'bow' then\n",
    "        nnmodel = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(nn.Tanh())\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "    else\n",
    "        nnmodel = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(nn.ReLU())\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "    end\n",
    "\n",
    "    if adapt then \n",
    "        print(\"Adaptive regularization\")\n",
    "        local logmod = nn.Sequential()\n",
    "            :add(nn.Linear(embeddingSize * 3, 1))\n",
    "            :add(nn.LogSigmoid())\n",
    "            :add(nn.SoftMax())\n",
    "\n",
    "        local regmod = nn.Sequential()\n",
    "            :add(nn.Linear(embeddingSize * 3, 2))\n",
    "\n",
    "        local fullmod = nn.ConcatTable()\n",
    "            :add(regmod)\n",
    "            :add(logmod)\n",
    "\n",
    "        local final = nn.Sequential()\n",
    "            :add(pmodule)\n",
    "            :add(nn.JoinTable(2))\n",
    "            :add(fullmod)\n",
    "\n",
    "        nnmodel = final\n",
    "    end\n",
    "\n",
    "    if use_cuda then\n",
    "        return nnmodel:cuda()\n",
    "    end\n",
    "    return nnmodel\n",
    "end\n",
    "\n",
    "function buildPredsummary(summary, chosenactions, inputsentences, select_index)\n",
    "    if summary == nil then\n",
    "        summary = torch.zeros(inputsentences:size())\n",
    "    end\n",
    "    for i=1, chosenactions:size(1) do\n",
    "        -- the 2 is for the SELECT index, will have to make this more general later\n",
    "        if chosenactions[i][select_index] == 1 then\n",
    "            summary[i]:copy(inputsentences[i])\n",
    "        end\n",
    "    end    \n",
    "    return summary\n",
    "end\n",
    "\n",
    "function buildPredsummaryFast(summary, chosenactions, inputsentences, select_index)\n",
    "    n = inputsentences:size(1)\n",
    "    k = inputsentences:size(2)\n",
    "    if summary == nil then\n",
    "        summary = torch.zeros(inputsentences:size())\n",
    "    end\n",
    "    actionmatrix = chosenactions:select(2, select_index):clone():resize(n, 1):view(n, 1):expand(n, k):clone()\n",
    "--     actionmatrix = chosenactions:select(2, select_index):resize(1, n):view(n, 1):expand(n, k):clone()\n",
    "    return actionmatrix:cmul(inputsentences:double())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Setting parameters\n",
    "n = 10\n",
    "n_s = 5\n",
    "k = 7\n",
    "q = 5\n",
    "a = 1\n",
    "b = 100\n",
    "embDim = 50\n",
    "SKIP = 1\n",
    "SELECT = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Simulating streams and queries\n",
    "queries = genNbyK(n, q, a, b)\n",
    "\n",
    "-- Note that the sentences are batched by sentence index so sentences[1] is the first sentence of each article\n",
    "sentences = {}\n",
    "for i=1, n_s do\n",
    "    sentences[i] = genNbyK(n, k, a, b)\n",
    "end\n",
    "\n",
    "-- Using this to generate the optimal actions\n",
    "true_actions = {}\n",
    "for i=1, n_s do\n",
    "    ---- Simulating the data\n",
    "    trueqValues = torch.rand(n, 2)\n",
    "    \n",
    "     ---- Generating the max values and getting the indices\n",
    "    qMaxtrue, qindxtrue = torch.max(trueqValues, 2)\n",
    "    \n",
    "    --- I want to select the qindx elements for each row\n",
    "    true_actions[i] = torch.zeros(n, 2):scatter(2, qindxtrue, torch.ones(trueqValues:size()))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running bag-of-words model to learn f1\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "predictions = \t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-0.3811 -0.2914\n",
       "-0.2728  0.0209\n",
       " 0.0008  0.1178\n",
       " 0.0951 -0.0020\n",
       "-0.0579  0.1702\n",
       "-0.2681 -0.2834\n",
       "-0.0495  0.0078\n",
       " 0.0457  0.0468\n",
       "-0.0956  0.0349\n",
       "-0.2767  0.1540\n",
       "[torch.DoubleTensor of size 10x2]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local SKIP = 1\n",
    "local SELECT = 2\n",
    "\n",
    "-- Simulating streams and queries\n",
    "queries = genNbyK(n, q, a, b)\n",
    "\n",
    "-- Note that the sentences are batched by sentence index so sentences[1] is the first sentence of each article\n",
    "sentences = {}\n",
    "for i=1, n_s do\n",
    "    sentences[i] = genNbyK(n, k, a, b)\n",
    "end\n",
    "\n",
    "-- Using this to generate the optimal actions\n",
    "true_actions = {}\n",
    "for i=1, n_s do \n",
    "    ---- Simulating the data\n",
    "    trueqValues = torch.rand(n, 2)\n",
    "    \n",
    "     ---- Generating the max values and getting the indices\n",
    "    qMaxtrue, qindxtrue = torch.max(trueqValues, 2)\n",
    "    \n",
    "    --- I want to select the qindx elements for each row\n",
    "    true_actions[i] = torch.zeros(n, 2):scatter(2, qindxtrue, torch.ones(trueqValues:size()))\n",
    "end\n",
    "\n",
    "model = buildModel('bow', b, embDim, 'f1', false, false)\n",
    "preds = model:forward({sentences[1], queries, torch.zeros(n, q)})\n",
    "print(\"predictions = \")\n",
    "print(preds)\n",
    "\n",
    "-- Pulling the best actions\n",
    "qMax, qindx = torch.max(preds, 2)\n",
    "\n",
    "-- Here's the fast way to select the optimal action for each query\n",
    "actions = torch.zeros(n, 2):scatter(2, qindx, torch.ones(preds:size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalPredsummary = torch.zeros(n, 3 * k)\n",
    "\n",
    "predsummary1 = buildPredsummaryFast(predsummary, actions, sentences[1], SELECT)\n",
    "predsummary2 = buildPredsummaryFast(predsummary, actions, sentences[2], SELECT)\n",
    "\n",
    "nps = predsummary1:size(1)\n",
    "n_l = totalPredsummary:size(2)\n",
    "for i=1, predsummary1:size(1) do\n",
    "    if predsummary1[i]:sum() > 0 then \n",
    "        indices = torch.linspace(1, n_l, n_l):long() \n",
    "        maxindex = torch.max(indices[torch.eq(totalPredsummary[i], 0)])\n",
    "        lenx = predsummary1[i]:size(1)\n",
    "        totalPredsummary[i][{{maxindex - lenx+1, maxindex}}]:copy(predsummary1[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nps = predsummary1:size(1)\n",
    "n_l = totalPredsummary:size(2)\n",
    "for i=1, predsummary1:size(1) do\n",
    "    if predsummary1[i]:sum() > 0 then \n",
    "        indices = torch.linspace(1, n_l, n_l):long() \n",
    "        maxindex = torch.max(indices[torch.eq(totalPredsummary[i], 0)])\n",
    "        lenx = predsummary1[i]:size(1)\n",
    "        totalPredsummary[i][{{maxindex - lenx+1, maxindex}}]:copy(predsummary1[i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 20\n",
       "  0   0   0   0   0   0   0   8   5  75  24  91   5  92   8   5  75  24  91   5\n",
       "  0   0   0   0   0   0   0  19  75  81  82  95  26   3  19  75  81  82  95  26\n",
       "  0   0   0   0   0   0   0  44  61  98  28  92  26  74  44  61  98  28  92  26\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0  94  16  61  70  61  86  62  94  16  61  70  61  86\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0  46  12  75  80   9  96  74  46  12  75  80   9  96\n",
       "  0   0   0   0   0   0   0  44  93  25  62  27  27   5  44  93  25  62  27  27\n",
       "  0   0   0   0   0   0   0  47  40  28  80  48  63  92  47  40  28  80  48  63\n",
       "  0   0   0   0   0   0   0  70  46  10  81  11   3   4  70  46  10  81  11   3\n",
       "\n",
       "Columns 21 to 21\n",
       " 92\n",
       "  3\n",
       " 74\n",
       "  0\n",
       " 62\n",
       "  0\n",
       " 74\n",
       "  5\n",
       " 92\n",
       "  4\n",
       "[torch.DoubleTensor of size 10x21]\n",
       "\n",
       "  8   5  75  24  91   5  92\n",
       " 19  75  81  82  95  26   3\n",
       " 44  61  98  28  92  26  74\n",
       "  0   0   0   0   0   0   0\n",
       " 94  16  61  70  61  86  62\n",
       "  0   0   0   0   0   0   0\n",
       " 46  12  75  80   9  96  74\n",
       " 44  93  25  62  27  27   5\n",
       " 47  40  28  80  48  63  92\n",
       " 70  46  10  81  11   3   4\n",
       "[torch.DoubleTensor of size 10x7]\n",
       "\n"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary, predsummary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 7]\n",
       "\n"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary[i][{{maxindex - lenx+1, maxindex}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.LongTensor with no dimension]\n",
       "\n"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1[i]:nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nps = predsummary1:size(1)\n",
    "n_l = totalPredsummary:size(2)\n",
    "i = 4\n",
    "\n",
    "indices = torch.linspace(1, n_l, n_l):long() \n",
    "maxindex = torch.max(indices[torch.eq(totalPredsummary[i], 0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"lenx = predsummary1[i]:nonzero():size(1)...\"]:1: bad argument #1 to 'size' (dimension 1 out of range of 0D tensor at /Users/franciscojavierarceo/torch/pkg/torch/generic/Tensor.c:19)\nstack traceback:\n\t[C]: in function 'size'\n\t[string \"lenx = predsummary1[i]:nonzero():size(1)...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0107b06d20",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"lenx = predsummary1[i]:nonzero():size(1)...\"]:1: bad argument #1 to 'size' (dimension 1 out of range of 0D tensor at /Users/franciscojavierarceo/torch/pkg/torch/generic/Tensor.c:19)\nstack traceback:\n\t[C]: in function 'size'\n\t[string \"lenx = predsummary1[i]:nonzero():size(1)...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ojavierarceo/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...vierarceo/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ojavierarceo/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0107b06d20"
     ]
    }
   ],
   "source": [
    "lenx = predsummary1[i]:nonzero():size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenx = predsummary1[i]:nonzero():size(1)\n",
    "totalPredsummary[i][{{maxindex - lenx+1, maxindex}}]:copy(predsummary1[i]:nonzero())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 7]\n",
       "\n"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  8\n",
       "  5\n",
       " 75\n",
       " 24\n",
       " 91\n",
       "  5\n",
       " 92\n",
       "[torch.DoubleTensor of size 7]\n",
       "\n"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  8\n",
       "  5\n",
       " 75\n",
       " 24\n",
       " 91\n",
       "  5\n",
       " 92\n",
       "[torch.DoubleTensor of size 7]\n",
       "\n"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0  0  0  1  2  3  4  5  6  7  1  2  3  4  5  6  7\n",
       " 0  0  0  0  0  0  0  1  2  3  4  5  6  7  1  2  3  4  5  6  7\n",
       " 0  0  0  0  0  0  0  1  2  3  4  5  6  7  1  2  3  4  5  6  7\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  1  2  3  4  5  6  7  1  2  3  4  5  6  7\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  1  2  3  4  5  6  7  1  2  3  4  5  6  7\n",
       " 0  0  0  0  0  0  0  1  2  3  4  5  6  7  1  2  3  4  5  6  7\n",
       " 0  0  0  0  0  0  0  1  2  3  4  5  6  7  1  2  3  4  5  6  7\n",
       " 0  0  0  0  0  0  0  1  2  3  4  5  6  7  1  2  3  4  5  6  7\n",
       "[torch.DoubleTensor of size 10x21]\n",
       "\n"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  8\n",
       "  5\n",
       " 75\n",
       " 24\n",
       " 91\n",
       "  5\n",
       " 92\n",
       "[torch.DoubleTensor of size 21]\n",
       "\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 8]\n",
       "\n"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- totalPredsummary[i][ {{21 - 21+1, 21 - 7} }]\n",
    "totalPredsummary[i][ {{21 - 7 *2 , 21 - 7} }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "sindx = 2\n",
    "nws = 21\n",
    "s_val = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  8\n",
       "  5\n",
       " 75\n",
       " 24\n",
       " 91\n",
       "  5\n",
       " 92\n",
       "[torch.DoubleTensor of size 7]\n",
       "\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15\t\n"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 7]\n",
       "\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Sliding from left to right so the arithmetic is weird\n",
    "\n",
    "-- totalPredsummary[i][{{ nws - s_val * sindx + 1, nws - s_val }}]:copy(predsummary1[1])\n",
    "totalPredsummary[i][{{ nws - s_val * sindx + 1, nws - s_val }}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 20\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   5  75  24  91   5\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  19  75  81  82  95  26\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  44  61  98  28  92  26\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  94  16  61  70  61  86\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46  12  75  80   9  96\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  44  93  25  62  27  27\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  47  40  28  80  48  63\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  70  46  10  81  11   3\n",
       "\n",
       "Columns 21 to 21\n",
       " 92\n",
       "  3\n",
       " 74\n",
       "  0\n",
       " 62\n",
       "  0\n",
       " 74\n",
       "  5\n",
       " 92\n",
       "  4\n",
       "[torch.DoubleTensor of size 10x21]\n",
       "\n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_l = totalPredsummary[1]:size(1)\n",
    "indices = torch.linspace(1, n_l, n_l):long()\n",
    "maxindex = torch.max(indices[torch.eq(totalPredsummary[i], 0)])\n",
    "lenx = predsummary1[i]:nonzero():size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14\t7\t\n"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxindex, lenx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 8]\n",
       "\n"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary[i][{{lenx, maxindex}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14\t7\t\n"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Here's how to get the indices\n",
    "torch.max(indices[torch.eq(totalPredsummary[1], 0)]),  predsummary1[i]:nonzero():size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  5\n",
       " 75\n",
       " 24\n",
       " 91\n",
       "  5\n",
       " 92\n",
       "[torch.DoubleTensor of size 14]\n",
       "\n"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary[i][{{lenx+1, maxindex}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7\t\n"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1:size(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 20\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   8   5  75  24  91   5\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  19  75  81  82  95  26\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  44  61  98  28  92  26\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  94  16  61  70  61  86\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46  12  75  80   9  96\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  44  93  25  62  27  27\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  47  40  28  80  48  63\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  70  46  10  81  11   3\n",
       "\n",
       "Columns 21 to 21\n",
       " 92\n",
       "  3\n",
       " 74\n",
       "  0\n",
       " 62\n",
       "  0\n",
       " 74\n",
       "  5\n",
       " 92\n",
       "  4\n",
       "[torch.DoubleTensor of size 10x21]\n",
       "\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       " 36\n",
       " 48\n",
       " 16\n",
       " 69\n",
       " 35\n",
       " 33\n",
       " 13\n",
       "[torch.DoubleTensor of size 14]\n",
       "\n",
       "0\t\n"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary[1], totalPredsummary[2]:sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0   0   0   0   0   0   0  36  48  16  69  35  33  13\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0  44   8  12  28  82  69  99\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0  30  57  60  61  55  29  26\n",
       "[torch.DoubleTensor of size 10x14]\n",
       "\n"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 36  48  16  69  35  33  13\n",
       "  0   0   0   0   0   0   0\n",
       " 44   8  12  28  82  69  99\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       " 30  57  60  61  55  29  26\n",
       "[torch.DoubleTensor of size 10x7]\n",
       "\n",
       "  4  54  69  92  40  13  42\n",
       "  0   0   0   0   0   0   0\n",
       " 63  80  31  31  96  25  36\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       " 16  66  10  55  41  57  14\n",
       "[torch.DoubleTensor of size 10x7]\n",
       "\n"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1, predsummary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalPredsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Filling in the rightmost part of the data\n",
    "totalPredsummary[1][{{14-7+1, 14}}]:copy(predsummary1[1])\n",
    "\n",
    "totalPredsummary[3][{{14-7+1, 14}}]:copy(predsummary1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out, y  = torch.min(totalPredsummary, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0\n",
       " 0  0\n",
       "[torch.DoubleTensor of size 2x2]\n",
       "\n"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary[{{1, 2, 3, 4}, {1, 2}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0   0   0   0   0   0   0  36  48  16  69  35  33  13\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0  44   8  12  28  82  69  99\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "[torch.DoubleTensor of size 10x14]\n",
       "\n"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 10x1]\n",
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.LongTensor of size 10x1]\n",
       "\n"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 36\n",
       " 48\n",
       " 16\n",
       " 69\n",
       " 35\n",
       " 33\n",
       " 13\n",
       "[torch.DoubleTensor of size 7]\n",
       "\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 36  48  16  69  35  33  13\n",
       "  0   0   0   0   0   0   0\n",
       " 44   8  12  28  82  69  99\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       " 30  57  60  61  55  29  26\n",
       "[torch.DoubleTensor of size 10x7]\n",
       "\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0   0   0   0   0   0   0  36  48  16  69  35  33  13\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0  44   8  12  28  82  69  99\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "[torch.DoubleTensor of size 10x14]\n",
       "\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 36  48  16  69  35  33  13\n",
       "  0   0   0   0   0   0   0\n",
       " 44   8  12  28  82  69  99\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0\n",
       " 30  57  60  61  55  29  26\n",
       "[torch.DoubleTensor of size 10x7]\n",
       "\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsummary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0   0   0   0   0   0   0  36  48  16  69  35  33  13\n",
       "  0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "  0   0   0   0   0   0   0  44   8  12  28  82  69  99\n",
       "[torch.DoubleTensor of size 3x14]\n",
       "\n"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary:index(1, torch.LongTensor({1, 2, 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0\n",
       " 0  0\n",
       "[torch.DoubleTensor of size 2x2]\n",
       "\n",
       " 36  48  16\n",
       "  0   0   0\n",
       " 44   8  12\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalPredsummary[{{1, 2}, {2, 3}}], predsummary1[{{1, 3}, {1, 3 }}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function generateNewSummary(predsummaryT, totalPredsummary, actionvec, k)\n",
    "    for i=1, predsummaryT:size(1) do\n",
    "        for j = 1, predsummaryT:size(2) do\n",
    "            if \n",
    "            totalPredsummary[i][{k -predsummaryT:size(2)  , k}]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function stackMemory(newinput, memory_hist, memsize, adapt, use_cuda)\n",
    "    local sentMemory = torch.cat(newinput[1][1]:double(), memory_hist[1][1]:double(), 1)\n",
    "    local queryMemory = torch.cat(newinput[1][2]:double(), memory_hist[1][2]:double(), 1)\n",
    "    local sumryMemory = torch.cat(newinput[1][3]:double(), memory_hist[1][3]:double(), 1)\n",
    "    local rewardMemory = torch.cat(newinput[2]:double(), memory_hist[2]:double(), 1)\n",
    "\n",
    "    if adapt thena\n",
    "        regMemory = torch.cat(newinput[4]:double(), memory_hist[4]:double(), 1)\n",
    "    end \n",
    "\n",
    "    if use_cuda then \n",
    "        actionMemory = torch.cat(newinput[3]:double(), memory_hist[3]:double(), 1)\n",
    "    else \n",
    "        actionMemory = torch.cat(newinput[3], memory_hist[3], 1)\n",
    "    end\n",
    "    --- specifying rows to index \n",
    "    if sentMemory:size(1) <= memsize then\n",
    "        nend = sentMemory:size(1)\n",
    "        nstart = 1\n",
    "    else \n",
    "        nstart = math.max(memsize - sentMemory:size(1), 1)\n",
    "        nend = memsize + nstart\n",
    "    end\n",
    "    --- Selecting n last data points\n",
    "    sentMemory = sentMemory[{{nstart, nend}}]\n",
    "    queryMemory = queryMemory[{{nstart, nend}}]\n",
    "    sumryMemory = sumryMemory[{{nstart, nend}}]\n",
    "    rewardMemory = rewardMemory[{{nstart, nend}}]\n",
    "    actionMemory = actionMemory[{{nstart, nend}}]\n",
    "\n",
    "    if use_cuda then\n",
    "        inputMemory = {sentMemory:cuda(), queryMemory:cuda(), sumryMemory:cuda()}\n",
    "        rewardMemory = rewardMemory:cuda()\n",
    "        actionMemory = torch.ByteTensor(#actionMemory):copy(actionMemory):cuda()\n",
    "    end\n",
    "\n",
    "    inputMemory = {sentMemory, queryMemory, sumryMemory}\n",
    "    if adapt then\n",
    "        regMemory = regMemory[{{nstart, nend}}]\n",
    "        return {inputMemory, rewardMemory, actionMemory, regMemory}\n",
    "    end \n",
    "    return {inputMemory, rewardMemory, actionMemory}\n",
    "end    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
