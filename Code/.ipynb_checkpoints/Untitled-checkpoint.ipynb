{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "require 'cutorch'\n",
    "require 'cunn'\n",
    "require 'cunnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function build_bowmlp(nn_vocab_module, embed_dim)\n",
    "    local model = nn.Sequential()\n",
    "    :add(nn_vocab_module)            -- returns a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.Sum(1, embed_dim, true)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.Tanh())                     ---     :add(nn.ReLU()) <- this one did worse\n",
    "   return model\n",
    "end\n",
    "\n",
    "function build_lstm(nn_vocab_module, embed_dim)\n",
    "    local model = nn.Sequential()\n",
    "    :add(nn_vocab_module)            -- returns a sequence-length x batch-size x embedDim tensor\n",
    "    :add(nn.SplitTable(1, embed_dim)) -- splits into a sequence-length table with batch-size x embedDim entries\n",
    "    :add(nn.Sequencer(nn.LSTM(embed_dim, embed_dim)))\n",
    "    :add(nn.SelectTable(-1)) -- selects last state of the LSTM\n",
    "    :add(nn.Linear(embed_dim, embed_dim)) -- map last state to a score for classification\n",
    "    :add(nn.Tanh())                     ---     :add(nn.ReLU()) <- this one did worse\n",
    "   return model\n",
    "end\n",
    "\n",
    "function build_model(model, vocab_size, embed_dim, outputSize, use_cuda)\n",
    "    local nn_vocab = nn.LookupTableMaskZero(vocab_size, embed_dim)\n",
    "    if model == 'bow' then\n",
    "        print(\"Running BOW model\")\n",
    "        mod1 = build_bowmlp(nn_vocab, embed_dim)\n",
    "        mod2 = build_bowmlp(nn_vocab, embed_dim)\n",
    "        mod3 = build_bowmlp(nn_vocab, embed_dim)\n",
    "    end\n",
    "    if model == 'lstm' then         \n",
    "        print(\"Running LSTM model\")\n",
    "        mod1 = build_lstm(nn_vocab, embed_dim)\n",
    "        mod2 = build_lstm(nn_vocab, embed_dim)\n",
    "        mod3 = build_lstm(nn_vocab, embed_dim)\n",
    "    end\n",
    "\n",
    "    local ParallelModel = nn.ParallelTable()\n",
    "    ParallelModel:add(mod1)\n",
    "    ParallelModel:add(mod2)\n",
    "    ParallelModel:add(mod3)\n",
    "\n",
    "    local FinalMLP = nn.Sequential()\n",
    "    FinalMLP:add(ParallelModel)\n",
    "    FinalMLP:add(nn.JoinTable(2))\n",
    "    FinalMLP:add(nn.Linear(embed_dim * 3, 2) )\n",
    "    FinalMLP:add(nn.Max(2) )\n",
    "    FinalMLP:add(nn.Tanh())\n",
    "\n",
    "    if use_cuda then\n",
    "        return FinalMLP:cuda()\n",
    "    else\n",
    "        return FinalMLP\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usecuda = true\n",
    "model = 'lstm'\n",
    "\n",
    "batch_size = 2\n",
    "vocab_size = 4\n",
    "embed_dim = 10\n",
    "outputSize = 1\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_cuda then\n",
    "  Tensor = torch.CudaTensor\n",
    "  LongTensor = torch.CudaLongTensor\n",
    "else\n",
    "  Tensor = torch.Tensor\n",
    "  LongTensor = torch.LongTensor\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Running LSTM model\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- sentences, summary, query, yrouge = build_data(usecuda)\n",
    "FinalMLP  = build_model(model, vocab_size, embed_dim, outputSize, usecuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSECriterion():cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = {{0, 1, 3, 4}, {0, 2, 4, 3}}\n",
    "summaries = {{0, 0, 1, 4}, {0, 2, 3, 1}}\n",
    "scores = {0.74, -0.24}\n",
    "queries = {{0, 1, 4, 3}, {0, 1, 4, 3}}\n",
    "\n",
    "minibatch = 1\n",
    "\n",
    "sentence = LongTensor({sentences[minibatch]}):t()\n",
    "summary = LongTensor({summaries[minibatch]}):t()\n",
    "query = LongTensor({queries[minibatch]}):t()\n",
    "yrougue = Tensor({scores[minibatch]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01 *\n",
       "-4.4842\n",
       "[torch.CudaTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:forward({sentence, summary, query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : CudaTensor - size: 1x10\n",
       "  2 : CudaTensor - size: 1x10\n",
       "  3 : CudaTensor - size: 1x10\n",
       "}\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(1).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 10\n",
       " 0.0785 -0.1104  0.1924  0.0999  0.2157 -0.1067 -0.3475  0.1636  0.1813  0.2357\n",
       "\n",
       "Columns 11 to 20\n",
       " 0.0524  0.3517  0.1536 -0.1130  0.2979 -0.2889 -0.2363  0.1289  0.1409  0.2291\n",
       "\n",
       "Columns 21 to 30\n",
       "-0.0942  0.2010 -0.0956  0.1286  0.0615 -0.2787 -0.1118 -0.1678  0.1824 -0.0821\n",
       "[torch.CudaTensor of size 1x30]\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(2).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2189 -0.0449\n",
       "[torch.CudaTensor of size 1x2]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(3).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01 *\n",
       "-4.4872\n",
       "[torch.CudaTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalMLP:get(4).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.7400\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yrougue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch 10, loss =0.132912\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 20, loss =0.178267\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 30, loss =0.189686\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 40, loss =0.186478\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 50, loss =0.177294\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 60, loss =0.165713\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 70, loss =0.153201\t"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 80, loss =0.140383\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 90, loss =0.127561\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 100, loss =0.114925\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullpreds = {0, 0}\n",
    "for epoch = 1, 100 do\n",
    "    for minibatch = 1, 2 do\n",
    "        sentence = LongTensor({sentences[minibatch]}):t()\n",
    "        summary = LongTensor({summaries[minibatch]}):t()\n",
    "        query = LongTensor({queries[minibatch]}):t()\n",
    "        yrougue = Tensor({scores[minibatch]}):cuda()\n",
    "        preds = FinalMLP:forward({sentence, summary, query})\n",
    "        --- storing predictions\n",
    "        fullpreds[minibatch] = torch.totable(preds)\n",
    "        \n",
    "        loss = criterion:forward(preds, yrougue)\n",
    "        FinalMLP:zeroGradParameters()\n",
    "        grads = criterion:backward(preds, yrougue)\n",
    "        FinalMLP:backward({sentence, summary, query}, grads)\n",
    "        FinalMLP:updateParameters(learning_rate)\n",
    "\n",
    "    end\n",
    "    if (epoch % 10)==0 then \n",
    "        print(string.format(\"Epoch %i, loss =%6f\", epoch, loss))\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
