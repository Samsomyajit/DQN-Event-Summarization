\documentclass[12pt]{article}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{ bm }
\usepackage{amsmath }
\usepackage{hyperref}

\title{Deep Q-Learning for NLP}

\author{
	Chris Kedzie \\ \href{mailto: kedzie@cs.columbia.edu}{\small kedzie@cs.columbia.edu} 
		\and  
	Francisco Javier Arceo \\ \href{mailto: fja2114@columbia.edu}{\small fja2114@columbia.edu} 
	}
	
\begin{document}
\maketitle

\bibliographystyle{plain}

%\begin{abstract}
%\end{abstract}

\section{Brain Dump}

Input Data: Streaming Queries from the time of query until an hour before the time of query. 

Step 1:  ?

Step 2:  ?

Output: Summarization of relevant Queries.

Last hidden layer of an LSTM-RNN will be a k-dimensional embedding of a given sentence. 

Use Deep Q Learning framework based on \cite{MnihKSGAWR13} and \cite{DBLP:journals/corr/MnihBMGLHSK16}.

\section{Useful Links}

Just adding some links to useful things 

\url{http://trec.nist.gov/}

\url{http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf}

\section{To-Do's}
\center
\begin{tabular}{ l | c | c  }
	\hline
	Task  & Status  & Person\\ \hline
  	Read DQN Paper \cite{MnihKSGAWR13}  & Complete  & Francisco \\
	Read Asynchronous RL Paper \cite{DBLP:journals/corr/MnihBMGLHSK16} & Incomplete  & Francisco \\
	Read  Regularization Paper \cite{chen2012marginalized} & Incomplete  & Francisco \\
	Install Torch & Complete  & Francisco \\
	Small simulation of MLP in Torch & Incomplete  & Francisco \\
	Small simulation of DQN in Torch & Incomplete  & Francisco \\
	Download data & Incomplete  & Francisco \\
	Explore data & Incomplete  & Francisco \\
	\hline
\end{tabular}

\bibliography{DeepNLPQLearning}

\end{document}
